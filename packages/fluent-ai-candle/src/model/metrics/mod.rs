//! Performance metrics and statistics for model operations
//!
//! This module provides:
//! - Comprehensive model performance statistics
//! - Real-time generation metrics
//! - Memory usage tracking
//! - Cache performance monitoring

use crate::model::cache::KVCacheStats;

/// Comprehensive model performance statistics
#[derive(Debug, Clone)]
pub struct ModelPerformanceStats {
    /// Total tokens generated by this model instance
    pub total_tokens_generated: u64,
    /// Average tokens per second
    pub avg_tokens_per_second: u64,
    /// Current sequence ID
    pub current_sequence_id: u64,
    /// Total memory usage (model + cache)
    pub total_memory_usage: u64,
    /// Cache memory usage
    pub cache_memory_usage: u64,
    /// Cache hit rate (0.0-1.0)
    pub cache_hit_rate: f32,
    /// Number of cache entries
    pub cache_entries: u64,
    /// Active sequences
    pub active_sequences: u32,
    /// Cache evictions performed
    pub cache_evictions: u64,
    /// Memory utilization (0.0-1.0)
    pub memory_utilization: f32,
}

impl Default for ModelPerformanceStats {
    fn default() -> Self {
        Self {
            total_tokens_generated: 0,
            avg_tokens_per_second: 0,
            current_sequence_id: 0,
            total_memory_usage: 0,
            cache_memory_usage: 0,
            cache_hit_rate: 0.0,
            cache_entries: 0,
            active_sequences: 0,
            cache_evictions: 0,
            memory_utilization: 0.0,
        }
    }
}

impl ModelPerformanceStats {
    /// Create performance stats from cache stats
    pub fn from_cache_stats(cache_stats: &KVCacheStats, model_memory: u64) -> Self {
        Self {
            total_tokens_generated: 0, // This would be tracked separately
            avg_tokens_per_second: 0,  // This would be calculated from generation timing
            current_sequence_id: 0,    // This would be tracked by the model
            total_memory_usage: model_memory + cache_stats.total_memory_bytes,
            cache_memory_usage: cache_stats.total_memory_bytes,
            cache_hit_rate: cache_stats.hit_rate,
            cache_entries: cache_stats.total_entries,
            active_sequences: cache_stats.active_sequences,
            cache_evictions: cache_stats.eviction_count,
            memory_utilization: cache_stats.memory_utilization,
        }
    }

    /// Update token generation statistics
    pub fn update_token_stats(&mut self, tokens_generated: u64, duration_nanos: u64) {
        self.total_tokens_generated += tokens_generated;
        
        if duration_nanos > 0 {
            let tokens_per_second = (tokens_generated * 1_000_000_000) / duration_nanos;
            // Calculate moving average
            if self.avg_tokens_per_second == 0 {
                self.avg_tokens_per_second = tokens_per_second;
            } else {
                // Weighted average with decay factor of 0.9
                self.avg_tokens_per_second = ((self.avg_tokens_per_second as f64 * 0.9) + (tokens_per_second as f64 * 0.1)) as u64;
            }
        }
    }

    /// Get tokens per second for the current generation
    pub fn current_tokens_per_second(&self, tokens_in_window: u64, window_duration_nanos: u64) -> u64 {
        if window_duration_nanos == 0 {
            return 0;
        }
        (tokens_in_window * 1_000_000_000) / window_duration_nanos
    }
}

/// Real-time generation metrics
#[derive(Debug, Clone)]
pub struct GenerationMetrics {
    /// Current tokens per second
    pub tokens_per_second: u64,
    /// Total tokens generated
    pub total_tokens: u64,
    /// Time since last generation in nanoseconds
    pub time_since_last_generation_nanos: u64,
    /// Current active sequence
    pub current_sequence: u64,
    /// Whether actively generating
    pub is_actively_generating: bool,
}

impl Default for GenerationMetrics {
    fn default() -> Self {
        Self {
            tokens_per_second: 0,
            total_tokens: 0,
            time_since_last_generation_nanos: 0,
            current_sequence: 0,
            is_actively_generating: false,
        }
    }
}

impl GenerationMetrics {
    /// Create new generation metrics for a sequence
    pub fn new(sequence_id: u64) -> Self {
        Self {
            current_sequence: sequence_id,
            ..Default::default()
        }
    }

    /// Start generation tracking
    pub fn start_generation(&mut self) {
        self.is_actively_generating = true;
        self.time_since_last_generation_nanos = 0;
    }

    /// Stop generation tracking
    pub fn stop_generation(&mut self) {
        self.is_actively_generating = false;
    }

    /// Update token generation with timestamp
    pub fn update_token_generation(&mut self, tokens_generated: u64, generation_time_nanos: u64) {
        self.total_tokens += tokens_generated;
        self.time_since_last_generation_nanos = generation_time_nanos;
        
        if generation_time_nanos > 0 {
            self.tokens_per_second = (tokens_generated * 1_000_000_000) / generation_time_nanos;
        }
    }

    /// Get time since last generation in milliseconds
    pub fn time_since_last_generation_ms(&self) -> f64 {
        self.time_since_last_generation_nanos as f64 / 1_000_000.0
    }

    /// Check if generation is stalled (no activity for over 1 second)
    pub fn is_stalled(&self) -> bool {
        self.is_actively_generating && self.time_since_last_generation_nanos > 1_000_000_000
    }
}

/// Aggregated metrics for model monitoring
#[derive(Debug, Clone)]
pub struct ModelMetrics {
    /// Performance statistics
    pub performance: ModelPerformanceStats,
    /// Generation metrics
    pub generation: GenerationMetrics,
    /// Cache statistics
    pub cache_stats: Option<KVCacheStats>,
}

impl Default for ModelMetrics {
    fn default() -> Self {
        Self {
            performance: ModelPerformanceStats::default(),
            generation: GenerationMetrics::default(),
            cache_stats: None,
        }
    }
}

impl ModelMetrics {
    /// Create comprehensive metrics with cache stats
    pub fn with_cache_stats(cache_stats: KVCacheStats, model_memory_bytes: u64) -> Self {
        Self {
            performance: ModelPerformanceStats::from_cache_stats(&cache_stats, model_memory_bytes),
            generation: GenerationMetrics::default(),
            cache_stats: Some(cache_stats),
        }
    }

    /// Update all metrics
    pub fn update(&mut self, cache_stats: Option<KVCacheStats>, model_memory_bytes: u64, 
                  tokens_generated: u64, generation_duration_nanos: u64) {
        // Update performance stats
        self.performance.update_token_stats(tokens_generated, generation_duration_nanos);
        
        if let Some(stats) = cache_stats {
            self.performance.cache_memory_usage = stats.total_memory_bytes;
            self.performance.cache_hit_rate = stats.hit_rate;
            self.performance.cache_entries = stats.total_entries;
            self.performance.active_sequences = stats.active_sequences;
            self.performance.cache_evictions = stats.eviction_count;
            self.performance.total_memory_usage = model_memory_bytes + stats.total_memory_bytes;
            self.cache_stats = Some(stats);
        }
        
        // Update generation metrics
        self.generation.update_token_generation(tokens_generated, generation_duration_nanos);
    }

    /// Get summary statistics
    pub fn summary(&self) -> String {
        format!(
            "ModelMetrics[tokens: {}, avg_tps: {}, cache_hit_rate: {:.2}%, memory: {:.1}MB, active_seqs: {}]",
            self.performance.total_tokens_generated,
            self.performance.avg_tokens_per_second,
            self.performance.cache_hit_rate * 100.0,
            self.performance.total_memory_usage as f64 / 1_048_576.0, // Convert to MB
            self.performance.active_sequences
        )
    }
}