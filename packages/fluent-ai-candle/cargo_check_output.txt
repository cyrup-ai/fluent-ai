    Blocking waiting for file lock on build directory
    Checking fluent_ai_candle v0.1.0 (/Volumes/samsung_t9/fluent-ai/packages/fluent-ai-candle)
error[E0560]: struct `completion_response::CompletionResponse<'_>` has no field named `id`
   --> packages/fluent-ai-candle/src/client.rs:721:21
    |
721 |                     id: "temp".to_string(),
    |                     ^^ `completion_response::CompletionResponse<'_>` does not have this field
    |
    = note: available fields are: `text`, `provider`, `finish_reason`, `response_time_ms`, `generation_time_ms`, `tokens_per_second`

error[E0560]: struct `completion_response::CompletionResponse<'_>` has no field named `object`
   --> packages/fluent-ai-candle/src/client.rs:722:21
    |
722 |                     object: "text_completion".to_string(),
    |                     ^^^^^^ `completion_response::CompletionResponse<'_>` does not have this field
    |
    = note: available fields are: `text`, `provider`, `finish_reason`, `response_time_ms`, `generation_time_ms`, `tokens_per_second`

error[E0560]: struct `completion_response::CompletionResponse<'_>` has no field named `created`
   --> packages/fluent-ai-candle/src/client.rs:723:21
    |
723 |                     created: 0,
    |                     ^^^^^^^ `completion_response::CompletionResponse<'_>` does not have this field
    |
    = note: available fields are: `text`, `provider`, `finish_reason`, `response_time_ms`, `generation_time_ms`, `tokens_per_second`

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/client.rs:724:28
    |
724 |                     model: "candle-model".to_string(),
    |                            ^^^^^^^^^^^^^^^^^^^^^^^^^^ expected `Cow<'_, str>`, found `String`
    |
    = note: expected enum `Cow<'_, str>`
             found struct `std::string::String`
help: call `Into::into` on this expression to convert `std::string::String` into `Cow<'_, str>`
    |
724 |                     model: "candle-model".to_string().into(),
    |                                                      +++++++

error[E0560]: struct `completion_response::CompletionResponse<'_>` has no field named `choices`
   --> packages/fluent-ai-candle/src/client.rs:725:21
    |
725 |                     choices: vec![],
    |                     ^^^^^^^ `completion_response::CompletionResponse<'_>` does not have this field
    |
    = note: available fields are: `text`, `provider`, `finish_reason`, `response_time_ms`, `generation_time_ms`, `tokens_per_second`

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/client.rs:715:26
    |
715 |           AsyncStream::new(move || {
    |  _________----------------_^
    | |         |
    | |         arguments to this function are incorrect
716 | |             // TODO: Implement proper streaming logic
717 | |             // For now, return empty stream to resolve lifetime issues
718 | |             Box::pin(async move {
...   |
728 | |             })
729 | |         })
    | |_________^ expected `Receiver<Result<..., ...>>`, found closure
    |
    = note: expected struct `std::sync::mpsc::Receiver<std::result::Result<completion_response::CompletionResponse<'a>, candle_completion::error::CandleCompletionError>>`
              found closure `{closure@packages/fluent-ai-candle/src/client.rs:715:26: 715:33}`
note: associated function defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/fluent-ai-async/src/stream.rs:76:12
    |
76  |     pub fn new(receiver: std::sync::mpsc::Receiver<T>) -> Self
    |            ^^^

error[E0063]: missing fields `system_fingerprint` and `usage` in initializer of `candle_completion::streaming::CandleStreamingResponse`
   --> packages/fluent-ai-candle/src/client.rs:771:20
    |
771 |                 Ok(CandleStreamingResponse {
    |                    ^^^^^^^^^^^^^^^^^^^^^^^ missing `system_fingerprint` and `usage`

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/client.rs:766:26
    |
766 |           AsyncStream::new(move || {
    |  _________----------------_^
    | |         |
    | |         arguments to this function are incorrect
767 | |             // TODO: Implement proper streaming logic
768 | |             // For now, return empty stream to resolve lifetime issues
769 | |             Box::pin(async move {
...   |
778 | |             })
779 | |         })
    | |_________^ expected `Receiver<Result<..., ...>>`, found closure
    |
    = note: expected struct `std::sync::mpsc::Receiver<std::result::Result<candle_completion::streaming::CandleStreamingResponse, candle_completion::error::CandleCompletionError>>`
              found closure `{closure@packages/fluent-ai-candle/src/client.rs:766:26: 766:33}`
note: associated function defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/fluent-ai-async/src/stream.rs:76:12
    |
76  |     pub fn new(receiver: std::sync::mpsc::Receiver<T>) -> Self
    |            ^^^

error[E0599]: no variant or associated item named `TensorOperationFailed` found for enum `processing::error::ProcessingError` in the current scope
   --> packages/fluent-ai-candle/src/sampling/mirostat.rs:451:43
    |
451 |             .map_err(|e| ProcessingError::TensorOperationFailed(format!("Failed to create tensor from logits: {}", e)))?;
    |                                           ^^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `processing::error::ProcessingError`
    |
   ::: packages/fluent-ai-candle/src/processing/error.rs:15:1
    |
15  | pub enum ProcessingError {
    | ------------------------ variant or associated item `TensorOperationFailed` not found for this enum
    |
note: if you're trying to build a new `processing::error::ProcessingError` consider using one of the following associated functions:
      processing::error::ProcessingError::configuration
      processing::error::ProcessingError::context
      processing::error::ProcessingError::numerical
      processing::error::ProcessingError::resource
      and 6 others
   --> packages/fluent-ai-candle/src/processing/error.rs:123:5
    |
123 |     pub fn configuration<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
129 |     pub fn context<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
135 |     pub fn numerical<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
141 |     pub fn resource<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no method named `process` found for mutable reference `&mut mirostat::MirostatProcessor` in the current scope
   --> packages/fluent-ai-candle/src/sampling/mirostat.rs:458:37
    |
458 |         let processed_tensor = self.process(&logits_tensor, token_ids, position)
    |                                     ^^^^^^^
    |
    = help: items from traits can only be used if the trait is implemented and in scope
    = note: the following traits define an item `process`, perhaps you need to implement one of them:
            candidate #1: `PostProcessor`
            candidate #2: `fluent_ai_simd::logits::LogitsProcessor`
help: there is a method `process_logits` with a similar name, but with different arguments
   --> packages/fluent-ai-candle/src/processing/traits.rs:81:5
    |
81  | /     fn process_logits(
82  | |         &mut self,
83  | |         logits: &mut [f32],
84  | |         context: &ProcessingContext,
85  | |     ) -> ProcessingResult<()>;
    | |______________________________^

error[E0599]: no variant or associated item named `TensorOperationFailed` found for enum `processing::error::ProcessingError` in the current scope
   --> packages/fluent-ai-candle/src/sampling/mirostat.rs:459:43
    |
459 |             .map_err(|e| ProcessingError::TensorOperationFailed(format!("Mirostat processing failed: {}", e)))?;
    |                                           ^^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `processing::error::ProcessingError`
    |
   ::: packages/fluent-ai-candle/src/processing/error.rs:15:1
    |
15  | pub enum ProcessingError {
    | ------------------------ variant or associated item `TensorOperationFailed` not found for this enum
    |
note: if you're trying to build a new `processing::error::ProcessingError` consider using one of the following associated functions:
      processing::error::ProcessingError::configuration
      processing::error::ProcessingError::context
      processing::error::ProcessingError::numerical
      processing::error::ProcessingError::resource
      and 6 others
   --> packages/fluent-ai-candle/src/processing/error.rs:123:5
    |
123 |     pub fn configuration<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
129 |     pub fn context<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
135 |     pub fn numerical<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
141 |     pub fn resource<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `TensorOperationFailed` found for enum `processing::error::ProcessingError` in the current scope
   --> packages/fluent-ai-candle/src/sampling/mirostat.rs:463:43
    |
463 |             .map_err(|e| ProcessingError::TensorOperationFailed(format!("Failed to extract processed logits: {}", e)))?;
    |                                           ^^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `processing::error::ProcessingError`
    |
   ::: packages/fluent-ai-candle/src/processing/error.rs:15:1
    |
15  | pub enum ProcessingError {
    | ------------------------ variant or associated item `TensorOperationFailed` not found for this enum
    |
note: if you're trying to build a new `processing::error::ProcessingError` consider using one of the following associated functions:
      processing::error::ProcessingError::configuration
      processing::error::ProcessingError::context
      processing::error::ProcessingError::numerical
      processing::error::ProcessingError::resource
      and 6 others
   --> packages/fluent-ai-candle/src/processing/error.rs:123:5
    |
123 |     pub fn configuration<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
129 |     pub fn context<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
135 |     pub fn numerical<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
141 |     pub fn resource<S: Into<String>>(message: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_completion/compact_completion_response.rs:167:13
    |
167 | /             Box::pin(async move {
168 | |                 if sender.send(response).is_err() {
...   |
172 | |             })
    | |              ^- help: consider using a semicolon here: `;`
    | |______________|
    |                expected `()`, found `Pin<Box<...>>`
    |
    = note: expected unit type `()`
                  found struct `Pin<Box<{async block@packages/fluent-ai-candle/src/types/candle_completion/compact_completion_response.rs:167:22: 167:32}>>`

error[E0599]: no method named `inc` found for struct `CachePadded<AtomicU64>` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:352:45
    |
352 |             self_clone.index_update_counter.inc();
    |                                             ^^^ method not found in `CachePadded<AtomicU64>`

error[E0609]: no field `statistics` on type `ChatSearchIndex`
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:355:47
    |
355 |             if let Ok(mut stats) = self_clone.statistics.try_write() {
    |                                               ^^^^^^^^^^ unknown field
    |
    = note: available fields are: `inverted_index`, `document_store`, `term_frequencies`, `document_count`, `query_counter` ... and 8 others

error[E0599]: no method named `inc` found for struct `CachePadded<AtomicU64>` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:391:38
    |
391 |             self_clone.query_counter.inc();
    |                                      ^^^ method not found in `CachePadded<AtomicU64>`

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:542:53
    |
542 | ...                   matching_terms: vec![term.clone()],
    |                                       ^^^^^^^^^^^^^^^^^^ expected `SmallVec<Arc<str>, 8>`, found `Vec<Arc<str>>`
    |
    = note: expected struct `SmallVec<Arc<str>, 8>`
               found struct `Vec<Arc<str>>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<Arc<str>>` into `SmallVec<Arc<str>, 8>`
    |
542 |                                     matching_terms: vec![term.clone()].into(),
    |                                                                       +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:544:43
    |
544 | ...                   tags: vec![],
    |                             ^^^^^^ expected `SmallVec<Arc<str>, 4>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<Arc<str>, 4>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<Arc<str>, 4>`
    |
544 |                                     tags: vec![].into(),
    |                                                 +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:545:46
    |
545 | ...                   context: vec![],
    |                                ^^^^^^ expected `SmallVec<SearchChatMessage, 6>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<SearchChatMessage, 6>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<SearchChatMessage, 6>`
    |
545 |                                     context: vec![].into(),
    |                                                    +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:546:54
    |
546 | ...                   match_positions: vec![],
    |                                        ^^^^^^ expected `SmallVec<MatchPosition, 16>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<MatchPosition, 16>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<MatchPosition, 16>`
    |
546 |                                     match_positions: vec![].into(),
    |                                                            +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:592:41
    |
592 |                         matching_terms: vec![],
    |                                         ^^^^^^ expected `SmallVec<Arc<str>, 8>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<Arc<str>, 8>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<Arc<str>, 8>`
    |
592 |                         matching_terms: vec![].into(),
    |                                               +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:594:31
    |
594 |                         tags: vec![],
    |                               ^^^^^^ expected `SmallVec<Arc<str>, 4>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<Arc<str>, 4>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<Arc<str>, 4>`
    |
594 |                         tags: vec![].into(),
    |                                     +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:595:34
    |
595 |                         context: vec![],
    |                                  ^^^^^^ expected `SmallVec<SearchChatMessage, 6>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<SearchChatMessage, 6>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<SearchChatMessage, 6>`
    |
595 |                         context: vec![].into(),
    |                                        +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:596:42
    |
596 |                         match_positions: vec![],
    |                                          ^^^^^^ expected `SmallVec<MatchPosition, 16>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<MatchPosition, 16>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<MatchPosition, 16>`
    |
596 |                         match_positions: vec![].into(),
    |                                                +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:627:45
    |
627 | ...                   matching_terms: terms_clone.clone(),
    |                                       ^^^^^^^^^^^^^^^^^^^ expected `SmallVec<Arc<str>, 8>`, found `Vec<Arc<str>>`
    |
    = note: expected struct `SmallVec<Arc<str>, 8>`
               found struct `Vec<Arc<str>>`
help: call `Into::into` on this expression to convert `Vec<Arc<str>>` into `SmallVec<Arc<str>, 8>`
    |
627 |                             matching_terms: terms_clone.clone().into(),
    |                                                                +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:631:35
    |
631 | ...                   tags: vec![],
    |                             ^^^^^^ expected `SmallVec<Arc<str>, 4>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<Arc<str>, 4>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<Arc<str>, 4>`
    |
631 |                             tags: vec![].into(),
    |                                         +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:632:38
    |
632 | ...                   context: vec![],
    |                                ^^^^^^ expected `SmallVec<SearchChatMessage, 6>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<SearchChatMessage, 6>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<SearchChatMessage, 6>`
    |
632 |                             context: vec![].into(),
    |                                            +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:633:46
    |
633 | ...                   match_positions: vec![],
    |                                        ^^^^^^ expected `SmallVec<MatchPosition, 16>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<MatchPosition, 16>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<MatchPosition, 16>`
    |
633 |                             match_positions: vec![].into(),
    |                                                    +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:642:41
    |
642 |                         matching_terms: terms_clone.clone(),
    |                                         ^^^^^^^^^^^^^^^^^^^ expected `SmallVec<Arc<str>, 8>`, found `Vec<Arc<str>>`
    |
    = note: expected struct `SmallVec<Arc<str>, 8>`
               found struct `Vec<Arc<str>>`
help: call `Into::into` on this expression to convert `Vec<Arc<str>>` into `SmallVec<Arc<str>, 8>`
    |
642 |                         matching_terms: terms_clone.clone().into(),
    |                                                            +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:646:31
    |
646 |                         tags: vec![],
    |                               ^^^^^^ expected `SmallVec<Arc<str>, 4>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<Arc<str>, 4>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<Arc<str>, 4>`
    |
646 |                         tags: vec![].into(),
    |                                     +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:647:34
    |
647 |                         context: vec![],
    |                                  ^^^^^^ expected `SmallVec<SearchChatMessage, 6>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<SearchChatMessage, 6>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<SearchChatMessage, 6>`
    |
647 |                         context: vec![].into(),
    |                                        +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:648:42
    |
648 |                         match_positions: vec![],
    |                                          ^^^^^^ expected `SmallVec<MatchPosition, 16>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<MatchPosition, 16>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<MatchPosition, 16>`
    |
648 |                         match_positions: vec![].into(),
    |                                                +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:678:41
    |
678 |                         matching_terms: terms_clone.clone(),
    |                                         ^^^^^^^^^^^^^^^^^^^ expected `SmallVec<Arc<str>, 8>`, found `Vec<Arc<str>>`
    |
    = note: expected struct `SmallVec<Arc<str>, 8>`
               found struct `Vec<Arc<str>>`
help: call `Into::into` on this expression to convert `Vec<Arc<str>>` into `SmallVec<Arc<str>, 8>`
    |
678 |                         matching_terms: terms_clone.clone().into(),
    |                                                            +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:682:31
    |
682 |                         tags: vec![],
    |                               ^^^^^^ expected `SmallVec<Arc<str>, 4>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<Arc<str>, 4>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<Arc<str>, 4>`
    |
682 |                         tags: vec![].into(),
    |                                     +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:683:34
    |
683 |                         context: vec![],
    |                                  ^^^^^^ expected `SmallVec<SearchChatMessage, 6>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<SearchChatMessage, 6>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<SearchChatMessage, 6>`
    |
683 |                         context: vec![].into(),
    |                                        +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:684:42
    |
684 |                         match_positions: vec![],
    |                                          ^^^^^^ expected `SmallVec<MatchPosition, 16>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<MatchPosition, 16>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<MatchPosition, 16>`
    |
684 |                         match_positions: vec![].into(),
    |                                                +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:713:45
    |
713 | ...                   matching_terms: vec![term_clone.clone()],
    |                                       ^^^^^^^^^^^^^^^^^^^^^^^^ expected `SmallVec<Arc<str>, 8>`, found `Vec<Arc<str>>`
    |
    = note: expected struct `SmallVec<Arc<str>, 8>`
               found struct `Vec<Arc<str>>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<Arc<str>>` into `SmallVec<Arc<str>, 8>`
    |
713 |                             matching_terms: vec![term_clone.clone()].into(),
    |                                                                     +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:718:35
    |
718 | ...                   tags: vec![],
    |                             ^^^^^^ expected `SmallVec<Arc<str>, 4>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<Arc<str>, 4>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<Arc<str>, 4>`
    |
718 |                             tags: vec![].into(),
    |                                         +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:719:38
    |
719 | ...                   context: vec![],
    |                                ^^^^^^ expected `SmallVec<SearchChatMessage, 6>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<SearchChatMessage, 6>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<SearchChatMessage, 6>`
    |
719 |                             context: vec![].into(),
    |                                            +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:720:46
    |
720 | ...                   match_positions: vec![],
    |                                        ^^^^^^ expected `SmallVec<MatchPosition, 16>`, found `Vec<_>`
    |
    = note: expected struct `SmallVec<MatchPosition, 16>`
               found struct `Vec<_>`
    = note: this error originates in the macro `vec` (in Nightly builds, run with -Z macro-backtrace for more info)
help: call `Into::into` on this expression to convert `Vec<_>` into `SmallVec<MatchPosition, 16>`
    |
720 |                             match_positions: vec![].into(),
    |                                                    +++++++

error[E0609]: no field `statistics` on type `ChatSearchIndex`
   --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:988:43
    |
988 |             if let Ok(stats) = self_clone.statistics.try_read() {
    |                                           ^^^^^^^^^^ unknown field
    |
    = note: available fields are: `inverted_index`, `document_store`, `term_frequencies`, `document_count`, `query_counter` ... and 8 others

error[E0599]: no method named `try_read` found for struct `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>` in the current scope
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1227:51
     |
1227 |         let rules = match self.auto_tagging_rules.try_read() {
     |                                                   ^^^^^^^^ method not found in `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>`

error[E0599]: no method named `try_write` found for struct `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>` in the current scope
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1313:55
     |
1313 |         let mut rules = match self.auto_tagging_rules.try_write() {
     |                                                       ^^^^^^^^^ method not found in `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>`

error[E0599]: no method named `try_write` found for struct `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>` in the current scope
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1318:47
     |
1318 |                 match self.auto_tagging_rules.try_write() {
     |                                               ^^^^^^^^^ method not found in `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>`

error[E0599]: no method named `try_write` found for struct `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>` in the current scope
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1356:55
     |
1356 |         let mut rules = match self.auto_tagging_rules.try_write() {
     |                                                       ^^^^^^^^^ method not found in `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>`

error[E0599]: no method named `try_write` found for struct `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>` in the current scope
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1361:47
     |
1361 |                 match self.auto_tagging_rules.try_write() {
     |                                               ^^^^^^^^^ method not found in `Arc<SkipMap<Arc<str>, Vec<Arc<str>>>>`

error[E0277]: the trait bound `AtomicUsize: Clone` is not satisfied
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1474:5
     |
1469 | #[derive(Clone)]
     |          ----- in this derive macro expansion
...
1474 |     total_exports: CachePadded<AtomicUsize>,
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicUsize`
     |
     = note: required for `CachePadded<AtomicUsize>` to implement `Clone`

error[E0277]: the trait bound `AtomicUsize: Clone` is not satisfied
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1475:5
     |
1469 | #[derive(Clone)]
     |          ----- in this derive macro expansion
...
1475 |     total_messages_exported: CachePadded<AtomicUsize>,
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicUsize`
     |
     = note: required for `CachePadded<AtomicUsize>` to implement `Clone`

error[E0277]: the trait bound `AtomicU64: Clone` is not satisfied
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1476:5
     |
1469 | #[derive(Clone)]
     |          ----- in this derive macro expansion
...
1476 |     average_export_time: CachePadded<AtomicU64>, // Store f64 as bits
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicU64`
     |
     = note: required for `CachePadded<AtomicU64>` to implement `Clone`

error[E0277]: the trait bound `AtomicU64: Clone` is not satisfied
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1477:5
     |
1469 | #[derive(Clone)]
     |          ----- in this derive macro expansion
...
1477 |     last_export_time: CachePadded<AtomicU64>,
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicU64`
     |
     = note: required for `CachePadded<AtomicU64>` to implement `Clone`

error[E0609]: no field `export_statistics` on type `HistoryExporter`
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:1624:47
     |
1624 |             if let Ok(mut stats) = self_clone.export_statistics.try_write() {
     |                                               ^^^^^^^^^^^^^^^^^ unknown field
     |
     = note: available fields are: `export_counter`, `total_exports`, `total_messages_exported`, `average_export_time`, `last_export_time`

error[E0277]: the trait bound `AtomicUsize: Clone` is not satisfied
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:2090:5
     |
2081 | #[derive(Clone)]
     |          ----- in this derive macro expansion
...
2090 |     total_operations: CachePadded<AtomicUsize>,
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicUsize`
     |
     = note: required for `CachePadded<AtomicUsize>` to implement `Clone`

error[E0277]: the trait bound `AtomicU64: Clone` is not satisfied
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:2091:5
     |
2081 | #[derive(Clone)]
     |          ----- in this derive macro expansion
...
2091 |     system_uptime: CachePadded<AtomicU64>,
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicU64`
     |
     = note: required for `CachePadded<AtomicU64>` to implement `Clone`

error[E0308]: mismatched types
    --> packages/fluent-ai-candle/src/types/candle_chat/search.rs:2180:31
     |
2180 |                 result.tags = self_clone.tagger.get_message_tags(&message_id);
     |                 -----------   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected `SmallVec<Arc<str>, 4>`, found `Vec<Arc<str>>`
     |                 |
     |                 expected due to the type of this binding
     |
     = note: expected struct `SmallVec<Arc<str>, 4>`
                found struct `Vec<Arc<str>>`
help: call `Into::into` on this expression to convert `Vec<Arc<str>>` into `SmallVec<Arc<str>, 4>`
     |
2180 |                 result.tags = self_clone.tagger.get_message_tags(&message_id).into();
     |                                                                              +++++++

error[E0223]: ambiguous associated type
   --> packages/fluent-ai-candle/src/types/candle_context/extraction/extractor.rs:229:33
    |
229 |             let default_chunk = crate::types::CandleCompletionChunk::Complete {
    |                                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
help: if there were a trait named `Example` with associated type `Complete` implemented for `candle_completion::streaming::CandleStreamingChoice`, you could use the fully-qualified path
    |
229 -             let default_chunk = crate::types::CandleCompletionChunk::Complete {
229 +             let default_chunk = <candle_completion::streaming::CandleStreamingChoice as Example>::Complete {
    |

warning: unreachable statement
   --> packages/fluent-ai-candle/src/types/candle_context/provider.rs:445:17
    |
442 |                   fluent_ai_async::handle_error!(error, "File context validation failed");
    |                   ----------------------------------------------------------------------- any code following this expression is unreachable
...
445 | /                 if let Some(ref events) = event_sender {
446 | |                     let _ = events.send(ContextEvent::ValidationFailed {
447 | |                         validation_type: "FileContext".to_string(),
448 | |                         error: error.to_string(),
449 | |                         timestamp: SystemTime::now(),
450 | |                     });
451 | |                 }
    | |_________________^ unreachable statement
    |
    = note: `#[warn(unreachable_code)]` on by default

warning: unreachable expression
   --> packages/fluent-ai-candle/src/types/candle_context/provider.rs:476:21
    |
473 |                       fluent_ai_async::handle_error!(error, "File document loading failed");
    |                       --------------------------------------------------------------------- any code following this expression is unreachable
...
476 | /                     if let Some(ref events) = event_sender {
477 | |                         let _ = events.send(ContextEvent::ContextLoadFailed {
478 | |                             context_type: "File".to_string(),
479 | |                             source: context.path.clone(),
...   |
482 | |                         });
483 | |                     }
    | |_____________________^ unreachable expression

warning: unreachable statement
   --> packages/fluent-ai-candle/src/types/candle_context/provider.rs:923:29
    |
917 | / ...                   fluent_ai_async::handle_error!(
918 | | ...                       ContextError::ContextNotFound(
919 | | ...                           "GitHub repository URL is required".to_string()
920 | | ...                       ),
921 | | ...                       "GitHub repository URL missing"
922 | | ...                   );
    | |_______________________- any code following this expression is unreachable
923 |   ...                   return;
    |                         ^^^^^^^ unreachable statement

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:202:36
    |
202 |             return Err(ModelError::InvalidConfiguration(
    |                                    ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:208:36
    |
208 |             return Err(ModelError::InvalidConfiguration(
    |                                    ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:215:40
    |
215 |                 return Err(ModelError::InvalidConfiguration(
    |                                        ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:223:40
    |
223 |                 return Err(ModelError::InvalidConfiguration(
    |                                        ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:230:36
    |
230 |             return Err(ModelError::InvalidConfiguration(
    |                                    ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:348:29
    |
348 |                 ModelError::InvalidConfiguration("provider_name is required".into())
    |                             ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:352:44
    |
352 |                 .ok_or_else(|| ModelError::InvalidConfiguration("name is required".into()))?,
    |                                            ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:395:36
    |
395 |             return Err(ModelError::InvalidConfiguration(
    |                                    ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant named `ModelAlreadyExists` found for enum `model::error::ModelError`
   --> packages/fluent-ai-candle/src/types/candle_model/info.rs:401:36
    |
401 |             return Err(ModelError::ModelAlreadyExists {
    |                                    ^^^^^^^^^^^^^^^^^^ variant not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant `ModelAlreadyExists` not found here

error[E0599]: no variant named `ModelAlreadyExists` found for enum `model::error::ModelError`
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:105:36
    |
105 |             return Err(ModelError::ModelAlreadyExists {
    |                                    ^^^^^^^^^^^^^^^^^^ variant not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant `ModelAlreadyExists` not found here

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:155:36
    |
155 |             return Err(ModelError::InvalidConfiguration(
    |                                    ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant named `ModelNotFound` found for enum `model::error::ModelError`
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:180:40
    |
180 |             .ok_or_else(|| ModelError::ModelNotFound {
    |                                        ^^^^^^^^^^^^^ variant not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant `ModelNotFound` not found here

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:243:33
    |
243 |                 Err(ModelError::InvalidConfiguration(
    |                                 ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:247:37
    |
247 |             None => Err(ModelError::InvalidConfiguration(
    |                                     ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `InvalidConfiguration` found for enum `model::error::ModelError` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:285:25
    |
285 |         Err(ModelError::InvalidConfiguration(Cow::Owned(format!(
    |                         ^^^^^^^^^^^^^^^^^^^^ variant or associated item not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant or associated item `InvalidConfiguration` not found for this enum
    |
note: if you're trying to build a new `model::error::ModelError` consider using one of the following associated functions:
      model::error::ModelError::candle
      model::error::ModelError::initialization_failed
      model::error::ModelError::inference
   --> packages/fluent-ai-candle/src/model/error.rs:111:5
    |
111 |     pub fn candle(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
118 |     pub fn initialization_failed(reason: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
125 |     pub fn inference(message: impl Into<String>) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant named `ModelNotFound` found for enum `model::error::ModelError`
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:308:40
    |
308 |             .ok_or_else(|| ModelError::ModelNotFound {
    |                                        ^^^^^^^^^^^^^ variant not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant `ModelNotFound` not found here

error[E0599]: no variant named `ModelNotFound` found for enum `model::error::ModelError`
   --> packages/fluent-ai-candle/src/types/candle_model/registry.rs:331:40
    |
331 |             .ok_or_else(|| ModelError::ModelNotFound {
    |                                        ^^^^^^^^^^^^^ variant not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant `ModelNotFound` not found here

error[E0277]: the trait bound `model::registry::ModelRegistry: Clone` is not satisfied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:182:5
    |
180 | #[derive(Clone)]
    |          ----- in this derive macro expansion
181 | pub struct ModelResolver {
182 |     registry: ModelRegistry,
    |     ^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `model::registry::ModelRegistry`

error[E0599]: no method named `clone` found for struct `model::registry::ModelRegistry` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:240:38
    |
240 |         let registry = self.registry.clone();
    |                                      ^^^^^ method not found in `model::registry::ModelRegistry`
    |
   ::: packages/fluent-ai-candle/src/model/registry.rs:11:1
    |
11  | pub struct ModelRegistry {
    | ------------------------ method `clone` not found for this struct
    |
    = help: items from traits can only be used if the trait is implemented and in scope
    = note: the following trait defines an item `clone`, perhaps you need to implement it:
            candidate #1: `Clone`

error[E0107]: method takes 0 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:269:47
    |
269 |             if let Ok(Some(model)) = registry.get::<M>(provider, model_name) {
    |                                               ^^^----- help: remove the unnecessary generics
    |                                               |
    |                                               expected 0 generic arguments
    |
note: method defined here, with 0 generic parameters
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^

error[E0061]: this method takes 1 argument but 2 arguments were supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:269:47
    |
269 |             if let Ok(Some(model)) = registry.get::<M>(provider, model_name) {
    |                                               ^^^^^^^^           ---------- unexpected argument #2 of type `&'a str`
    |
note: method defined here
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^
help: remove the extra argument
    |
269 -             if let Ok(Some(model)) = registry.get::<M>(provider, model_name) {
269 +             if let Ok(Some(model)) = registry.get::<M>(provider) {
    |

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:269:23
    |
269 |             if let Ok(Some(model)) = registry.get::<M>(provider, model_name) {
    |                       ^^^^^^^^^^^    --------------------------------------- this expression has type `std::result::Result<Arc<dyn types::candle_model::traits::Model>, RegistryError>`
    |                       |
    |                       expected `Arc<dyn Model>`, found `Option<_>`
    |
    = note: expected struct `Arc<dyn types::candle_model::traits::Model>`
                 found enum `std::option::Option<_>`

error[E0107]: method takes 0 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:282:47
    |
282 |             if let Ok(Some(model)) = registry.get::<M>(default_provider, model_name) {
    |                                               ^^^----- help: remove the unnecessary generics
    |                                               |
    |                                               expected 0 generic arguments
    |
note: method defined here, with 0 generic parameters
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^

error[E0061]: this method takes 1 argument but 2 arguments were supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:282:47
    |
282 |             if let Ok(Some(model)) = registry.get::<M>(default_provider, model_name) {
    |                                               ^^^^^^^^                   ---------- unexpected argument #2 of type `&'a str`
    |
note: method defined here
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^
help: remove the extra argument
    |
282 -             if let Ok(Some(model)) = registry.get::<M>(default_provider, model_name) {
282 +             if let Ok(Some(model)) = registry.get::<M>(default_provider) {
    |

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:282:23
    |
282 |             if let Ok(Some(model)) = registry.get::<M>(default_provider, model_name) {
    |                       ^^^^^^^^^^^    ----------------------------------------------- this expression has type `std::result::Result<Arc<dyn types::candle_model::traits::Model>, RegistryError>`
    |                       |
    |                       expected `Arc<dyn Model>`, found `Option<_>`
    |
    = note: expected struct `Arc<dyn types::candle_model::traits::Model>`
                 found enum `std::option::Option<_>`

error[E0107]: method takes 0 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:296:47
    |
296 |             if let Ok(Some(model)) = registry.get::<M>(provider, model_name_alias) {
    |                                               ^^^----- help: remove the unnecessary generics
    |                                               |
    |                                               expected 0 generic arguments
    |
note: method defined here, with 0 generic parameters
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^

error[E0061]: this method takes 1 argument but 2 arguments were supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:296:47
    |
296 |             if let Ok(Some(model)) = registry.get::<M>(provider, model_name_alias) {
    |                                               ^^^^^^^^           ---------------- unexpected argument #2 of type `&std::string::String`
    |
note: method defined here
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^
help: remove the extra argument
    |
296 -             if let Ok(Some(model)) = registry.get::<M>(provider, model_name_alias) {
296 +             if let Ok(Some(model)) = registry.get::<M>(provider) {
    |

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:296:23
    |
296 |             if let Ok(Some(model)) = registry.get::<M>(provider, model_name_alias) {
    |                       ^^^^^^^^^^^    --------------------------------------------- this expression has type `std::result::Result<Arc<dyn types::candle_model::traits::Model>, RegistryError>`
    |                       |
    |                       expected `Arc<dyn Model>`, found `Option<_>`
    |
    = note: expected struct `Arc<dyn types::candle_model::traits::Model>`
                 found enum `std::option::Option<_>`

error[E0107]: method takes 0 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:316:51
    |
316 |                 if let Ok(Some(model)) = registry.get::<M>(&rule.provider, &rule.target) {
    |                                                   ^^^----- help: remove the unnecessary generics
    |                                                   |
    |                                                   expected 0 generic arguments
    |
note: method defined here, with 0 generic parameters
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^

error[E0061]: this method takes 1 argument but 2 arguments were supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:316:51
    |
316 |                 if let Ok(Some(model)) = registry.get::<M>(&rule.provider, &rule.target) {
    |                                                   ^^^^^^^^                 ------------ unexpected argument #2 of type `&std::string::String`
    |
note: method defined here
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^
help: remove the extra argument
    |
316 -                 if let Ok(Some(model)) = registry.get::<M>(&rule.provider, &rule.target) {
316 +                 if let Ok(Some(model)) = registry.get::<M>(&rule.provider) {
    |

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:316:27
    |
316 |                 if let Ok(Some(model)) = registry.get::<M>(&rule.provider, &rule.target) {
    |                           ^^^^^^^^^^^    ----------------------------------------------- this expression has type `std::result::Result<Arc<dyn types::candle_model::traits::Model>, RegistryError>`
    |                           |
    |                           expected `Arc<dyn Model>`, found `Option<_>`
    |
    = note: expected struct `Arc<dyn types::candle_model::traits::Model>`
                 found enum `std::option::Option<_>`

error[E0107]: method takes 0 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:351:26
    |
351 |                         .get::<M>(&resolution.provider, &resolution.model)
    |                          ^^^----- help: remove the unnecessary generics
    |                          |
    |                          expected 0 generic arguments
    |
note: method defined here, with 0 generic parameters
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^

error[E0061]: this method takes 1 argument but 2 arguments were supplied
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:351:26
    |
351 |                         .get::<M>(&resolution.provider, &resolution.model)
    |                          ^^^^^^^^                       ----------------- unexpected argument #2 of type `&std::string::String`
    |
note: method defined here
   --> packages/fluent-ai-candle/src/model/registry.rs:49:12
    |
49  |     pub fn get(&self, name: &str) -> Result<Arc<dyn Model>, RegistryError> {
    |            ^^^
help: remove the extra argument
    |
351 -                         .get::<M>(&resolution.provider, &resolution.model)
351 +                         .get::<M>(&resolution.provider)
    |

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:353:28
    |
349 |                       match resolver
    |  ___________________________-
350 | |                         .registry
351 | |                         .get::<M>(&resolution.provider, &resolution.model)
    | |__________________________________________________________________________- this expression has type `std::result::Result<Arc<dyn types::candle_model::traits::Model>, RegistryError>`
352 |                       {
353 |                           Ok(Some(model)) => {
    |                              ^^^^^^^^^^^ expected `Arc<dyn Model>`, found `Option<_>`
    |
    = note: expected struct `Arc<dyn types::candle_model::traits::Model>`
                 found enum `std::option::Option<_>`

error[E0599]: no method named `find_all` found for reference `&model::registry::ModelRegistry` in the current scope
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:402:35
    |
402 |         let all_models = registry.find_all::<M>();
    |                                   ^^^^^^^^ method not found in `&model::registry::ModelRegistry`

error[E0599]: no variant named `ModelNotFound` found for enum `model::error::ModelError`
   --> packages/fluent-ai-candle/src/types/candle_model/resolver.rs:423:29
    |
423 |             Err(ModelError::ModelNotFound {
    |                             ^^^^^^^^^^^^^ variant not found in `model::error::ModelError`
    |
   ::: packages/fluent-ai-candle/src/model/error.rs:48:1
    |
48  | pub enum ModelError {
    | ------------------- variant `ModelNotFound` not found here

error[E0369]: binary operation `==` cannot be applied to type `Vec<message::types::CandleMessage>`
   --> packages/fluent-ai-candle/src/types/candle_model/traits.rs:148:5
    |
145 | #[derive(Debug, Clone, Serialize, Deserialize, PartialEq)]
    |                                                --------- in this derive macro expansion
...
148 |     pub messages: Vec<crate::types::candle_chat::message::CandleMessage>,
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    |
note: an implementation of `PartialEq` might be missing for `message::types::CandleMessage`
   --> packages/fluent-ai-candle/src/types/candle_chat/message/mod.rs:19:5
    |
19  |     pub struct CandleMessage {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^ must implement `PartialEq`
help: consider annotating `message::types::CandleMessage` with `#[derive(PartialEq)]`
   --> packages/fluent-ai-candle/src/types/candle_chat/message/mod.rs:19:5
    |
19  +     #[derive(PartialEq)]
20  |     pub struct CandleMessage {
    |

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:265:20
    |
262 |     ) -> AsyncTask<EngineResult<CandleCompletionResponse<'static>>> {
    |          ---------------------------------------------------------- expected `AsyncTask<std::result::Result<completion_response::CompletionResponse<'static>, EngineError>>` because of return type
...
265 |             return spawn_task(move || Err(e));
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^ expected `AsyncTask<Result<..., ...>>`, found `AsyncTask<Result<_, ValidationError>>`
    |
    = note: expected struct `AsyncTask<std::result::Result<completion_response::CompletionResponse<'static>, EngineError>>`
               found struct `AsyncTask<std::result::Result<_, model::error::ValidationError>>`

error[E0609]: no field `prompt` on type `candle_completion::request::CandleCompletionRequest`
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:283:30
    |
283 |         let prompt = request.prompt.to_string();
    |                              ^^^^^^ unknown field
    |
    = note: available fields are: `system_prompt`, `chat_history`, `documents`, `tools`, `temperature` ... and 3 others

error[E0599]: `std::string::String` is not an iterator
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:284:51
    |
284 |         let system_prompt = request.system_prompt.map(|s| s.to_string());
    |                                                   ^^^ `std::string::String` is not an iterator
    |
   ::: /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/alloc/src/string.rs:360:1
    |
360 | pub struct String {
    | ----------------- doesn't satisfy `std::string::String: Iterator`
    |
    = note: the following trait bounds were not satisfied:
            `std::string::String: Iterator`
            which is required by `&mut std::string::String: Iterator`
            `str: Iterator`
            which is required by `&mut str: Iterator`
    = help: items from traits can only be used if the trait is in scope
help: trait `Parser` which provides `map` is implemented but not in scope; perhaps you want to import it
    |
7   + use winnow::parser::Parser;
    |

error[E0609]: no field `conversation_history` on type `candle_completion::request::CandleCompletionRequest`
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:286:14
    |
286 |             .conversation_history
    |              ^^^^^^^^^^^^^^^^^^^^ unknown field
    |
    = note: available fields are: `system_prompt`, `chat_history`, `documents`, `tools`, `temperature` ... and 3 others

error[E0599]: the method `to_string` exists for reference `&tool_definition::ToolDefinition`, but its trait bounds were not satisfied
    --> packages/fluent-ai-candle/src/types/candle_engine.rs:290:65
     |
290  |         let tools: Vec<String> = request.tools.iter().map(|s| s.to_string()).collect();
     |                                                                 ^^^^^^^^^ method cannot be called on `&tool_definition::ToolDefinition` due to unsatisfied trait bounds
     |
    ::: packages/fluent-ai-candle/src/types/candle_completion/tool_definition.rs:8:1
     |
8    | pub struct ToolDefinition {
     | ------------------------- doesn't satisfy `tool_definition::ToolDefinition: ToString` or `tool_definition::ToolDefinition: std::fmt::Display`
     |
     = note: the following trait bounds were not satisfied:
             `tool_definition::ToolDefinition: std::fmt::Display`
             which is required by `tool_definition::ToolDefinition: ToString`
             `&tool_definition::ToolDefinition: std::fmt::Display`
             which is required by `&tool_definition::ToolDefinition: ToString`
note: the trait `std::fmt::Display` must be implemented
    --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/fmt/mod.rs:1003:1
     |
1003 | pub trait Display: PointeeSized {
     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
     = help: items from traits can only be used if the trait is implemented and in scope
     = note: the following trait defines an item `to_string`, perhaps you need to implement it:
             candidate #1: `ToString`

error[E0609]: no field `metadata` on type `candle_completion::request::CandleCompletionRequest`
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:291:32
    |
291 |         let metadata = request.metadata.map(|s| s.to_string());
    |                                ^^^^^^^^ unknown field
    |
    = note: available fields are: `system_prompt`, `chat_history`, `documents`, `tools`, `temperature` ... and 3 others

error[E0609]: no field `prompt` on type `candle_completion::request::CandleCompletionRequest`
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:380:30
    |
380 |         let prompt = request.prompt.to_string();
    |                              ^^^^^^ unknown field
    |
    = note: available fields are: `system_prompt`, `chat_history`, `documents`, `tools`, `temperature` ... and 3 others

error[E0599]: `std::string::String` is not an iterator
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:381:51
    |
381 |         let system_prompt = request.system_prompt.map(|s| s.to_string());
    |                                                   ^^^ `std::string::String` is not an iterator
    |
   ::: /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/alloc/src/string.rs:360:1
    |
360 | pub struct String {
    | ----------------- doesn't satisfy `std::string::String: Iterator`
    |
    = note: the following trait bounds were not satisfied:
            `std::string::String: Iterator`
            which is required by `&mut std::string::String: Iterator`
            `str: Iterator`
            which is required by `&mut str: Iterator`
    = help: items from traits can only be used if the trait is in scope
help: trait `Parser` which provides `map` is implemented but not in scope; perhaps you want to import it
    |
7   + use winnow::parser::Parser;
    |

error[E0609]: no field `conversation_history` on type `candle_completion::request::CandleCompletionRequest`
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:383:14
    |
383 |             .conversation_history
    |              ^^^^^^^^^^^^^^^^^^^^ unknown field
    |
    = note: available fields are: `system_prompt`, `chat_history`, `documents`, `tools`, `temperature` ... and 3 others

error[E0599]: the method `to_string` exists for reference `&tool_definition::ToolDefinition`, but its trait bounds were not satisfied
    --> packages/fluent-ai-candle/src/types/candle_engine.rs:387:65
     |
387  |         let tools: Vec<String> = request.tools.iter().map(|s| s.to_string()).collect();
     |                                                                 ^^^^^^^^^ method cannot be called on `&tool_definition::ToolDefinition` due to unsatisfied trait bounds
     |
    ::: packages/fluent-ai-candle/src/types/candle_completion/tool_definition.rs:8:1
     |
8    | pub struct ToolDefinition {
     | ------------------------- doesn't satisfy `tool_definition::ToolDefinition: ToString` or `tool_definition::ToolDefinition: std::fmt::Display`
     |
     = note: the following trait bounds were not satisfied:
             `tool_definition::ToolDefinition: std::fmt::Display`
             which is required by `tool_definition::ToolDefinition: ToString`
             `&tool_definition::ToolDefinition: std::fmt::Display`
             which is required by `&tool_definition::ToolDefinition: ToString`
note: the trait `std::fmt::Display` must be implemented
    --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/fmt/mod.rs:1003:1
     |
1003 | pub trait Display: PointeeSized {
     | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
     = help: items from traits can only be used if the trait is implemented and in scope
     = note: the following trait defines an item `to_string`, perhaps you need to implement it:
             candidate #1: `ToString`

error[E0609]: no field `metadata` on type `candle_completion::request::CandleCompletionRequest`
   --> packages/fluent-ai-candle/src/types/candle_engine.rs:388:32
    |
388 |         let metadata = request.metadata.map(|s| s.to_string());
    |                                ^^^^^^^^ unknown field
    |
    = note: available fields are: `system_prompt`, `chat_history`, `documents`, `tools`, `temperature` ... and 3 others

error[E0560]: struct `CandleVarBuilder<'a>` has no field named `safetensors`
   --> packages/fluent-ai-candle/src/var_builder.rs:837:13
    |
837 |             safetensors: None,
    |             ^^^^^^^^^^^ `CandleVarBuilder<'a>` does not have this field
    |
    = note: available fields are: `safetensors_data`

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/var_builder.rs:839:30
    |
839 |             tensor_metadata: Arc::new(HashMap::new()),
    |                              ^^^^^^^^^^^^^^^^^^^^^^^^ expected `HashMap<String, TensorMetadata>`, found `Arc<HashMap<_, _>>`
    |
    = note: expected struct `HashMap<std::string::String, TensorMetadata>`
               found struct `Arc<HashMap<_, _>>`

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/var_builder.rs:864:29
    |
864 |                     length: num_bytes as u64,
    |                             ^^^^^^^^^^^^^^^^ expected `usize`, found `u64`

error[E0599]: no variant or associated item named `Msg` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:878:37
    |
878 |             return Err(CandleError::Msg("No paths provided".into()));
    |                                     ^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:19:1
    |
19  | pub enum CandleError {
    | -------------------- variant or associated item `Msg` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 18 others
   --> packages/fluent-ai-candle/src/error.rs:223:5
    |
223 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
229 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
235 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
241 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `Msg` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:897:39
    |
897 |             .map_err(|e| CandleError::Msg(format!("Invalid safetensors file: {}", e)))?;
    |                                       ^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:19:1
    |
19  | pub enum CandleError {
    | -------------------- variant or associated item `Msg` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 18 others
   --> packages/fluent-ai-candle/src/error.rs:223:5
    |
223 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
229 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
235 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
241 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0277]: the `?` operator can only be applied to values that implement `Try`
   --> packages/fluent-ai-candle/src/var_builder.rs:922:21
    |
922 |           let inner = VarBuilder::from_tensors(
    |  _____________________^
923 | |             safetensors_arc
924 | |                 .tensors()
925 | |                 .map(|(name, _)| (name.to_string(), safetensors_arc.tensor(name).unwrap()))
...   |
928 | |             &config.device,
929 | |         )?;
    | |__________^ the `?` operator cannot be applied to type `VarBuilderArgs<'_, Box<dyn SimpleBackend>>`
    |
    = help: the trait `Try` is not implemented for `VarBuilderArgs<'_, Box<dyn SimpleBackend>>`

error[E0609]: no field `safetensors` on type `CandleVarBuilder<'_>`
   --> packages/fluent-ai-candle/src/var_builder.rs:932:17
    |
932 |         builder.safetensors = Some(safetensors_arc);
    |                 ^^^^^^^^^^^ unknown field
    |
    = note: available fields are: `inner`, `metadata`, `config`, `stats`, `created_at_nanos` ... and 5 others

error[E0599]: no method named `populate_metadata_safe` found for struct `CandleVarBuilder<'_>` in the current scope
    --> packages/fluent-ai-candle/src/var_builder.rs:938:17
     |
117  | pub struct CandleVarBuilder<'a> {
     | ------------------------------- method `populate_metadata_safe` not found for this struct
...
938  |         builder.populate_metadata_safe(&builder.inner, &mut builder.metadata)?;
     |         --------^^^^^^^^^^^^^^^^^^^^^^---------------------------------------
     |         |       |
     |         |       this is an associated function, not a method
     |         help: use associated function syntax instead: `CandleVarBuilder::<'_>::populate_metadata_safe(&builder.inner, &mut builder.metadata)`
     |
     = note: found the following associated functions; to be used as methods, functions must have a `self` parameter
note: the candidate is defined in an impl for the type `CandleVarBuilder<'a>`
    --> packages/fluent-ai-candle/src/var_builder.rs:1131:5
     |
1131 |     fn populate_metadata_safe(inner: &VarBuilder<'a>, metadata: &mut ModelMetadata) -> Result<()> {
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0277]: the `?` operator can only be applied to values that implement `Try`
   --> packages/fluent-ai-candle/src/var_builder.rs:948:21
    |
948 |         let inner = VarBuilder::from_tensors(tensors.clone(), config.dtype, &config.device)?;
    |                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the `?` operator cannot be applied to type `VarBuilderArgs<'_, Box<dyn SimpleBackend>>`
    |
    = help: the trait `Try` is not implemented for `VarBuilderArgs<'_, Box<dyn SimpleBackend>>`

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/var_builder.rs:952:35
    |
952 |         builder.tensor_metadata = Arc::new(tensor_metadata);
    |         -----------------------   ^^^^^^^^^^^^^^^^^^^^^^^^^ expected `HashMap<String, TensorMetadata>`, found `Arc<HashMap<String, TensorMetadata>>`
    |         |
    |         expected due to the type of this binding
    |
    = note: expected struct `HashMap<_, _>`
               found struct `Arc<HashMap<_, _>>`

error[E0599]: no method named `populate_metadata_from_tensors` found for struct `CandleVarBuilder<'_>` in the current scope
    --> packages/fluent-ai-candle/src/var_builder.rs:955:17
     |
117  | pub struct CandleVarBuilder<'a> {
     | ------------------------------- method `populate_metadata_from_tensors` not found for this struct
...
955  |         builder.populate_metadata_from_tensors(&tensors, &mut builder.metadata)?;
     |         --------^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^---------------------------------
     |         |       |
     |         |       this is an associated function, not a method
     |         help: use associated function syntax instead: `CandleVarBuilder::<'_>::populate_metadata_from_tensors(&tensors, &mut builder.metadata)`
     |
     = note: found the following associated functions; to be used as methods, functions must have a `self` parameter
note: the candidate is defined in an impl for the type `CandleVarBuilder<'a>`
    --> packages/fluent-ai-candle/src/var_builder.rs:1152:5
     |
1152 | /     fn populate_metadata_from_tensors(
1153 | |         tensors: &std::collections::HashMap<String, Tensor>,
1154 | |         metadata: &mut ModelMetadata,
1155 | |     ) -> Result<()> {
     | |___________________^

error[E0599]: no function or associated item named `default` found for struct `AsyncTask` in the current scope
  --> packages/fluent-ai-candle/src/builders/candle_chat/candle_chatbot.rs:33:30
   |
33 |     let executor = Executor::default();
   |                              ^^^^^^^ function or associated item not found in `AsyncTask<_>`
   |
note: if you're trying to build a new `AsyncTask<_>` consider using one of the following associated functions:
      AsyncTask::<T>::new
      AsyncTask::<T>::from_value
  --> /Volumes/samsung_t9/fluent-ai/packages/fluent-ai-async/src/task.rs:22:5
   |
22 |     pub fn new(rx: Receiver<T>) -> Self {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
28 |     pub fn from_value(value: T) -> Self {
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no method named `chat` found for type parameter `C` in the current scope
  --> packages/fluent-ai-candle/src/builders/candle_chat/candle_chatbot.rs:59:28
   |
28 | pub fn cli_chatbot<C>(chatbot: C) -> Result<(), CandleCompletionError>
   |                    - method `chat` not found for this type parameter
...
59 |         let task = chatbot.chat(prompt, chat_log.clone()); // AsyncTask<Result<_,_>>
   |                            ^^^^ method not found in `C`

error[E0599]: no function or associated item named `user` found for struct `message::types::CandleMessage` in the current scope
  --> packages/fluent-ai-candle/src/builders/candle_chat/candle_chatbot.rs:77:38
   |
77 |         chat_log.push(CandleMessage::user(prompt));
   |                                      ^^^^ function or associated item not found in `message::types::CandleMessage`
   |
  ::: packages/fluent-ai-candle/src/types/candle_chat/message/mod.rs:19:5
   |
19 |     pub struct CandleMessage {
   |     ------------------------ function or associated item `user` not found for this struct
   |
note: if you're trying to build a new `message::types::CandleMessage`, consider using `message::types::CandleMessage::new` which returns `message::types::CandleMessage`
  --> packages/fluent-ai-candle/src/types/candle_chat/message/mod.rs:58:9
   |
58 |         pub fn new(id: u64, role: CandleMessageRole, content: &[u8]) -> Self {
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no function or associated item named `assistant` found for struct `message::types::CandleMessage` in the current scope
  --> packages/fluent-ai-candle/src/builders/candle_chat/candle_chatbot.rs:78:38
   |
78 |         chat_log.push(CandleMessage::assistant(&reply));
   |                                      ^^^^^^^^^ function or associated item not found in `message::types::CandleMessage`
   |
  ::: packages/fluent-ai-candle/src/types/candle_chat/message/mod.rs:19:5
   |
19 |     pub struct CandleMessage {
   |     ------------------------ function or associated item `assistant` not found for this struct
   |
note: if you're trying to build a new `message::types::CandleMessage`, consider using `message::types::CandleMessage::new` which returns `message::types::CandleMessage`
  --> packages/fluent-ai-candle/src/types/candle_chat/message/mod.rs:58:9
   |
58 |         pub fn new(id: u64, role: CandleMessageRole, content: &[u8]) -> Self {
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `LogitsProcessor`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:16:9
   |
16 |         LogitsProcessor,
   |         ^^^^^^^^^^^^^^^
   |
   = note: `#[warn(unused_imports)]` on by default

error[E0716]: temporary value dropped while borrowed
   --> packages/fluent-ai-candle/src/logits.rs:143:54
    |
143 |             .map_err(|e| CandleError::configuration(&e.to_string()))?;
    |                          ----------------------------^^^^^^^^^^^^^-
    |                          |                           |            |
    |                          |                           |            temporary value is freed at the end of this statement
    |                          |                           creates a temporary value which is freed while still in use
    |                          argument requires that borrow lasts for `'static`

error[E0716]: temporary value dropped while borrowed
   --> packages/fluent-ai-candle/src/logits.rs:159:58
    |
159 |             .map_err(|e| CandleError::generation_failed(&e.to_string()))
    |                          --------------------------------^^^^^^^^^^^^^-
    |                          |                               |            |
    |                          |                               |            temporary value is freed at the end of this statement
    |                          |                               creates a temporary value which is freed while still in use
    |                          argument requires that borrow lasts for `'static`

error[E0716]: temporary value dropped while borrowed
   --> packages/fluent-ai-candle/src/logits.rs:166:54
    |
166 |             .map_err(|e| CandleError::configuration(&e.to_string()))?;
    |                          ----------------------------^^^^^^^^^^^^^-
    |                          |                           |            |
    |                          |                           |            temporary value is freed at the end of this statement
    |                          |                           creates a temporary value which is freed while still in use
    |                          argument requires that borrow lasts for `'static`

error[E0716]: temporary value dropped while borrowed
   --> packages/fluent-ai-candle/src/logits.rs:190:54
    |
190 |             .map_err(|e| CandleError::configuration(&e.to_string()))?;
    |                          ----------------------------^^^^^^^^^^^^^-
    |                          |                           |            |
    |                          |                           |            temporary value is freed at the end of this statement
    |                          |                           creates a temporary value which is freed while still in use
    |                          argument requires that borrow lasts for `'static`

error[E0502]: cannot borrow `shards` as mutable because it is also borrowed as immutable
   --> packages/fluent-ai-candle/src/model/fluent/kimi_k2/loader.rs:109:40
    |
109 |   ...                   if shards.try_push(shard).is_ok() {
    |                            ^^^^^^^^^^^^^^^^^^^^^^ mutable borrow occurs here
110 |   ...                       // Send notification that shard is ready (without duplicating the shard)
111 |   ...                       let _ = y.send(LoaderEvent::Progress { 
    |  ___________________________________-
112 | | ...                           shard_idx: current_idx, 
113 | | ...                           bytes: &shards[current_idx].bytes[..]
    | |                                       ------ immutable borrow occurs here
114 | | ...                       });
    | |____________________________- argument requires that `shards` is borrowed for `'static`

error[E0597]: `shards` does not live long enough
   --> packages/fluent-ai-candle/src/model/fluent/kimi_k2/loader.rs:113:53
    |
72  |           let mut shards: ArrayVec<ModelShard, MAX_SHARDS> = ArrayVec::new();
    |               ---------- binding `shards` declared here
...
111 |                                           let _ = y.send(LoaderEvent::Progress { 
    |  _________________________________________________-
112 | |                                             shard_idx: current_idx, 
113 | |                                             bytes: &shards[current_idx].bytes[..]
    | |                                                     ^^^^^^ borrowed value does not live long enough
114 | |                                         });
    | |__________________________________________- argument requires that `shards` is borrowed for `'static`
...
134 |       })
    |       - `shards` dropped here while still borrowed

error[E0505]: cannot move out of `shards` because it is borrowed
   --> packages/fluent-ai-candle/src/model/fluent/kimi_k2/loader.rs:127:56
    |
72  |         let mut shards: ArrayVec<ModelShard, MAX_SHARDS> = ArrayVec::new();
    |             ---------- binding `shards` declared here
...
113 |                                             bytes: &shards[current_idx].bytes[..]
    |                                                     ------ borrow of `shards` occurs here
...
127 |                 let _ = y.send(LoaderEvent::Complete { shards });
    |                           ----                         ^^^^^^ move out of `shards` occurs here
    |                           |
    |                           borrow later used by call

error[E0521]: borrowed data escapes outside of function
   --> packages/fluent-ai-candle/src/model/fluent/kimi_k2/loader.rs:58:5
    |
57  |   pub fn load_model(config: &KimiK2Config) -> AsyncStream<LoaderEvent<'static>> {
    |                     ------  - let's call the lifetime of this reference `'1`
    |                     |
    |                     `config` is a reference that is only valid in the function body
58  | /     AsyncStream::with_channel(move |y: fluent_ai_async::AsyncStreamSender<LoaderEvent<'static>>| {
59  | |         // Use ProgressHub directly - no abstractions
60  | |         let client = match create_client(Backend::Auto) {
61  | |             Ok(client) => client,
...   |
134 | |     })
    | |      ^
    | |      |
    | |______`config` escapes the function body here
    |        argument requires that `'1` must outlive `'static`
    |
    = note: requirement occurs because of the type `AsyncStreamSender<LoaderEvent<'_>>`, which makes the generic argument `LoaderEvent<'_>` invariant
    = note: the struct `AsyncStreamSender<T, CAP>` is invariant over the parameter `T`
    = help: see <https://doc.rust-lang.org/nomicon/subtyping.html> for more information about variance

error[E0597]: `indexed` does not live long enough
   --> packages/fluent-ai-candle/src/model/fluent/kimi_k2/model.rs:296:32
    |
293 |             let mut indexed: Vec<(usize, f32)> = row.iter().copied().enumerate().collect();
    |                 ----------- binding `indexed` declared here
...
296 |             topk_results.push(&indexed[..k]);
    |                                ^^^^^^^ borrowed value does not live long enough
297 |         }
    |         - `indexed` dropped here while still borrowed
...
300 |         let batch_size = topk_results.len();
    |                          ------------ borrow later used here

error[E0716]: temporary value dropped while borrowed
   --> packages/fluent-ai-candle/src/model/loading/mod.rs:388:52
    |
388 |                return Err(CandleError::configuration(&format!(
    |   ________________________-                           ^
    |  |____________________________________________________|
389 | ||                 "Quantization {:?} not supported for architecture {}",
390 | ||                 self.quantization_type, metadata.architecture
391 | ||             )));
    | ||             ^- - temporary value is freed at the end of this statement
    | ||_____________||
    | |______________|argument requires that borrow lasts for `'static`
    |                creates a temporary value which is freed while still in use
    |
    = note: this error originates in the macro `format` (in Nightly builds, run with -Z macro-backtrace for more info)

error[E0716]: temporary value dropped while borrowed
   --> packages/fluent-ai-candle/src/model/loading/mod.rs:375:52
    |
375 |                return Err(CandleError::configuration(&format!(
    |   ________________________-                           ^
    |  |____________________________________________________|
376 | ||                 "Model requires {}MB but budget is {}MB",
377 | ||                 metadata.required_memory_bytes / 1024 / 1024,
378 | ||                 self.memory_budget / 1024 / 1024
379 | ||             )));
    | ||             ^- - temporary value is freed at the end of this statement
    | ||_____________||
    | |______________|argument requires that borrow lasts for `'static`
    |                creates a temporary value which is freed while still in use
    |
    = note: this error originates in the macro `format` (in Nightly builds, run with -Z macro-backtrace for more info)

warning: unused variable: `token_ids`
   --> packages/fluent-ai-candle/src/sampling/composite.rs:105:9
    |
105 |         token_ids: &[u32],
    |         ^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_token_ids`
    |
    = note: `#[warn(unused_variables)]` on by default

warning: unused variable: `position`
   --> packages/fluent-ai-candle/src/sampling/composite.rs:106:9
    |
106 |         position: usize,
    |         ^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_position`

error[E0596]: cannot borrow `**processor` as mutable, as it is behind a `&` reference
   --> packages/fluent-ai-candle/src/sampling/composite.rs:144:13
    |
114 |         for (i, processor) in self.processors.iter().enumerate() {
    |                               ---------------------------------- this iterator yields `&` references
...
144 |             processor
    |             ^^^^^^^^^ `processor` is a `&` reference, so the data it refers to cannot be borrowed as mutable

warning: unused variable: `one_hot`
   --> packages/fluent-ai-candle/src/sampling/gumbel.rs:197:17
    |
197 |         let mut one_hot = Tensor::zeros(shape, DType::F32, &self.device)
    |                 ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_one_hot`

warning: variable does not need to be mutable
   --> packages/fluent-ai-candle/src/sampling/gumbel.rs:197:13
    |
197 |         let mut one_hot = Tensor::zeros(shape, DType::F32, &self.device)
    |             ----^^^^^^^
    |             |
    |             help: remove this `mut`
    |
    = note: `#[warn(unused_mut)]` on by default

warning: unused variable: `msg`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:36:45
   |
36 |             SimdError::InvalidConfiguration(msg) => {
   |                                             ^^^ help: if this is intentional, prefix it with an underscore: `_msg`

warning: unused variable: `msg`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:39:37
   |
39 |             SimdError::InvalidInput(msg) => CandleError::InvalidInput("Invalid SIMD input"),
   |                                     ^^^ help: if this is intentional, prefix it with an underscore: `_msg`

warning: unused variable: `msg`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:40:40
   |
40 |             SimdError::ProcessingError(msg) => {
   |                                        ^^^ help: if this is intentional, prefix it with an underscore: `_msg`

warning: unused variable: `msg`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:43:39
   |
43 |             SimdError::NumericalError(msg) => {
   |                                       ^^^ help: if this is intentional, prefix it with an underscore: `_msg`

warning: unused variable: `msg`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:46:45
   |
46 |             SimdError::UnsupportedOperation(msg) => {
   |                                             ^^^ help: if this is intentional, prefix it with an underscore: `_msg`

warning: unused variable: `msg`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:49:40
   |
49 |             SimdError::TensorOperation(msg) => {
   |                                        ^^^ help: if this is intentional, prefix it with an underscore: `_msg`

warning: unused variable: `logits`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:85:9
   |
85 |         logits: &mut [f32],
   |         ^^^^^^ help: if this is intentional, prefix it with an underscore: `_logits`

warning: unused variable: `context`
  --> packages/fluent-ai-candle/src/sampling/simd.rs:86:9
   |
86 |         context: &ProcessingContext,
   |         ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_context`

warning: unused variable: `temperature`
   --> packages/fluent-ai-candle/src/sampling/simd.rs:129:16
    |
129 |     pub fn new(temperature: f32) -> CandleResult<Self> {
    |                ^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_temperature`

warning: unused variable: `size`
   --> packages/fluent-ai-candle/src/sampling/simd.rs:216:9
    |
216 |         size: usize,
    |         ^^^^ help: if this is intentional, prefix it with an underscore: `_size`

warning: unused variable: `iterations`
   --> packages/fluent-ai-candle/src/sampling/simd.rs:217:9
    |
217 |         iterations: u32,
    |         ^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_iterations`

warning: unused variable: `sender`
   --> packages/fluent-ai-candle/src/types/candle_context/provider.rs:661:50
    |
661 |             _ => AsyncStream::with_channel(move |sender| {
    |                                                  ^^^^^^ help: if this is intentional, prefix it with an underscore: `_sender`

warning: unused variable: `sender`
   --> packages/fluent-ai-candle/src/types/candle_context/provider.rs:911:41
    |
911 |         AsyncStream::with_channel(move |sender| {
    |                                         ^^^^^^ help: if this is intentional, prefix it with an underscore: `_sender`

Some errors have detailed explanations: E0061, E0063, E0107, E0223, E0277, E0308, E0369, E0502, E0505...
For more information about an error, try `rustc --explain E0061`.
warning: `fluent_ai_candle` (lib) generated 21 warnings
error: could not compile `fluent_ai_candle` (lib) due to 130 previous errors; 21 warnings emitted
