// Generated code - DO NOT EDIT MANUALLY
// This file is automatically generated by build.rs


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum OpenaiModel {
    Gpt4o,
    Gpt4oMini,
    Gpt4,
    Gpt35Turbo,
}

impl OpenaiModel {
    #[doc = r" Get all available model variants"]
    pub const fn all_variants() -> &'static [OpenaiModel] {
        &[
            OpenaiModel::Gpt4o,
            OpenaiModel::Gpt4oMini,
            OpenaiModel::Gpt4,
            OpenaiModel::Gpt35Turbo,
        ]
    }
    
    #[doc = r" Get all model variants as Vec"]
    pub fn all_models() -> Vec<OpenaiModel> {
        Self::all_variants().to_vec()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum MistralModel {
    MistralLargeLatest,
    MistralSmallLatest,
    CodestralLatest,
}

impl MistralModel {
    #[doc = r" Get all available model variants"]
    pub const fn all_variants() -> &'static [MistralModel] {
        &[
            MistralModel::MistralLargeLatest,
            MistralModel::MistralSmallLatest,
            MistralModel::CodestralLatest,
        ]
    }
    
    #[doc = r" Get all model variants as Vec"]
    pub fn all_models() -> Vec<MistralModel> {
        Self::all_variants().to_vec()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum AnthropicModel {
    Claude35Sonnet20241022,
    Claude35Sonnet20240620,
    Claude35Haiku20241022,
    Claude3Haiku20240307,
    Claude3Opus20240229,
    Claude3Sonnet20240229,
}

impl AnthropicModel {
    #[doc = r" Get all available model variants"]
    pub const fn all_variants() -> &'static [AnthropicModel] {
        &[
            AnthropicModel::Claude35Sonnet20241022,
            AnthropicModel::Claude35Sonnet20240620,
            AnthropicModel::Claude35Haiku20241022,
            AnthropicModel::Claude3Haiku20240307,
            AnthropicModel::Claude3Opus20240229,
            AnthropicModel::Claude3Sonnet20240229,
        ]
    }
    
    #[doc = r" Get all model variants as Vec"]
    pub fn all_models() -> Vec<AnthropicModel> {
        Self::all_variants().to_vec()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum TogetherModel {
    MetaLlamaMetaLlama318bInstructTurbo,
    MetaLlamaMetaLlama3170bInstructTurbo,
    MistralaiMixtral8x7bInstructV01,
}

impl TogetherModel {
    #[doc = r" Get all available model variants"]
    pub const fn all_variants() -> &'static [TogetherModel] {
        &[
            TogetherModel::MetaLlamaMetaLlama318bInstructTurbo,
            TogetherModel::MetaLlamaMetaLlama3170bInstructTurbo,
            TogetherModel::MistralaiMixtral8x7bInstructV01,
        ]
    }
    
    #[doc = r" Get all model variants as Vec"]
    pub fn all_models() -> Vec<TogetherModel> {
        Self::all_variants().to_vec()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum OpenrouterModel {
    Gpt4o,
    Gpt4oMini,
    Claude35Sonnet20241022,
    Claude35Haiku20241022,
    MetaLlamaLlama31405bInstruct,
    AnthropicClaude3Opus,
    OpenaiGpt4Turbo,
}

impl OpenrouterModel {
    #[doc = r" Get all available model variants"]
    pub const fn all_variants() -> &'static [OpenrouterModel] {
        &[
            OpenrouterModel::Gpt4o,
            OpenrouterModel::Gpt4oMini,
            OpenrouterModel::Claude35Sonnet20241022,
            OpenrouterModel::Claude35Haiku20241022,
            OpenrouterModel::MetaLlamaLlama31405bInstruct,
            OpenrouterModel::AnthropicClaude3Opus,
            OpenrouterModel::OpenaiGpt4Turbo,
        ]
    }
    
    #[doc = r" Get all model variants as Vec"]
    pub fn all_models() -> Vec<OpenrouterModel> {
        Self::all_variants().to_vec()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum HuggingfaceModel {
    MetaLlamaLlama318bInstruct,
    MetaLlamaLlama3170bInstruct,
    MistralaiMistral7bInstructV03,
    MicrosoftDialogptLarge,
    GoogleGemma29bIt,
    MicrosoftCodet5Large,
    BigscienceBloom,
}

impl HuggingfaceModel {
    #[doc = r" Get all available model variants"]
    pub const fn all_variants() -> &'static [HuggingfaceModel] {
        &[
            HuggingfaceModel::MetaLlamaLlama318bInstruct,
            HuggingfaceModel::MetaLlamaLlama3170bInstruct,
            HuggingfaceModel::MistralaiMistral7bInstructV03,
            HuggingfaceModel::MicrosoftDialogptLarge,
            HuggingfaceModel::GoogleGemma29bIt,
            HuggingfaceModel::MicrosoftCodet5Large,
            HuggingfaceModel::BigscienceBloom,
        ]
    }
    
    #[doc = r" Get all model variants as Vec"]
    pub fn all_models() -> Vec<HuggingfaceModel> {
        Self::all_variants().to_vec()
    }
}

#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum XaiModel {
    GrokBeta,
    GrokVisionBeta,
}

impl XaiModel {
    #[doc = r" Get all available model variants"]
    pub const fn all_variants() -> &'static [XaiModel] {
        &[
            XaiModel::GrokBeta,
            XaiModel::GrokVisionBeta,
        ]
    }
    
    #[doc = r" Get all model variants as Vec"]
    pub fn all_models() -> Vec<XaiModel> {
        Self::all_variants().to_vec()
    }
}


impl crate::common::Model for OpenaiModel {
    fn name(&self) -> &'static str {
        match self {
            OpenaiModel::Gpt4o => "gpt-4o",
            OpenaiModel::Gpt4oMini => "gpt-4o-mini",
            OpenaiModel::Gpt4 => "gpt-4",
            OpenaiModel::Gpt35Turbo => "gpt-3.5-turbo",
        }
    }
    
    fn provider_name(&self) -> &'static str {
        "openai"
    }
    
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            OpenaiModel::Gpt4o => Some(96000u32),
            OpenaiModel::Gpt4oMini => Some(96000u32),
            OpenaiModel::Gpt4 => Some(6144u32),
            OpenaiModel::Gpt35Turbo => Some(12288u32),
        }
    }
    
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            OpenaiModel::Gpt4o => Some(32000u32),
            OpenaiModel::Gpt4oMini => Some(32000u32),
            OpenaiModel::Gpt4 => Some(2048u32),
            OpenaiModel::Gpt35Turbo => Some(4096u32),
        }
    }
    
    fn pricing_input(&self) -> Option<f64> {
        match self {
            OpenaiModel::Gpt4o => Some(2.5f64),
            OpenaiModel::Gpt4oMini => Some(0.15f64),
            OpenaiModel::Gpt4 => Some(30f64),
            OpenaiModel::Gpt35Turbo => Some(0.5f64),
        }
    }
    
    fn pricing_output(&self) -> Option<f64> {
        match self {
            OpenaiModel::Gpt4o => Some(10f64),
            OpenaiModel::Gpt4oMini => Some(0.6f64),
            OpenaiModel::Gpt4 => Some(60f64),
            OpenaiModel::Gpt35Turbo => Some(1.5f64),
        }
    }
    
    fn supports_vision(&self) -> bool {
        false
    }
    
    fn supports_function_calling(&self) -> bool {
        true
    }
    
    fn supports_embeddings(&self) -> bool {
        false
    }
    
    fn requires_max_tokens(&self) -> bool {
        false
    }
    
    fn supports_thinking(&self) -> bool {
        false    }
    
    fn required_temperature(&self) -> Option<f64> {
        None    }
    
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None    }
}

impl crate::common::Model for MistralModel {
    fn name(&self) -> &'static str {
        match self {
            MistralModel::MistralLargeLatest => "mistral-large-latest",
            MistralModel::MistralSmallLatest => "mistral-small-latest",
            MistralModel::CodestralLatest => "codestral-latest",
        }
    }
    
    fn provider_name(&self) -> &'static str {
        "mistral"
    }
    
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            MistralModel::MistralLargeLatest => Some(96000u32),
            MistralModel::MistralSmallLatest => Some(24000u32),
            MistralModel::CodestralLatest => Some(24000u32),
        }
    }
    
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            MistralModel::MistralLargeLatest => Some(32000u32),
            MistralModel::MistralSmallLatest => Some(8000u32),
            MistralModel::CodestralLatest => Some(8000u32),
        }
    }
    
    fn pricing_input(&self) -> Option<f64> {
        match self {
            MistralModel::MistralLargeLatest => Some(2f64),
            MistralModel::MistralSmallLatest => Some(1f64),
            MistralModel::CodestralLatest => Some(0.2f64),
        }
    }
    
    fn pricing_output(&self) -> Option<f64> {
        match self {
            MistralModel::MistralLargeLatest => Some(6f64),
            MistralModel::MistralSmallLatest => Some(3f64),
            MistralModel::CodestralLatest => Some(0.6f64),
        }
    }
    
    fn supports_vision(&self) -> bool {
        false
    }
    
    fn supports_function_calling(&self) -> bool {
        true
    }
    
    fn supports_embeddings(&self) -> bool {
        false
    }
    
    fn requires_max_tokens(&self) -> bool {
        false
    }
    
    fn supports_thinking(&self) -> bool {
        false    }
    
    fn required_temperature(&self) -> Option<f64> {
        None    }
    
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None    }
}

impl crate::common::Model for AnthropicModel {
    fn name(&self) -> &'static str {
        match self {
            AnthropicModel::Claude35Sonnet20241022 => "claude-3-5-sonnet-20241022",
            AnthropicModel::Claude35Sonnet20240620 => "claude-3-5-sonnet-20240620",
            AnthropicModel::Claude35Haiku20241022 => "claude-3-5-haiku-20241022",
            AnthropicModel::Claude3Haiku20240307 => "claude-3-haiku-20240307",
            AnthropicModel::Claude3Opus20240229 => "claude-3-opus-20240229",
            AnthropicModel::Claude3Sonnet20240229 => "claude-3-sonnet-20240229",
        }
    }
    
    fn provider_name(&self) -> &'static str {
        "anthropic"
    }
    
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            AnthropicModel::Claude35Sonnet20241022 => Some(150000u32),
            AnthropicModel::Claude35Sonnet20240620 => Some(150000u32),
            AnthropicModel::Claude35Haiku20241022 => Some(150000u32),
            AnthropicModel::Claude3Haiku20240307 => Some(150000u32),
            AnthropicModel::Claude3Opus20240229 => Some(150000u32),
            AnthropicModel::Claude3Sonnet20240229 => Some(150000u32),
        }
    }
    
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            AnthropicModel::Claude35Sonnet20241022 => Some(50000u32),
            AnthropicModel::Claude35Sonnet20240620 => Some(50000u32),
            AnthropicModel::Claude35Haiku20241022 => Some(50000u32),
            AnthropicModel::Claude3Haiku20240307 => Some(50000u32),
            AnthropicModel::Claude3Opus20240229 => Some(50000u32),
            AnthropicModel::Claude3Sonnet20240229 => Some(50000u32),
        }
    }
    
    fn pricing_input(&self) -> Option<f64> {
        match self {
            AnthropicModel::Claude35Sonnet20241022 => Some(3f64),
            AnthropicModel::Claude35Sonnet20240620 => Some(3f64),
            AnthropicModel::Claude35Haiku20241022 => Some(1f64),
            AnthropicModel::Claude3Haiku20240307 => Some(0.25f64),
            AnthropicModel::Claude3Opus20240229 => Some(15f64),
            AnthropicModel::Claude3Sonnet20240229 => Some(3f64),
        }
    }
    
    fn pricing_output(&self) -> Option<f64> {
        match self {
            AnthropicModel::Claude35Sonnet20241022 => Some(15f64),
            AnthropicModel::Claude35Sonnet20240620 => Some(15f64),
            AnthropicModel::Claude35Haiku20241022 => Some(5f64),
            AnthropicModel::Claude3Haiku20240307 => Some(1.25f64),
            AnthropicModel::Claude3Opus20240229 => Some(75f64),
            AnthropicModel::Claude3Sonnet20240229 => Some(15f64),
        }
    }
    
    fn supports_vision(&self) -> bool {
        false
    }
    
    fn supports_function_calling(&self) -> bool {
        true
    }
    
    fn supports_embeddings(&self) -> bool {
        false
    }
    
    fn requires_max_tokens(&self) -> bool {
        false
    }
    
    fn supports_thinking(&self) -> bool {
        false    }
    
    fn required_temperature(&self) -> Option<f64> {
        None    }
    
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None    }
}

impl crate::common::Model for TogetherModel {
    fn name(&self) -> &'static str {
        match self {
            TogetherModel::MetaLlamaMetaLlama318bInstructTurbo => "meta-llama/Meta-Llama-3.1-8B-Instruct-Turbo",
            TogetherModel::MetaLlamaMetaLlama3170bInstructTurbo => "meta-llama/Meta-Llama-3.1-70B-Instruct-Turbo",
            TogetherModel::MistralaiMixtral8x7bInstructV01 => "mistralai/Mixtral-8x7B-Instruct-v0.1",
        }
    }
    
    fn provider_name(&self) -> &'static str {
        "together"
    }
    
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            TogetherModel::MetaLlamaMetaLlama318bInstructTurbo => Some(98304u32),
            TogetherModel::MetaLlamaMetaLlama3170bInstructTurbo => Some(98304u32),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(24576u32),
        }
    }
    
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            TogetherModel::MetaLlamaMetaLlama318bInstructTurbo => Some(32768u32),
            TogetherModel::MetaLlamaMetaLlama3170bInstructTurbo => Some(32768u32),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(8192u32),
        }
    }
    
    fn pricing_input(&self) -> Option<f64> {
        match self {
            TogetherModel::MetaLlamaMetaLlama318bInstructTurbo => Some(0.18f64),
            TogetherModel::MetaLlamaMetaLlama3170bInstructTurbo => Some(0.88f64),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(0.6f64),
        }
    }
    
    fn pricing_output(&self) -> Option<f64> {
        match self {
            TogetherModel::MetaLlamaMetaLlama318bInstructTurbo => Some(0.18f64),
            TogetherModel::MetaLlamaMetaLlama3170bInstructTurbo => Some(0.88f64),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(0.6f64),
        }
    }
    
    fn supports_vision(&self) -> bool {
        false
    }
    
    fn supports_function_calling(&self) -> bool {
        true
    }
    
    fn supports_embeddings(&self) -> bool {
        false
    }
    
    fn requires_max_tokens(&self) -> bool {
        false
    }
    
    fn supports_thinking(&self) -> bool {
        false    }
    
    fn required_temperature(&self) -> Option<f64> {
        None    }
    
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None    }
}

impl crate::common::Model for OpenrouterModel {
    fn name(&self) -> &'static str {
        match self {
            OpenrouterModel::Gpt4o => "gpt-4o",
            OpenrouterModel::Gpt4oMini => "gpt-4o-mini",
            OpenrouterModel::Claude35Sonnet20241022 => "claude-3-5-sonnet-20241022",
            OpenrouterModel::Claude35Haiku20241022 => "claude-3-5-haiku-20241022",
            OpenrouterModel::MetaLlamaLlama31405bInstruct => "meta-llama/llama-3.1-405b-instruct",
            OpenrouterModel::AnthropicClaude3Opus => "anthropic/claude-3-opus",
            OpenrouterModel::OpenaiGpt4Turbo => "openai/gpt-4-turbo",
        }
    }
    
    fn provider_name(&self) -> &'static str {
        "openrouter"
    }
    
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            OpenrouterModel::Gpt4o => Some(96000u32),
            OpenrouterModel::Gpt4oMini => Some(96000u32),
            OpenrouterModel::Claude35Sonnet20241022 => Some(150000u32),
            OpenrouterModel::Claude35Haiku20241022 => Some(150000u32),
            OpenrouterModel::MetaLlamaLlama31405bInstruct => Some(98304u32),
            OpenrouterModel::AnthropicClaude3Opus => Some(150000u32),
            OpenrouterModel::OpenaiGpt4Turbo => Some(96000u32),
        }
    }
    
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            OpenrouterModel::Gpt4o => Some(32000u32),
            OpenrouterModel::Gpt4oMini => Some(32000u32),
            OpenrouterModel::Claude35Sonnet20241022 => Some(50000u32),
            OpenrouterModel::Claude35Haiku20241022 => Some(50000u32),
            OpenrouterModel::MetaLlamaLlama31405bInstruct => Some(32768u32),
            OpenrouterModel::AnthropicClaude3Opus => Some(50000u32),
            OpenrouterModel::OpenaiGpt4Turbo => Some(32000u32),
        }
    }
    
    fn pricing_input(&self) -> Option<f64> {
        match self {
            OpenrouterModel::Gpt4o => Some(2.5f64),
            OpenrouterModel::Gpt4oMini => Some(0.15f64),
            OpenrouterModel::Claude35Sonnet20241022 => Some(3f64),
            OpenrouterModel::Claude35Haiku20241022 => Some(0.25f64),
            OpenrouterModel::MetaLlamaLlama31405bInstruct => Some(2.7f64),
            OpenrouterModel::AnthropicClaude3Opus => Some(15f64),
            OpenrouterModel::OpenaiGpt4Turbo => Some(10f64),
        }
    }
    
    fn pricing_output(&self) -> Option<f64> {
        match self {
            OpenrouterModel::Gpt4o => Some(10f64),
            OpenrouterModel::Gpt4oMini => Some(0.6f64),
            OpenrouterModel::Claude35Sonnet20241022 => Some(15f64),
            OpenrouterModel::Claude35Haiku20241022 => Some(1.25f64),
            OpenrouterModel::MetaLlamaLlama31405bInstruct => Some(2.7f64),
            OpenrouterModel::AnthropicClaude3Opus => Some(75f64),
            OpenrouterModel::OpenaiGpt4Turbo => Some(30f64),
        }
    }
    
    fn supports_vision(&self) -> bool {
        false
    }
    
    fn supports_function_calling(&self) -> bool {
        true
    }
    
    fn supports_embeddings(&self) -> bool {
        false
    }
    
    fn requires_max_tokens(&self) -> bool {
        false
    }
    
    fn supports_thinking(&self) -> bool {
        false    }
    
    fn required_temperature(&self) -> Option<f64> {
        None    }
    
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None    }
}

impl crate::common::Model for HuggingfaceModel {
    fn name(&self) -> &'static str {
        match self {
            HuggingfaceModel::MetaLlamaLlama318bInstruct => "meta-llama/Llama-3.1-8B-Instruct",
            HuggingfaceModel::MetaLlamaLlama3170bInstruct => "meta-llama/Llama-3.1-70B-Instruct",
            HuggingfaceModel::MistralaiMistral7bInstructV03 => "mistralai/Mistral-7B-Instruct-v0.3",
            HuggingfaceModel::MicrosoftDialogptLarge => "microsoft/DialoGPT-large",
            HuggingfaceModel::GoogleGemma29bIt => "google/gemma-2-9b-it",
            HuggingfaceModel::MicrosoftCodet5Large => "microsoft/CodeT5-large",
            HuggingfaceModel::BigscienceBloom => "bigscience/bloom",
        }
    }
    
    fn provider_name(&self) -> &'static str {
        "huggingface"
    }
    
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            HuggingfaceModel::MetaLlamaLlama318bInstruct => Some(6144u32),
            HuggingfaceModel::MetaLlamaLlama3170bInstruct => Some(6144u32),
            HuggingfaceModel::MistralaiMistral7bInstructV03 => Some(6144u32),
            HuggingfaceModel::MicrosoftDialogptLarge => Some(1024u32),
            HuggingfaceModel::GoogleGemma29bIt => Some(6144u32),
            HuggingfaceModel::MicrosoftCodet5Large => Some(1024u32),
            HuggingfaceModel::BigscienceBloom => Some(2048u32),
        }
    }
    
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            HuggingfaceModel::MetaLlamaLlama318bInstruct => Some(2048u32),
            HuggingfaceModel::MetaLlamaLlama3170bInstruct => Some(2048u32),
            HuggingfaceModel::MistralaiMistral7bInstructV03 => Some(2048u32),
            HuggingfaceModel::MicrosoftDialogptLarge => Some(1024u32),
            HuggingfaceModel::GoogleGemma29bIt => Some(2048u32),
            HuggingfaceModel::MicrosoftCodet5Large => Some(1024u32),
            HuggingfaceModel::BigscienceBloom => Some(1024u32),
        }
    }
    
    fn pricing_input(&self) -> Option<f64> {
        match self {
            HuggingfaceModel::MetaLlamaLlama318bInstruct => Some(0f64),
            HuggingfaceModel::MetaLlamaLlama3170bInstruct => Some(0f64),
            HuggingfaceModel::MistralaiMistral7bInstructV03 => Some(0f64),
            HuggingfaceModel::MicrosoftDialogptLarge => Some(0f64),
            HuggingfaceModel::GoogleGemma29bIt => Some(0f64),
            HuggingfaceModel::MicrosoftCodet5Large => Some(0f64),
            HuggingfaceModel::BigscienceBloom => Some(0f64),
        }
    }
    
    fn pricing_output(&self) -> Option<f64> {
        match self {
            HuggingfaceModel::MetaLlamaLlama318bInstruct => Some(0f64),
            HuggingfaceModel::MetaLlamaLlama3170bInstruct => Some(0f64),
            HuggingfaceModel::MistralaiMistral7bInstructV03 => Some(0f64),
            HuggingfaceModel::MicrosoftDialogptLarge => Some(0f64),
            HuggingfaceModel::GoogleGemma29bIt => Some(0f64),
            HuggingfaceModel::MicrosoftCodet5Large => Some(0f64),
            HuggingfaceModel::BigscienceBloom => Some(0f64),
        }
    }
    
    fn supports_vision(&self) -> bool {
        false
    }
    
    fn supports_function_calling(&self) -> bool {
        true
    }
    
    fn supports_embeddings(&self) -> bool {
        false
    }
    
    fn requires_max_tokens(&self) -> bool {
        false
    }
    
    fn supports_thinking(&self) -> bool {
        false    }
    
    fn required_temperature(&self) -> Option<f64> {
        None    }
    
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None    }
}

impl crate::common::Model for XaiModel {
    fn name(&self) -> &'static str {
        match self {
            XaiModel::GrokBeta => "grok-beta",
            XaiModel::GrokVisionBeta => "grok-vision-beta",
        }
    }
    
    fn provider_name(&self) -> &'static str {
        "xai"
    }
    
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            XaiModel::GrokBeta => Some(98304u32),
            XaiModel::GrokVisionBeta => Some(6144u32),
        }
    }
    
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            XaiModel::GrokBeta => Some(32768u32),
            XaiModel::GrokVisionBeta => Some(2048u32),
        }
    }
    
    fn pricing_input(&self) -> Option<f64> {
        match self {
            XaiModel::GrokBeta => Some(5f64),
            XaiModel::GrokVisionBeta => Some(5f64),
        }
    }
    
    fn pricing_output(&self) -> Option<f64> {
        match self {
            XaiModel::GrokBeta => Some(15f64),
            XaiModel::GrokVisionBeta => Some(15f64),
        }
    }
    
    fn supports_vision(&self) -> bool {
        false
    }
    
    fn supports_function_calling(&self) -> bool {
        true
    }
    
    fn supports_embeddings(&self) -> bool {
        false
    }
    
    fn requires_max_tokens(&self) -> bool {
        false
    }
    
    fn supports_thinking(&self) -> bool {
        false    }
    
    fn required_temperature(&self) -> Option<f64> {
        None    }
    
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None    }
}
