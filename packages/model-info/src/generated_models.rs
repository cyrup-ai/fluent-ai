// Generated code - DO NOT EDIT MANUALLY
// This file is automatically generated by build.rs


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum OpenaiModel {
    Gpt4o,
    Gpt4oMini,
    Gpt35Turbo,
}
impl OpenaiModel {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [OpenaiModel] {
        &[OpenaiModel::Gpt4o, OpenaiModel::Gpt4oMini, OpenaiModel::Gpt35Turbo]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<OpenaiModel> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum OpenAI {
    Gpt4o,
    Gpt4oMini,
    Gpt35Turbo,
}
impl OpenAI {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [OpenAI] {
        &[OpenAI::Gpt4o, OpenAI::Gpt4oMini, OpenAI::Gpt35Turbo]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<OpenAI> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum MistralModel {
    MistralLargeLatest,
    MistralLarge2407,
    MistralLarge2402,
    MistralMediumLatest,
    MistralSmallLatest,
    MistralTiny,
    CodestralLatest,
    Codestral2405,
}
impl MistralModel {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [MistralModel] {
        &[
            MistralModel::MistralLargeLatest,
            MistralModel::MistralLarge2407,
            MistralModel::MistralLarge2402,
            MistralModel::MistralMediumLatest,
            MistralModel::MistralSmallLatest,
            MistralModel::MistralTiny,
            MistralModel::CodestralLatest,
            MistralModel::Codestral2405,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<MistralModel> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Mistral {
    MistralLargeLatest,
    MistralLarge2407,
    MistralLarge2402,
    MistralMediumLatest,
    MistralSmallLatest,
    MistralTiny,
    CodestralLatest,
    Codestral2405,
}
impl Mistral {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [Mistral] {
        &[
            Mistral::MistralLargeLatest,
            Mistral::MistralLarge2407,
            Mistral::MistralLarge2402,
            Mistral::MistralMediumLatest,
            Mistral::MistralSmallLatest,
            Mistral::MistralTiny,
            Mistral::CodestralLatest,
            Mistral::Codestral2405,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<Mistral> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum AnthropicModel {
    Claude4Sonnet,
    Claude4SonnetThinking,
    Claude4Opus,
    Claude4OpusThinking,
}
impl AnthropicModel {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [AnthropicModel] {
        &[
            AnthropicModel::Claude4Sonnet,
            AnthropicModel::Claude4SonnetThinking,
            AnthropicModel::Claude4Opus,
            AnthropicModel::Claude4OpusThinking,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<AnthropicModel> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Anthropic {
    Claude4Sonnet,
    Claude4SonnetThinking,
    Claude4Opus,
    Claude4OpusThinking,
}
impl Anthropic {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [Anthropic] {
        &[
            Anthropic::Claude4Sonnet,
            Anthropic::Claude4SonnetThinking,
            Anthropic::Claude4Opus,
            Anthropic::Claude4OpusThinking,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<Anthropic> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum TogetherModel {
    MetaLlamaLlama270bChatHf,
    MistralaiMixtral8x7bInstructV01,
    CodellamaCodellama34bInstructHf,
    MetaLlamaLlama213bChatHf,
    NousresearchNousHermes2Mixtral8x7bDpo,
    ZeroOneAiYi34bChat,
}
impl TogetherModel {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [TogetherModel] {
        &[
            TogetherModel::MetaLlamaLlama270bChatHf,
            TogetherModel::MistralaiMixtral8x7bInstructV01,
            TogetherModel::CodellamaCodellama34bInstructHf,
            TogetherModel::MetaLlamaLlama213bChatHf,
            TogetherModel::NousresearchNousHermes2Mixtral8x7bDpo,
            TogetherModel::ZeroOneAiYi34bChat,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<TogetherModel> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum Together {
    MetaLlamaLlama270bChatHf,
    MistralaiMixtral8x7bInstructV01,
    CodellamaCodellama34bInstructHf,
    MetaLlamaLlama213bChatHf,
    NousresearchNousHermes2Mixtral8x7bDpo,
    ZeroOneAiYi34bChat,
}
impl Together {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [Together] {
        &[
            Together::MetaLlamaLlama270bChatHf,
            Together::MistralaiMixtral8x7bInstructV01,
            Together::CodellamaCodellama34bInstructHf,
            Together::MetaLlamaLlama213bChatHf,
            Together::NousresearchNousHermes2Mixtral8x7bDpo,
            Together::ZeroOneAiYi34bChat,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<Together> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum OpenrouterModel {
    OpenaiGpt4,
    OpenaiGpt35Turbo,
    AnthropicClaude3Sonnet,
    AnthropicClaude3Haiku,
    MetaLlamaLlama38bInstruct,
    MetaLlamaLlama370bInstruct,
    GoogleGemma7bIt,
}
impl OpenrouterModel {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [OpenrouterModel] {
        &[
            OpenrouterModel::OpenaiGpt4,
            OpenrouterModel::OpenaiGpt35Turbo,
            OpenrouterModel::AnthropicClaude3Sonnet,
            OpenrouterModel::AnthropicClaude3Haiku,
            OpenrouterModel::MetaLlamaLlama38bInstruct,
            OpenrouterModel::MetaLlamaLlama370bInstruct,
            OpenrouterModel::GoogleGemma7bIt,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<OpenrouterModel> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum OpenRouter {
    OpenaiGpt4,
    OpenaiGpt35Turbo,
    AnthropicClaude3Sonnet,
    AnthropicClaude3Haiku,
    MetaLlamaLlama38bInstruct,
    MetaLlamaLlama370bInstruct,
    GoogleGemma7bIt,
}
impl OpenRouter {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [OpenRouter] {
        &[
            OpenRouter::OpenaiGpt4,
            OpenRouter::OpenaiGpt35Turbo,
            OpenRouter::AnthropicClaude3Sonnet,
            OpenRouter::AnthropicClaude3Haiku,
            OpenRouter::MetaLlamaLlama38bInstruct,
            OpenRouter::MetaLlamaLlama370bInstruct,
            OpenRouter::GoogleGemma7bIt,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<OpenRouter> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum HuggingfaceModel {
    MetaLlamaLlama270bChatHf,
    MetaLlamaLlama213bChatHf,
    MetaLlamaLlama27bChatHf,
    MistralaiMixtral8x7bInstructV01,
    MistralaiMistral7bInstructV01,
    CodellamaCodellama34bInstructHf,
    CodellamaCodellama13bInstructHf,
    CodellamaCodellama7bInstructHf,
    GoogleGemma7bIt,
    GoogleGemma2bIt,
}
impl HuggingfaceModel {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [HuggingfaceModel] {
        &[
            HuggingfaceModel::MetaLlamaLlama270bChatHf,
            HuggingfaceModel::MetaLlamaLlama213bChatHf,
            HuggingfaceModel::MetaLlamaLlama27bChatHf,
            HuggingfaceModel::MistralaiMixtral8x7bInstructV01,
            HuggingfaceModel::MistralaiMistral7bInstructV01,
            HuggingfaceModel::CodellamaCodellama34bInstructHf,
            HuggingfaceModel::CodellamaCodellama13bInstructHf,
            HuggingfaceModel::CodellamaCodellama7bInstructHf,
            HuggingfaceModel::GoogleGemma7bIt,
            HuggingfaceModel::GoogleGemma2bIt,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<HuggingfaceModel> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum HuggingFace {
    MetaLlamaLlama270bChatHf,
    MetaLlamaLlama213bChatHf,
    MetaLlamaLlama27bChatHf,
    MistralaiMixtral8x7bInstructV01,
    MistralaiMistral7bInstructV01,
    CodellamaCodellama34bInstructHf,
    CodellamaCodellama13bInstructHf,
    CodellamaCodellama7bInstructHf,
    GoogleGemma7bIt,
    GoogleGemma2bIt,
}
impl HuggingFace {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [HuggingFace] {
        &[
            HuggingFace::MetaLlamaLlama270bChatHf,
            HuggingFace::MetaLlamaLlama213bChatHf,
            HuggingFace::MetaLlamaLlama27bChatHf,
            HuggingFace::MistralaiMixtral8x7bInstructV01,
            HuggingFace::MistralaiMistral7bInstructV01,
            HuggingFace::CodellamaCodellama34bInstructHf,
            HuggingFace::CodellamaCodellama13bInstructHf,
            HuggingFace::CodellamaCodellama7bInstructHf,
            HuggingFace::GoogleGemma7bIt,
            HuggingFace::GoogleGemma2bIt,
        ]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<HuggingFace> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum XaiModel {
    Grok2,
    Grok2Mini,
}
impl XaiModel {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [XaiModel] {
        &[XaiModel::Grok2, XaiModel::Grok2Mini]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<XaiModel> {
        Self::all_variants().to_vec()
    }
}


#[derive(Debug, Clone, Copy, PartialEq, Eq, Hash)]
pub enum XAI {
    Grok2,
    Grok2Mini,
}
impl XAI {
    /// Get all available model variants
    pub const fn all_variants() -> &'static [XAI] {
        &[XAI::Grok2, XAI::Grok2Mini]
    }
    /// Get all model variants as Vec
    pub fn all_models() -> Vec<XAI> {
        Self::all_variants().to_vec()
    }
}



impl crate::common::Model for OpenaiModel {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            OpenaiModel::Gpt4o => "gpt-4o",
            OpenaiModel::Gpt4oMini => "gpt-4o-mini",
            OpenaiModel::Gpt35Turbo => "gpt-3.5-turbo",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "openai"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            OpenaiModel::Gpt4o => Some(96000u32),
            OpenaiModel::Gpt4oMini => Some(96000u32),
            OpenaiModel::Gpt35Turbo => Some(12288u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            OpenaiModel::Gpt4o => Some(32000u32),
            OpenaiModel::Gpt4oMini => Some(32000u32),
            OpenaiModel::Gpt35Turbo => Some(4096u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            OpenaiModel::Gpt4o => Some(0.005f64),
            OpenaiModel::Gpt4oMini => Some(0.00015f64),
            OpenaiModel::Gpt35Turbo => Some(0.001f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            OpenaiModel::Gpt4o => Some(0.015f64),
            OpenaiModel::Gpt4oMini => Some(0.0006f64),
            OpenaiModel::Gpt35Turbo => Some(0.002f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            OpenaiModel::Gpt4o => Some(0f64),
            OpenaiModel::Gpt4oMini => Some(0f64),
            OpenaiModel::Gpt35Turbo => Some(0f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for OpenAI {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            OpenAI::Gpt4o => "gpt-4o",
            OpenAI::Gpt4oMini => "gpt-4o-mini",
            OpenAI::Gpt35Turbo => "gpt-3.5-turbo",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "openai"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            OpenAI::Gpt4o => Some(96000u32),
            OpenAI::Gpt4oMini => Some(96000u32),
            OpenAI::Gpt35Turbo => Some(12288u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            OpenAI::Gpt4o => Some(32000u32),
            OpenAI::Gpt4oMini => Some(32000u32),
            OpenAI::Gpt35Turbo => Some(4096u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            OpenAI::Gpt4o => Some(0.005f64),
            OpenAI::Gpt4oMini => Some(0.00015f64),
            OpenAI::Gpt35Turbo => Some(0.001f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            OpenAI::Gpt4o => Some(0.015f64),
            OpenAI::Gpt4oMini => Some(0.0006f64),
            OpenAI::Gpt35Turbo => Some(0.002f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            OpenAI::Gpt4o => Some(0f64),
            OpenAI::Gpt4oMini => Some(0f64),
            OpenAI::Gpt35Turbo => Some(0f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for MistralModel {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            MistralModel::MistralLargeLatest => "mistral-large-latest",
            MistralModel::MistralLarge2407 => "mistral-large-2407",
            MistralModel::MistralLarge2402 => "mistral-large-2402",
            MistralModel::MistralMediumLatest => "mistral-medium-latest",
            MistralModel::MistralSmallLatest => "mistral-small-latest",
            MistralModel::MistralTiny => "mistral-tiny",
            MistralModel::CodestralLatest => "codestral-latest",
            MistralModel::Codestral2405 => "codestral-2405",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "mistral"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            MistralModel::MistralLargeLatest => Some(96000u32),
            MistralModel::MistralLarge2407 => Some(96000u32),
            MistralModel::MistralLarge2402 => Some(24000u32),
            MistralModel::MistralMediumLatest => Some(24000u32),
            MistralModel::MistralSmallLatest => Some(24000u32),
            MistralModel::MistralTiny => Some(24000u32),
            MistralModel::CodestralLatest => Some(24000u32),
            MistralModel::Codestral2405 => Some(24000u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            MistralModel::MistralLargeLatest => Some(32000u32),
            MistralModel::MistralLarge2407 => Some(32000u32),
            MistralModel::MistralLarge2402 => Some(8000u32),
            MistralModel::MistralMediumLatest => Some(8000u32),
            MistralModel::MistralSmallLatest => Some(8000u32),
            MistralModel::MistralTiny => Some(8000u32),
            MistralModel::CodestralLatest => Some(8000u32),
            MistralModel::Codestral2405 => Some(8000u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            MistralModel::MistralLargeLatest => Some(2f64),
            MistralModel::MistralLarge2407 => Some(2f64),
            MistralModel::MistralLarge2402 => Some(4f64),
            MistralModel::MistralMediumLatest => Some(2.7f64),
            MistralModel::MistralSmallLatest => Some(1f64),
            MistralModel::MistralTiny => Some(0.14f64),
            MistralModel::CodestralLatest => Some(0.2f64),
            MistralModel::Codestral2405 => Some(0.2f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            MistralModel::MistralLargeLatest => Some(6f64),
            MistralModel::MistralLarge2407 => Some(6f64),
            MistralModel::MistralLarge2402 => Some(12f64),
            MistralModel::MistralMediumLatest => Some(8.1f64),
            MistralModel::MistralSmallLatest => Some(3f64),
            MistralModel::MistralTiny => Some(0.42f64),
            MistralModel::CodestralLatest => Some(0.6f64),
            MistralModel::Codestral2405 => Some(0.6f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        None
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for Mistral {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            Mistral::MistralLargeLatest => "mistral-large-latest",
            Mistral::MistralLarge2407 => "mistral-large-2407",
            Mistral::MistralLarge2402 => "mistral-large-2402",
            Mistral::MistralMediumLatest => "mistral-medium-latest",
            Mistral::MistralSmallLatest => "mistral-small-latest",
            Mistral::MistralTiny => "mistral-tiny",
            Mistral::CodestralLatest => "codestral-latest",
            Mistral::Codestral2405 => "codestral-2405",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "mistral"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            Mistral::MistralLargeLatest => Some(96000u32),
            Mistral::MistralLarge2407 => Some(96000u32),
            Mistral::MistralLarge2402 => Some(24000u32),
            Mistral::MistralMediumLatest => Some(24000u32),
            Mistral::MistralSmallLatest => Some(24000u32),
            Mistral::MistralTiny => Some(24000u32),
            Mistral::CodestralLatest => Some(24000u32),
            Mistral::Codestral2405 => Some(24000u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            Mistral::MistralLargeLatest => Some(32000u32),
            Mistral::MistralLarge2407 => Some(32000u32),
            Mistral::MistralLarge2402 => Some(8000u32),
            Mistral::MistralMediumLatest => Some(8000u32),
            Mistral::MistralSmallLatest => Some(8000u32),
            Mistral::MistralTiny => Some(8000u32),
            Mistral::CodestralLatest => Some(8000u32),
            Mistral::Codestral2405 => Some(8000u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            Mistral::MistralLargeLatest => Some(2f64),
            Mistral::MistralLarge2407 => Some(2f64),
            Mistral::MistralLarge2402 => Some(4f64),
            Mistral::MistralMediumLatest => Some(2.7f64),
            Mistral::MistralSmallLatest => Some(1f64),
            Mistral::MistralTiny => Some(0.14f64),
            Mistral::CodestralLatest => Some(0.2f64),
            Mistral::Codestral2405 => Some(0.2f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            Mistral::MistralLargeLatest => Some(6f64),
            Mistral::MistralLarge2407 => Some(6f64),
            Mistral::MistralLarge2402 => Some(12f64),
            Mistral::MistralMediumLatest => Some(8.1f64),
            Mistral::MistralSmallLatest => Some(3f64),
            Mistral::MistralTiny => Some(0.42f64),
            Mistral::CodestralLatest => Some(0.6f64),
            Mistral::Codestral2405 => Some(0.6f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        None
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for AnthropicModel {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            AnthropicModel::Claude4Sonnet => "claude-4-sonnet",
            AnthropicModel::Claude4SonnetThinking => "claude-4-sonnet-thinking",
            AnthropicModel::Claude4Opus => "claude-4-opus",
            AnthropicModel::Claude4OpusThinking => "claude-4-opus-thinking",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "anthropic"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            AnthropicModel::Claude4Sonnet => Some(150000u32),
            AnthropicModel::Claude4SonnetThinking => Some(150000u32),
            AnthropicModel::Claude4Opus => Some(150000u32),
            AnthropicModel::Claude4OpusThinking => Some(150000u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            AnthropicModel::Claude4Sonnet => Some(50000u32),
            AnthropicModel::Claude4SonnetThinking => Some(50000u32),
            AnthropicModel::Claude4Opus => Some(50000u32),
            AnthropicModel::Claude4OpusThinking => Some(50000u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            AnthropicModel::Claude4Sonnet => Some(3f64),
            AnthropicModel::Claude4SonnetThinking => Some(3f64),
            AnthropicModel::Claude4Opus => Some(15f64),
            AnthropicModel::Claude4OpusThinking => Some(15f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            AnthropicModel::Claude4Sonnet => Some(15f64),
            AnthropicModel::Claude4SonnetThinking => Some(15f64),
            AnthropicModel::Claude4Opus => Some(75f64),
            AnthropicModel::Claude4OpusThinking => Some(75f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        match self {
            AnthropicModel::Claude4SonnetThinking => true,
            AnthropicModel::Claude4OpusThinking => true,
            _ => false,
        }
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            AnthropicModel::Claude4SonnetThinking => Some(1f64),
            AnthropicModel::Claude4OpusThinking => Some(1f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        match self {
            AnthropicModel::Claude4SonnetThinking => Some(100000u32),
            AnthropicModel::Claude4OpusThinking => Some(100000u32),
            _ => None,
        }
    }
}


impl crate::common::Model for Anthropic {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            Anthropic::Claude4Sonnet => "claude-4-sonnet",
            Anthropic::Claude4SonnetThinking => "claude-4-sonnet-thinking",
            Anthropic::Claude4Opus => "claude-4-opus",
            Anthropic::Claude4OpusThinking => "claude-4-opus-thinking",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "anthropic"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            Anthropic::Claude4Sonnet => Some(150000u32),
            Anthropic::Claude4SonnetThinking => Some(150000u32),
            Anthropic::Claude4Opus => Some(150000u32),
            Anthropic::Claude4OpusThinking => Some(150000u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            Anthropic::Claude4Sonnet => Some(50000u32),
            Anthropic::Claude4SonnetThinking => Some(50000u32),
            Anthropic::Claude4Opus => Some(50000u32),
            Anthropic::Claude4OpusThinking => Some(50000u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            Anthropic::Claude4Sonnet => Some(3f64),
            Anthropic::Claude4SonnetThinking => Some(3f64),
            Anthropic::Claude4Opus => Some(15f64),
            Anthropic::Claude4OpusThinking => Some(15f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            Anthropic::Claude4Sonnet => Some(15f64),
            Anthropic::Claude4SonnetThinking => Some(15f64),
            Anthropic::Claude4Opus => Some(75f64),
            Anthropic::Claude4OpusThinking => Some(75f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        match self {
            Anthropic::Claude4SonnetThinking => true,
            Anthropic::Claude4OpusThinking => true,
            _ => false,
        }
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            Anthropic::Claude4SonnetThinking => Some(1f64),
            Anthropic::Claude4OpusThinking => Some(1f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        match self {
            Anthropic::Claude4SonnetThinking => Some(100000u32),
            Anthropic::Claude4OpusThinking => Some(100000u32),
            _ => None,
        }
    }
}


impl crate::common::Model for TogetherModel {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            TogetherModel::MetaLlamaLlama270bChatHf => "meta-llama/Llama-2-70b-chat-hf",
            TogetherModel::MistralaiMixtral8x7bInstructV01 => {
                "mistralai/Mixtral-8x7B-Instruct-v0.1"
            }
            TogetherModel::CodellamaCodellama34bInstructHf => {
                "codellama/CodeLlama-34b-Instruct-hf"
            }
            TogetherModel::MetaLlamaLlama213bChatHf => "meta-llama/Llama-2-13b-chat-hf",
            TogetherModel::NousresearchNousHermes2Mixtral8x7bDpo => {
                "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
            }
            TogetherModel::ZeroOneAiYi34bChat => "zero-one-ai/Yi-34B-Chat",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "together"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            TogetherModel::MetaLlamaLlama270bChatHf => Some(4096u32),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(24576u32),
            TogetherModel::CodellamaCodellama34bInstructHf => Some(12288u32),
            TogetherModel::MetaLlamaLlama213bChatHf => Some(4096u32),
            TogetherModel::NousresearchNousHermes2Mixtral8x7bDpo => Some(24576u32),
            TogetherModel::ZeroOneAiYi34bChat => Some(4096u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            TogetherModel::MetaLlamaLlama270bChatHf => Some(1024u32),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(8192u32),
            TogetherModel::CodellamaCodellama34bInstructHf => Some(4096u32),
            TogetherModel::MetaLlamaLlama213bChatHf => Some(1024u32),
            TogetherModel::NousresearchNousHermes2Mixtral8x7bDpo => Some(8192u32),
            TogetherModel::ZeroOneAiYi34bChat => Some(1024u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            TogetherModel::MetaLlamaLlama270bChatHf => Some(0.9f64),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(0.6f64),
            TogetherModel::CodellamaCodellama34bInstructHf => Some(0.776f64),
            TogetherModel::MetaLlamaLlama213bChatHf => Some(0.225f64),
            TogetherModel::NousresearchNousHermes2Mixtral8x7bDpo => Some(0.6f64),
            TogetherModel::ZeroOneAiYi34bChat => Some(0.8f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            TogetherModel::MetaLlamaLlama270bChatHf => Some(0.9f64),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(0.6f64),
            TogetherModel::CodellamaCodellama34bInstructHf => Some(0.776f64),
            TogetherModel::MetaLlamaLlama213bChatHf => Some(0.225f64),
            TogetherModel::NousresearchNousHermes2Mixtral8x7bDpo => Some(0.6f64),
            TogetherModel::ZeroOneAiYi34bChat => Some(0.8f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            TogetherModel::MetaLlamaLlama270bChatHf => Some(0f64),
            TogetherModel::MistralaiMixtral8x7bInstructV01 => Some(0f64),
            TogetherModel::CodellamaCodellama34bInstructHf => Some(0f64),
            TogetherModel::MetaLlamaLlama213bChatHf => Some(0f64),
            TogetherModel::NousresearchNousHermes2Mixtral8x7bDpo => Some(0f64),
            TogetherModel::ZeroOneAiYi34bChat => Some(0f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for Together {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            Together::MetaLlamaLlama270bChatHf => "meta-llama/Llama-2-70b-chat-hf",
            Together::MistralaiMixtral8x7bInstructV01 => {
                "mistralai/Mixtral-8x7B-Instruct-v0.1"
            }
            Together::CodellamaCodellama34bInstructHf => {
                "codellama/CodeLlama-34b-Instruct-hf"
            }
            Together::MetaLlamaLlama213bChatHf => "meta-llama/Llama-2-13b-chat-hf",
            Together::NousresearchNousHermes2Mixtral8x7bDpo => {
                "NousResearch/Nous-Hermes-2-Mixtral-8x7B-DPO"
            }
            Together::ZeroOneAiYi34bChat => "zero-one-ai/Yi-34B-Chat",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "together"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            Together::MetaLlamaLlama270bChatHf => Some(4096u32),
            Together::MistralaiMixtral8x7bInstructV01 => Some(24576u32),
            Together::CodellamaCodellama34bInstructHf => Some(12288u32),
            Together::MetaLlamaLlama213bChatHf => Some(4096u32),
            Together::NousresearchNousHermes2Mixtral8x7bDpo => Some(24576u32),
            Together::ZeroOneAiYi34bChat => Some(4096u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            Together::MetaLlamaLlama270bChatHf => Some(1024u32),
            Together::MistralaiMixtral8x7bInstructV01 => Some(8192u32),
            Together::CodellamaCodellama34bInstructHf => Some(4096u32),
            Together::MetaLlamaLlama213bChatHf => Some(1024u32),
            Together::NousresearchNousHermes2Mixtral8x7bDpo => Some(8192u32),
            Together::ZeroOneAiYi34bChat => Some(1024u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            Together::MetaLlamaLlama270bChatHf => Some(0.9f64),
            Together::MistralaiMixtral8x7bInstructV01 => Some(0.6f64),
            Together::CodellamaCodellama34bInstructHf => Some(0.776f64),
            Together::MetaLlamaLlama213bChatHf => Some(0.225f64),
            Together::NousresearchNousHermes2Mixtral8x7bDpo => Some(0.6f64),
            Together::ZeroOneAiYi34bChat => Some(0.8f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            Together::MetaLlamaLlama270bChatHf => Some(0.9f64),
            Together::MistralaiMixtral8x7bInstructV01 => Some(0.6f64),
            Together::CodellamaCodellama34bInstructHf => Some(0.776f64),
            Together::MetaLlamaLlama213bChatHf => Some(0.225f64),
            Together::NousresearchNousHermes2Mixtral8x7bDpo => Some(0.6f64),
            Together::ZeroOneAiYi34bChat => Some(0.8f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            Together::MetaLlamaLlama270bChatHf => Some(0f64),
            Together::MistralaiMixtral8x7bInstructV01 => Some(0f64),
            Together::CodellamaCodellama34bInstructHf => Some(0f64),
            Together::MetaLlamaLlama213bChatHf => Some(0f64),
            Together::NousresearchNousHermes2Mixtral8x7bDpo => Some(0f64),
            Together::ZeroOneAiYi34bChat => Some(0f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for OpenrouterModel {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            OpenrouterModel::OpenaiGpt4 => "openai/gpt-4",
            OpenrouterModel::OpenaiGpt35Turbo => "openai/gpt-3.5-turbo",
            OpenrouterModel::AnthropicClaude3Sonnet => "anthropic/claude-3-sonnet",
            OpenrouterModel::AnthropicClaude3Haiku => "anthropic/claude-3-haiku",
            OpenrouterModel::MetaLlamaLlama38bInstruct => {
                "meta-llama/llama-3-8b-instruct"
            }
            OpenrouterModel::MetaLlamaLlama370bInstruct => {
                "meta-llama/llama-3-70b-instruct"
            }
            OpenrouterModel::GoogleGemma7bIt => "google/gemma-7b-it",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "openrouter"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            OpenrouterModel::OpenaiGpt4 => Some(6144u32),
            OpenrouterModel::OpenaiGpt35Turbo => Some(4096u32),
            OpenrouterModel::AnthropicClaude3Sonnet => Some(150000u32),
            OpenrouterModel::AnthropicClaude3Haiku => Some(150000u32),
            OpenrouterModel::MetaLlamaLlama38bInstruct => Some(6144u32),
            OpenrouterModel::MetaLlamaLlama370bInstruct => Some(6144u32),
            OpenrouterModel::GoogleGemma7bIt => Some(6144u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            OpenrouterModel::OpenaiGpt4 => Some(2048u32),
            OpenrouterModel::OpenaiGpt35Turbo => Some(1024u32),
            OpenrouterModel::AnthropicClaude3Sonnet => Some(50000u32),
            OpenrouterModel::AnthropicClaude3Haiku => Some(50000u32),
            OpenrouterModel::MetaLlamaLlama38bInstruct => Some(2048u32),
            OpenrouterModel::MetaLlamaLlama370bInstruct => Some(2048u32),
            OpenrouterModel::GoogleGemma7bIt => Some(2048u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            OpenrouterModel::OpenaiGpt4 => Some(0.03f64),
            OpenrouterModel::OpenaiGpt35Turbo => Some(0.002f64),
            OpenrouterModel::AnthropicClaude3Sonnet => Some(0.003f64),
            OpenrouterModel::AnthropicClaude3Haiku => Some(0.00025f64),
            OpenrouterModel::MetaLlamaLlama38bInstruct => Some(0.00018f64),
            OpenrouterModel::MetaLlamaLlama370bInstruct => Some(0.00059f64),
            OpenrouterModel::GoogleGemma7bIt => Some(0.00013f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            OpenrouterModel::OpenaiGpt4 => Some(0.06f64),
            OpenrouterModel::OpenaiGpt35Turbo => Some(0.002f64),
            OpenrouterModel::AnthropicClaude3Sonnet => Some(0.015f64),
            OpenrouterModel::AnthropicClaude3Haiku => Some(0.00125f64),
            OpenrouterModel::MetaLlamaLlama38bInstruct => Some(0.00018f64),
            OpenrouterModel::MetaLlamaLlama370bInstruct => Some(0.00079f64),
            OpenrouterModel::GoogleGemma7bIt => Some(0.00013f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            OpenrouterModel::OpenaiGpt4 => Some(0f64),
            OpenrouterModel::OpenaiGpt35Turbo => Some(0f64),
            OpenrouterModel::AnthropicClaude3Sonnet => Some(0f64),
            OpenrouterModel::AnthropicClaude3Haiku => Some(0f64),
            OpenrouterModel::MetaLlamaLlama38bInstruct => Some(0f64),
            OpenrouterModel::MetaLlamaLlama370bInstruct => Some(0f64),
            OpenrouterModel::GoogleGemma7bIt => Some(0f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for OpenRouter {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            OpenRouter::OpenaiGpt4 => "openai/gpt-4",
            OpenRouter::OpenaiGpt35Turbo => "openai/gpt-3.5-turbo",
            OpenRouter::AnthropicClaude3Sonnet => "anthropic/claude-3-sonnet",
            OpenRouter::AnthropicClaude3Haiku => "anthropic/claude-3-haiku",
            OpenRouter::MetaLlamaLlama38bInstruct => "meta-llama/llama-3-8b-instruct",
            OpenRouter::MetaLlamaLlama370bInstruct => "meta-llama/llama-3-70b-instruct",
            OpenRouter::GoogleGemma7bIt => "google/gemma-7b-it",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "openrouter"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            OpenRouter::OpenaiGpt4 => Some(6144u32),
            OpenRouter::OpenaiGpt35Turbo => Some(4096u32),
            OpenRouter::AnthropicClaude3Sonnet => Some(150000u32),
            OpenRouter::AnthropicClaude3Haiku => Some(150000u32),
            OpenRouter::MetaLlamaLlama38bInstruct => Some(6144u32),
            OpenRouter::MetaLlamaLlama370bInstruct => Some(6144u32),
            OpenRouter::GoogleGemma7bIt => Some(6144u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            OpenRouter::OpenaiGpt4 => Some(2048u32),
            OpenRouter::OpenaiGpt35Turbo => Some(1024u32),
            OpenRouter::AnthropicClaude3Sonnet => Some(50000u32),
            OpenRouter::AnthropicClaude3Haiku => Some(50000u32),
            OpenRouter::MetaLlamaLlama38bInstruct => Some(2048u32),
            OpenRouter::MetaLlamaLlama370bInstruct => Some(2048u32),
            OpenRouter::GoogleGemma7bIt => Some(2048u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            OpenRouter::OpenaiGpt4 => Some(0.03f64),
            OpenRouter::OpenaiGpt35Turbo => Some(0.002f64),
            OpenRouter::AnthropicClaude3Sonnet => Some(0.003f64),
            OpenRouter::AnthropicClaude3Haiku => Some(0.00025f64),
            OpenRouter::MetaLlamaLlama38bInstruct => Some(0.00018f64),
            OpenRouter::MetaLlamaLlama370bInstruct => Some(0.00059f64),
            OpenRouter::GoogleGemma7bIt => Some(0.00013f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            OpenRouter::OpenaiGpt4 => Some(0.06f64),
            OpenRouter::OpenaiGpt35Turbo => Some(0.002f64),
            OpenRouter::AnthropicClaude3Sonnet => Some(0.015f64),
            OpenRouter::AnthropicClaude3Haiku => Some(0.00125f64),
            OpenRouter::MetaLlamaLlama38bInstruct => Some(0.00018f64),
            OpenRouter::MetaLlamaLlama370bInstruct => Some(0.00079f64),
            OpenRouter::GoogleGemma7bIt => Some(0.00013f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            OpenRouter::OpenaiGpt4 => Some(0f64),
            OpenRouter::OpenaiGpt35Turbo => Some(0f64),
            OpenRouter::AnthropicClaude3Sonnet => Some(0f64),
            OpenRouter::AnthropicClaude3Haiku => Some(0f64),
            OpenRouter::MetaLlamaLlama38bInstruct => Some(0f64),
            OpenRouter::MetaLlamaLlama370bInstruct => Some(0f64),
            OpenRouter::GoogleGemma7bIt => Some(0f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for HuggingfaceModel {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            HuggingfaceModel::MetaLlamaLlama270bChatHf => {
                "meta-llama/Llama-2-70b-chat-hf"
            }
            HuggingfaceModel::MetaLlamaLlama213bChatHf => {
                "meta-llama/Llama-2-13b-chat-hf"
            }
            HuggingfaceModel::MetaLlamaLlama27bChatHf => "meta-llama/Llama-2-7b-chat-hf",
            HuggingfaceModel::MistralaiMixtral8x7bInstructV01 => {
                "mistralai/Mixtral-8x7B-Instruct-v0.1"
            }
            HuggingfaceModel::MistralaiMistral7bInstructV01 => {
                "mistralai/Mistral-7B-Instruct-v0.1"
            }
            HuggingfaceModel::CodellamaCodellama34bInstructHf => {
                "codellama/CodeLlama-34b-Instruct-hf"
            }
            HuggingfaceModel::CodellamaCodellama13bInstructHf => {
                "codellama/CodeLlama-13b-Instruct-hf"
            }
            HuggingfaceModel::CodellamaCodellama7bInstructHf => {
                "codellama/CodeLlama-7b-Instruct-hf"
            }
            HuggingfaceModel::GoogleGemma7bIt => "google/gemma-7b-it",
            HuggingfaceModel::GoogleGemma2bIt => "google/gemma-2b-it",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "huggingface"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            HuggingfaceModel::MetaLlamaLlama270bChatHf => Some(4096u32),
            HuggingfaceModel::MetaLlamaLlama213bChatHf => Some(4096u32),
            HuggingfaceModel::MetaLlamaLlama27bChatHf => Some(4096u32),
            HuggingfaceModel::MistralaiMixtral8x7bInstructV01 => Some(24576u32),
            HuggingfaceModel::MistralaiMistral7bInstructV01 => Some(6144u32),
            HuggingfaceModel::CodellamaCodellama34bInstructHf => Some(12288u32),
            HuggingfaceModel::CodellamaCodellama13bInstructHf => Some(12288u32),
            HuggingfaceModel::CodellamaCodellama7bInstructHf => Some(12288u32),
            HuggingfaceModel::GoogleGemma7bIt => Some(6144u32),
            HuggingfaceModel::GoogleGemma2bIt => Some(6144u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            HuggingfaceModel::MetaLlamaLlama270bChatHf => Some(1024u32),
            HuggingfaceModel::MetaLlamaLlama213bChatHf => Some(1024u32),
            HuggingfaceModel::MetaLlamaLlama27bChatHf => Some(1024u32),
            HuggingfaceModel::MistralaiMixtral8x7bInstructV01 => Some(8192u32),
            HuggingfaceModel::MistralaiMistral7bInstructV01 => Some(2048u32),
            HuggingfaceModel::CodellamaCodellama34bInstructHf => Some(4096u32),
            HuggingfaceModel::CodellamaCodellama13bInstructHf => Some(4096u32),
            HuggingfaceModel::CodellamaCodellama7bInstructHf => Some(4096u32),
            HuggingfaceModel::GoogleGemma7bIt => Some(2048u32),
            HuggingfaceModel::GoogleGemma2bIt => Some(2048u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            HuggingfaceModel::MetaLlamaLlama270bChatHf => Some(0f64),
            HuggingfaceModel::MetaLlamaLlama213bChatHf => Some(0f64),
            HuggingfaceModel::MetaLlamaLlama27bChatHf => Some(0f64),
            HuggingfaceModel::MistralaiMixtral8x7bInstructV01 => Some(0f64),
            HuggingfaceModel::MistralaiMistral7bInstructV01 => Some(0f64),
            HuggingfaceModel::CodellamaCodellama34bInstructHf => Some(0f64),
            HuggingfaceModel::CodellamaCodellama13bInstructHf => Some(0f64),
            HuggingfaceModel::CodellamaCodellama7bInstructHf => Some(0f64),
            HuggingfaceModel::GoogleGemma7bIt => Some(0f64),
            HuggingfaceModel::GoogleGemma2bIt => Some(0f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            HuggingfaceModel::MetaLlamaLlama270bChatHf => Some(0f64),
            HuggingfaceModel::MetaLlamaLlama213bChatHf => Some(0f64),
            HuggingfaceModel::MetaLlamaLlama27bChatHf => Some(0f64),
            HuggingfaceModel::MistralaiMixtral8x7bInstructV01 => Some(0f64),
            HuggingfaceModel::MistralaiMistral7bInstructV01 => Some(0f64),
            HuggingfaceModel::CodellamaCodellama34bInstructHf => Some(0f64),
            HuggingfaceModel::CodellamaCodellama13bInstructHf => Some(0f64),
            HuggingfaceModel::CodellamaCodellama7bInstructHf => Some(0f64),
            HuggingfaceModel::GoogleGemma7bIt => Some(0f64),
            HuggingfaceModel::GoogleGemma2bIt => Some(0f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        None
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for HuggingFace {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            HuggingFace::MetaLlamaLlama270bChatHf => "meta-llama/Llama-2-70b-chat-hf",
            HuggingFace::MetaLlamaLlama213bChatHf => "meta-llama/Llama-2-13b-chat-hf",
            HuggingFace::MetaLlamaLlama27bChatHf => "meta-llama/Llama-2-7b-chat-hf",
            HuggingFace::MistralaiMixtral8x7bInstructV01 => {
                "mistralai/Mixtral-8x7B-Instruct-v0.1"
            }
            HuggingFace::MistralaiMistral7bInstructV01 => {
                "mistralai/Mistral-7B-Instruct-v0.1"
            }
            HuggingFace::CodellamaCodellama34bInstructHf => {
                "codellama/CodeLlama-34b-Instruct-hf"
            }
            HuggingFace::CodellamaCodellama13bInstructHf => {
                "codellama/CodeLlama-13b-Instruct-hf"
            }
            HuggingFace::CodellamaCodellama7bInstructHf => {
                "codellama/CodeLlama-7b-Instruct-hf"
            }
            HuggingFace::GoogleGemma7bIt => "google/gemma-7b-it",
            HuggingFace::GoogleGemma2bIt => "google/gemma-2b-it",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "huggingface"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            HuggingFace::MetaLlamaLlama270bChatHf => Some(4096u32),
            HuggingFace::MetaLlamaLlama213bChatHf => Some(4096u32),
            HuggingFace::MetaLlamaLlama27bChatHf => Some(4096u32),
            HuggingFace::MistralaiMixtral8x7bInstructV01 => Some(24576u32),
            HuggingFace::MistralaiMistral7bInstructV01 => Some(6144u32),
            HuggingFace::CodellamaCodellama34bInstructHf => Some(12288u32),
            HuggingFace::CodellamaCodellama13bInstructHf => Some(12288u32),
            HuggingFace::CodellamaCodellama7bInstructHf => Some(12288u32),
            HuggingFace::GoogleGemma7bIt => Some(6144u32),
            HuggingFace::GoogleGemma2bIt => Some(6144u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            HuggingFace::MetaLlamaLlama270bChatHf => Some(1024u32),
            HuggingFace::MetaLlamaLlama213bChatHf => Some(1024u32),
            HuggingFace::MetaLlamaLlama27bChatHf => Some(1024u32),
            HuggingFace::MistralaiMixtral8x7bInstructV01 => Some(8192u32),
            HuggingFace::MistralaiMistral7bInstructV01 => Some(2048u32),
            HuggingFace::CodellamaCodellama34bInstructHf => Some(4096u32),
            HuggingFace::CodellamaCodellama13bInstructHf => Some(4096u32),
            HuggingFace::CodellamaCodellama7bInstructHf => Some(4096u32),
            HuggingFace::GoogleGemma7bIt => Some(2048u32),
            HuggingFace::GoogleGemma2bIt => Some(2048u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            HuggingFace::MetaLlamaLlama270bChatHf => Some(0f64),
            HuggingFace::MetaLlamaLlama213bChatHf => Some(0f64),
            HuggingFace::MetaLlamaLlama27bChatHf => Some(0f64),
            HuggingFace::MistralaiMixtral8x7bInstructV01 => Some(0f64),
            HuggingFace::MistralaiMistral7bInstructV01 => Some(0f64),
            HuggingFace::CodellamaCodellama34bInstructHf => Some(0f64),
            HuggingFace::CodellamaCodellama13bInstructHf => Some(0f64),
            HuggingFace::CodellamaCodellama7bInstructHf => Some(0f64),
            HuggingFace::GoogleGemma7bIt => Some(0f64),
            HuggingFace::GoogleGemma2bIt => Some(0f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            HuggingFace::MetaLlamaLlama270bChatHf => Some(0f64),
            HuggingFace::MetaLlamaLlama213bChatHf => Some(0f64),
            HuggingFace::MetaLlamaLlama27bChatHf => Some(0f64),
            HuggingFace::MistralaiMixtral8x7bInstructV01 => Some(0f64),
            HuggingFace::MistralaiMistral7bInstructV01 => Some(0f64),
            HuggingFace::CodellamaCodellama34bInstructHf => Some(0f64),
            HuggingFace::CodellamaCodellama13bInstructHf => Some(0f64),
            HuggingFace::CodellamaCodellama7bInstructHf => Some(0f64),
            HuggingFace::GoogleGemma7bIt => Some(0f64),
            HuggingFace::GoogleGemma2bIt => Some(0f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        false
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        None
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        None
    }
}


impl crate::common::Model for XaiModel {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            XaiModel::Grok2 => "grok-2",
            XaiModel::Grok2Mini => "grok-2-mini",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "xai"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            XaiModel::Grok2 => Some(98304u32),
            XaiModel::Grok2Mini => Some(98304u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            XaiModel::Grok2 => Some(32768u32),
            XaiModel::Grok2Mini => Some(32768u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            XaiModel::Grok2 => Some(2f64),
            XaiModel::Grok2Mini => Some(0.3f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            XaiModel::Grok2 => Some(10f64),
            XaiModel::Grok2Mini => Some(0.5f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        match self {
            XaiModel::Grok2 => true,
            XaiModel::Grok2Mini => true,
            _ => false,
        }
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            XaiModel::Grok2 => Some(1f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        match self {
            XaiModel::Grok2 => Some(100000u32),
            XaiModel::Grok2Mini => Some(100000u32),
            _ => None,
        }
    }
}


impl crate::common::Model for XAI {
    #[inline]
    fn name(&self) -> &'static str {
        match self {
            XAI::Grok2 => "grok-2",
            XAI::Grok2Mini => "grok-2-mini",
        }
    }
    #[inline]
    fn provider_name(&self) -> &'static str {
        "xai"
    }
    #[inline]
    fn max_input_tokens(&self) -> Option<u32> {
        match self {
            XAI::Grok2 => Some(98304u32),
            XAI::Grok2Mini => Some(98304u32),
        }
    }
    #[inline]
    fn max_output_tokens(&self) -> Option<u32> {
        match self {
            XAI::Grok2 => Some(32768u32),
            XAI::Grok2Mini => Some(32768u32),
        }
    }
    #[inline]
    fn pricing_input(&self) -> Option<f64> {
        match self {
            XAI::Grok2 => Some(2f64),
            XAI::Grok2Mini => Some(0.3f64),
        }
    }
    #[inline]
    fn pricing_output(&self) -> Option<f64> {
        match self {
            XAI::Grok2 => Some(10f64),
            XAI::Grok2Mini => Some(0.5f64),
        }
    }
    #[inline]
    fn supports_vision(&self) -> bool {
        false
    }
    #[inline]
    fn supports_function_calling(&self) -> bool {
        true
    }
    #[inline]
    fn supports_embeddings(&self) -> bool {
        false
    }
    #[inline]
    fn requires_max_tokens(&self) -> bool {
        false
    }
    #[inline]
    fn supports_thinking(&self) -> bool {
        match self {
            XAI::Grok2 => true,
            XAI::Grok2Mini => true,
            _ => false,
        }
    }
    #[inline]
    fn required_temperature(&self) -> Option<f64> {
        match self {
            XAI::Grok2 => Some(1f64),
            _ => None,
        }
    }
    #[inline]
    fn optimal_thinking_budget(&self) -> Option<u32> {
        match self {
            XAI::Grok2 => Some(100000u32),
            XAI::Grok2Mini => Some(100000u32),
            _ => None,
        }
    }
}

