#![doc = r" Generated provider and model definitions from AiChat models.yaml"]
#![doc = r" "]
#![doc = r" This file is auto-generated. Do not edit manually."]
#![doc = r" Generated from: https://github.com/sigoden/aichat/blob/main/models.yaml"]
use serde::{Deserialize, Serialize};
// use std::collections::HashMap; // Commented out - unused
#[derive(Debug, Clone, PartialEq, Serialize, Deserialize)]
pub struct ModelInfo {
    pub provider: Provider,
    pub name: String,
    pub max_input_tokens: Option<u64>,
    pub max_output_tokens: Option<u64>,
    pub input_price: Option<f64>,
    pub output_price: Option<f64>,
    pub supports_vision: Option<bool>,
    pub supports_function_calling: Option<bool>,
    pub require_max_tokens: Option<bool>,
}
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum Provider {
    Openai,
    Gemini,
    Claude,
    Mistral,
    Ai21,
    Cohere,
    Xai,
    Perplexity,
    Groq,
    Vertexai,
    Bedrock,
    Cloudflare,
    Ernie,
    Qianwen,
    Hunyuan,
    Moonshot,
    Deepseek,
    Zhipuai,
    Minimax,
    Openrouter,
    Github,
    Deepinfra,
    Jina,
    Voyageai,
}
#[derive(Debug, Clone, PartialEq, Eq, Hash, Serialize, Deserialize)]
pub enum Model {
    Ai21JambaLarge,
    Ai21JambaMini,
    BedrockAnthropicClaude35Haiku20241022V10,
    BedrockAnthropicClaude35Sonnet20241022V20,
    BedrockCohereEmbedEnglishV3,
    BedrockCohereEmbedMultilingualV3,
    BedrockUsAmazonNovaLiteV10,
    BedrockUsAmazonNovaMicroV10,
    BedrockUsAmazonNovaPremierV10,
    BedrockUsAmazonNovaProV10,
    BedrockUsAnthropicClaude37Sonnet20250219V10,
    BedrockUsAnthropicClaude37Sonnet20250219V10Thinking,
    BedrockUsAnthropicClaudeOpus420250514V10,
    BedrockUsAnthropicClaudeOpus420250514V10Thinking,
    BedrockUsAnthropicClaudeSonnet420250514V10,
    BedrockUsAnthropicClaudeSonnet420250514V10Thinking,
    BedrockUsDeepseekR1V10,
    BedrockUsMetaLlama3370bInstructV10,
    BedrockUsMetaLlama4Maverick17bInstructV10,
    BedrockUsMetaLlama4Scout17bInstructV10,
    ClaudeClaude35Haiku20241022,
    ClaudeClaude35Sonnet20241022,
    ClaudeClaude37Sonnet20250219,
    ClaudeClaude37Sonnet20250219Thinking,
    ClaudeClaudeOpus420250514,
    ClaudeClaudeOpus420250514Thinking,
    ClaudeClaudeSonnet420250514,
    ClaudeClaudeSonnet420250514Thinking,
    CloudflareCfBaaiBgeLargeEnV15,
    CloudflareCfGoogleGemma312bIt,
    CloudflareCfMetaLlama3370bInstructFp8Fast,
    CloudflareCfMetaLlama4Scout17b16eInstruct,
    CloudflareCfMistralaiMistralSmall3124bInstruct,
    CloudflareCfQwenQwen25Coder32bInstruct,
    CloudflareCfQwenQwq32b,
    CohereCommandA032025,
    CohereCommandR7b122024,
    CohereEmbedEnglishV30,
    CohereEmbedMultilingualV30,
    CohereEmbedV40,
    CohereRerankEnglishV30,
    CohereRerankMultilingualV30,
    CohereRerankV35,
    DeepinfraBaaiBgeLargeEnV15,
    DeepinfraBaaiBgeM3,
    DeepinfraDeepseekAiDeepseekR10528,
    DeepinfraDeepseekAiDeepseekV30324,
    DeepinfraGoogleGemma327bIt,
    DeepinfraIntfloatE5LargeV2,
    DeepinfraIntfloatMultilingualE5Large,
    DeepinfraMetaLlamaLlama3370bInstruct,
    DeepinfraMetaLlamaLlama4Maverick17b128eInstructFp8,
    DeepinfraMetaLlamaLlama4Scout17b16eInstruct,
    DeepinfraMicrosoftPhi4ReasoningPlus,
    DeepinfraMistralaiDevstralSmall2505,
    DeepinfraMistralaiMistralSmall3224bInstruct2506,
    DeepinfraQwenQwen2572bInstruct,
    DeepinfraQwenQwen25Coder32bInstruct,
    DeepinfraQwenQwen3235bA22b,
    DeepinfraQwenQwen330bA3b,
    DeepinfraQwenQwen332b,
    DeepinfraQwenQwq32b,
    DeepinfraThenlperGteLarge,
    DeepseekDeepseekChat,
    DeepseekDeepseekReasoner,
    ErnieBceRerankerBase,
    ErnieBgeLargeEn,
    ErnieBgeLargeZh,
    ErnieErnie45Turbo128k,
    ErnieErnie45TurboVl32k,
    ErnieErnieX1Turbo32k,
    GeminiGemini20Flash,
    GeminiGemini20FlashLite,
    GeminiGemini25Flash,
    GeminiGemini25FlashLitePreview0617,
    GeminiGemini25Pro,
    GeminiGemma327bIt,
    GeminiTextEmbedding004,
    GithubCodestral2501,
    GithubCohereEmbedV3English,
    GithubCohereEmbedV3Multilingual,
    GithubDeepseekR10528,
    GithubDeepseekV30324,
    GithubGpt41,
    GithubGpt41Mini,
    GithubGpt41Nano,
    GithubGpt4o,
    GithubGpt4oMini,
    GithubGrok3,
    GithubGrok3Mini,
    GithubLlama3370bInstruct,
    GithubLlama4Maverick17b128eInstructFp8,
    GithubLlama4Scout17b16eInstruct,
    GithubMaiDsR1,
    GithubMistralMedium2505,
    GithubMistralSmall2503,
    GithubO3,
    GithubO3Mini,
    GithubO3MiniHigh,
    GithubO4Mini,
    GithubO4MiniHigh,
    GithubPhi4,
    GithubPhi4MiniInstruct,
    GithubPhi4MiniReasoning,
    GithubPhi4Reasoning,
    GithubTextEmbedding3Large,
    GithubTextEmbedding3Small,
    GroqLlama3370bVersatile,
    GroqMetaLlamaLlama4Maverick17b128eInstruct,
    GroqMetaLlamaLlama4Scout17b16eInstruct,
    GroqQwenQwen332b,
    GroqQwenQwq32b,
    HunyuanHunyuanEmbedding,
    HunyuanHunyuanLite,
    HunyuanHunyuanT1Latest,
    HunyuanHunyuanT1Vision,
    HunyuanHunyuanTurbosLatest,
    HunyuanHunyuanTurbosVision,
    JinaJinaClipV2,
    JinaJinaColbertV2,
    JinaJinaEmbeddingsV3,
    JinaJinaRerankerV2BaseMultilingual,
    MinimaxMinimaxM1,
    MinimaxMinimaxText01,
    MistralCodestralLatest,
    MistralDevstralSmallLatest,
    MistralMagistralMediumLatest,
    MistralMagistralSmallLatest,
    MistralMistralEmbed,
    MistralMistralMediumLatest,
    MistralMistralSmallLatest,
    MoonshotKimiLatest,
    MoonshotKimiThinkingPreview,
    OpenaiChatgpt4oLatest,
    OpenaiGpt35Turbo,
    OpenaiGpt41,
    OpenaiGpt41Mini,
    OpenaiGpt41Nano,
    OpenaiGpt4Turbo,
    OpenaiGpt4o,
    OpenaiGpt4oMini,
    OpenaiGpt4oMiniSearchPreview,
    OpenaiGpt4oSearchPreview,
    OpenaiO3,
    OpenaiO3Mini,
    OpenaiO3MiniHigh,
    OpenaiO4Mini,
    OpenaiO4MiniHigh,
    OpenaiTextEmbedding3Large,
    OpenaiTextEmbedding3Small,
    OpenrouterAi21Jamba16Large,
    OpenrouterAi21Jamba16Mini,
    OpenrouterAmazonNovaLiteV1,
    OpenrouterAmazonNovaMicroV1,
    OpenrouterAmazonNovaProV1,
    OpenrouterAnthropicClaude35Haiku,
    OpenrouterAnthropicClaude35Sonnet,
    OpenrouterAnthropicClaude37Sonnet,
    OpenrouterAnthropicClaude37SonnetThinking,
    OpenrouterAnthropicClaudeOpus4,
    OpenrouterAnthropicClaudeSonnet4,
    OpenrouterCohereCommandA,
    OpenrouterCohereCommandR7b122024,
    OpenrouterDeepseekDeepseekChatV30324,
    OpenrouterDeepseekDeepseekR10528,
    OpenrouterGoogleGemini20Flash001,
    OpenrouterGoogleGemini20FlashLite001,
    OpenrouterGoogleGemini25Flash,
    OpenrouterGoogleGemini25FlashLitePreview0617,
    OpenrouterGoogleGemini25Pro,
    OpenrouterGoogleGemma327bIt,
    OpenrouterMetaLlamaLlama3370bInstruct,
    OpenrouterMetaLlamaLlama4Maverick,
    OpenrouterMetaLlamaLlama4Scout,
    OpenrouterMicrosoftPhi4ReasoningPlus,
    OpenrouterMinimaxMinimax01,
    OpenrouterMistralaiCodestral2501,
    OpenrouterMistralaiDevstralSmall,
    OpenrouterMistralaiMagistralMedium2506,
    OpenrouterMistralaiMagistralMedium2506Thinking,
    OpenrouterMistralaiMagistralSmall2506,
    OpenrouterMistralaiMistralMedium3,
    OpenrouterMistralaiMistralSmall3224bInstruct,
    OpenrouterOpenaiChatgpt4oLatest,
    OpenrouterOpenaiGpt41,
    OpenrouterOpenaiGpt41Mini,
    OpenrouterOpenaiGpt41Nano,
    OpenrouterOpenaiGpt4o,
    OpenrouterOpenaiGpt4oMini,
    OpenrouterOpenaiGpt4oMiniSearchPreview,
    OpenrouterOpenaiGpt4oSearchPreview,
    OpenrouterOpenaiO3,
    OpenrouterOpenaiO3Mini,
    OpenrouterOpenaiO3MiniHigh,
    OpenrouterOpenaiO3Pro,
    OpenrouterOpenaiO4Mini,
    OpenrouterOpenaiO4MiniHigh,
    OpenrouterPerplexityR11776,
    OpenrouterPerplexitySonar,
    OpenrouterPerplexitySonarDeepResearch,
    OpenrouterPerplexitySonarPro,
    OpenrouterPerplexitySonarReasoning,
    OpenrouterPerplexitySonarReasoningPro,
    OpenrouterQwenQwen2572bInstruct,
    OpenrouterQwenQwen25Coder32bInstruct,
    OpenrouterQwenQwen25Vl72bInstruct,
    OpenrouterQwenQwen3235bA22b,
    OpenrouterQwenQwen330bA3b,
    OpenrouterQwenQwen332b,
    OpenrouterQwenQwenMax,
    OpenrouterQwenQwenPlus,
    OpenrouterQwenQwenTurbo,
    OpenrouterQwenQwenVlPlus,
    OpenrouterQwenQwq32b,
    OpenrouterThudmGlm432b,
    OpenrouterThudmGlmZ132b,
    OpenrouterXAiGrok3,
    OpenrouterXAiGrok3Mini,
    PerplexityR11776,
    PerplexitySonar,
    PerplexitySonarDeepResearch,
    PerplexitySonarPro,
    PerplexitySonarReasoning,
    PerplexitySonarReasoningPro,
    QianwenDeepseekR10528,
    QianwenDeepseekV3,
    QianwenQwen2572bInstruct,
    QianwenQwen25Coder32bInstruct,
    QianwenQwen25Vl72bInstruct,
    QianwenQwen3235bA22b,
    QianwenQwen330bA3b,
    QianwenQwen332b,
    QianwenQwenLong,
    QianwenQwenMaxLatest,
    QianwenQwenOmniTurboLatest,
    QianwenQwenPlusLatest,
    QianwenQwenTurboLatest,
    QianwenQwenVlMaxLatest,
    QianwenQwenVlPlusLatest,
    QianwenQwq32b,
    QianwenQwqPlusLatest,
    QianwenTextEmbeddingV3,
    QianwenTextEmbeddingV4,
    VertexaiClaude35Haiku20241022,
    VertexaiClaude35SonnetV220241022,
    VertexaiClaude37Sonnet20250219,
    VertexaiClaude37Sonnet20250219Thinking,
    VertexaiClaudeOpus420250514,
    VertexaiClaudeOpus420250514Thinking,
    VertexaiClaudeSonnet420250514,
    VertexaiClaudeSonnet420250514Thinking,
    VertexaiCodestral2501,
    VertexaiGemini20Flash001,
    VertexaiGemini20FlashLite001,
    VertexaiGemini25Flash,
    VertexaiGemini25FlashLitePreview0617,
    VertexaiGemini25Pro,
    VertexaiMistralSmall2503,
    VertexaiTextEmbedding005,
    VertexaiTextMultilingualEmbedding002,
    VoyageaiRerank2,
    VoyageaiRerank2Lite,
    VoyageaiVoyage3,
    VoyageaiVoyage3Large,
    VoyageaiVoyage3Lite,
    XaiGrok3FastLatest,
    XaiGrok3Latest,
    XaiGrok3MiniFastLatest,
    XaiGrok3MiniLatest,
    ZhipuaiEmbedding3,
    ZhipuaiGlm4Air,
    ZhipuaiGlm4Flash250414,
    ZhipuaiGlm4Long,
    ZhipuaiGlm4Plus,
    ZhipuaiGlm4vFlash,
    ZhipuaiGlm4vPlus0111,
    ZhipuaiGlmZ1Air,
    ZhipuaiGlmZ1Flash,
    ZhipuaiRerank,
}
impl Provider {
    #[doc = r" Get all models supported by this provider"]
    pub fn models(&self) -> Vec<Model> {
        match self {
            Provider::Openai => vec![
                Model::OpenaiGpt41,
                Model::OpenaiGpt41Mini,
                Model::OpenaiGpt41Nano,
                Model::OpenaiGpt4o,
                Model::OpenaiGpt4oSearchPreview,
                Model::OpenaiGpt4oMini,
                Model::OpenaiGpt4oMiniSearchPreview,
                Model::OpenaiChatgpt4oLatest,
                Model::OpenaiO4Mini,
                Model::OpenaiO4MiniHigh,
                Model::OpenaiO3,
                Model::OpenaiO3Mini,
                Model::OpenaiO3MiniHigh,
                Model::OpenaiGpt4Turbo,
                Model::OpenaiGpt35Turbo,
                Model::OpenaiTextEmbedding3Large,
                Model::OpenaiTextEmbedding3Small,
            ],
            Provider::Gemini => vec![
                Model::GeminiGemini25Flash,
                Model::GeminiGemini25Pro,
                Model::GeminiGemini25FlashLitePreview0617,
                Model::GeminiGemini20Flash,
                Model::GeminiGemini20FlashLite,
                Model::GeminiGemma327bIt,
                Model::GeminiTextEmbedding004,
            ],
            Provider::Claude => vec![
                Model::ClaudeClaudeOpus420250514,
                Model::ClaudeClaudeOpus420250514Thinking,
                Model::ClaudeClaudeSonnet420250514,
                Model::ClaudeClaudeSonnet420250514Thinking,
                Model::ClaudeClaude37Sonnet20250219,
                Model::ClaudeClaude37Sonnet20250219Thinking,
                Model::ClaudeClaude35Sonnet20241022,
                Model::ClaudeClaude35Haiku20241022,
            ],
            Provider::Mistral => vec![
                Model::MistralMistralMediumLatest,
                Model::MistralMistralSmallLatest,
                Model::MistralMagistralMediumLatest,
                Model::MistralMagistralSmallLatest,
                Model::MistralDevstralSmallLatest,
                Model::MistralCodestralLatest,
                Model::MistralMistralEmbed,
            ],
            Provider::Ai21 => vec![Model::Ai21JambaLarge, Model::Ai21JambaMini],
            Provider::Cohere => vec![
                Model::CohereCommandA032025,
                Model::CohereCommandR7b122024,
                Model::CohereEmbedV40,
                Model::CohereEmbedEnglishV30,
                Model::CohereEmbedMultilingualV30,
                Model::CohereRerankV35,
                Model::CohereRerankEnglishV30,
                Model::CohereRerankMultilingualV30,
            ],
            Provider::Xai => vec![
                Model::XaiGrok3Latest,
                Model::XaiGrok3FastLatest,
                Model::XaiGrok3MiniLatest,
                Model::XaiGrok3MiniFastLatest,
            ],
            Provider::Perplexity => vec![
                Model::PerplexitySonarPro,
                Model::PerplexitySonar,
                Model::PerplexitySonarReasoningPro,
                Model::PerplexitySonarReasoning,
                Model::PerplexitySonarDeepResearch,
                Model::PerplexityR11776,
            ],
            Provider::Groq => vec![
                Model::GroqMetaLlamaLlama4Maverick17b128eInstruct,
                Model::GroqMetaLlamaLlama4Scout17b16eInstruct,
                Model::GroqLlama3370bVersatile,
                Model::GroqQwenQwq32b,
                Model::GroqQwenQwen332b,
            ],
            Provider::Vertexai => vec![
                Model::VertexaiGemini25Flash,
                Model::VertexaiGemini25Pro,
                Model::VertexaiGemini25FlashLitePreview0617,
                Model::VertexaiGemini20Flash001,
                Model::VertexaiGemini20FlashLite001,
                Model::VertexaiClaudeOpus420250514,
                Model::VertexaiClaudeOpus420250514Thinking,
                Model::VertexaiClaudeSonnet420250514,
                Model::VertexaiClaudeSonnet420250514Thinking,
                Model::VertexaiClaude37Sonnet20250219,
                Model::VertexaiClaude37Sonnet20250219Thinking,
                Model::VertexaiClaude35SonnetV220241022,
                Model::VertexaiClaude35Haiku20241022,
                Model::VertexaiMistralSmall2503,
                Model::VertexaiCodestral2501,
                Model::VertexaiTextEmbedding005,
                Model::VertexaiTextMultilingualEmbedding002,
            ],
            Provider::Bedrock => vec![
                Model::BedrockUsAnthropicClaudeOpus420250514V10,
                Model::BedrockUsAnthropicClaudeOpus420250514V10Thinking,
                Model::BedrockUsAnthropicClaudeSonnet420250514V10,
                Model::BedrockUsAnthropicClaudeSonnet420250514V10Thinking,
                Model::BedrockUsAnthropicClaude37Sonnet20250219V10,
                Model::BedrockUsAnthropicClaude37Sonnet20250219V10Thinking,
                Model::BedrockAnthropicClaude35Sonnet20241022V20,
                Model::BedrockAnthropicClaude35Haiku20241022V10,
                Model::BedrockUsMetaLlama4Maverick17bInstructV10,
                Model::BedrockUsMetaLlama4Scout17bInstructV10,
                Model::BedrockUsMetaLlama3370bInstructV10,
                Model::BedrockUsAmazonNovaPremierV10,
                Model::BedrockUsAmazonNovaProV10,
                Model::BedrockUsAmazonNovaLiteV10,
                Model::BedrockUsAmazonNovaMicroV10,
                Model::BedrockCohereEmbedEnglishV3,
                Model::BedrockCohereEmbedMultilingualV3,
                Model::BedrockUsDeepseekR1V10,
            ],
            Provider::Cloudflare => vec![
                Model::CloudflareCfMetaLlama4Scout17b16eInstruct,
                Model::CloudflareCfMetaLlama3370bInstructFp8Fast,
                Model::CloudflareCfQwenQwq32b,
                Model::CloudflareCfQwenQwen25Coder32bInstruct,
                Model::CloudflareCfGoogleGemma312bIt,
                Model::CloudflareCfMistralaiMistralSmall3124bInstruct,
                Model::CloudflareCfBaaiBgeLargeEnV15,
            ],
            Provider::Ernie => vec![
                Model::ErnieErnie45Turbo128k,
                Model::ErnieErnie45TurboVl32k,
                Model::ErnieErnieX1Turbo32k,
                Model::ErnieBgeLargeZh,
                Model::ErnieBgeLargeEn,
                Model::ErnieBceRerankerBase,
            ],
            Provider::Qianwen => vec![
                Model::QianwenQwenMaxLatest,
                Model::QianwenQwenPlusLatest,
                Model::QianwenQwenTurboLatest,
                Model::QianwenQwenLong,
                Model::QianwenQwenOmniTurboLatest,
                Model::QianwenQwqPlusLatest,
                Model::QianwenQwenVlMaxLatest,
                Model::QianwenQwenVlPlusLatest,
                Model::QianwenQwen3235bA22b,
                Model::QianwenQwen330bA3b,
                Model::QianwenQwen332b,
                Model::QianwenQwq32b,
                Model::QianwenQwen2572bInstruct,
                Model::QianwenQwen25Vl72bInstruct,
                Model::QianwenQwen25Coder32bInstruct,
                Model::QianwenDeepseekV3,
                Model::QianwenDeepseekR10528,
                Model::QianwenTextEmbeddingV4,
                Model::QianwenTextEmbeddingV3,
            ],
            Provider::Hunyuan => vec![
                Model::HunyuanHunyuanTurbosLatest,
                Model::HunyuanHunyuanT1Latest,
                Model::HunyuanHunyuanLite,
                Model::HunyuanHunyuanTurbosVision,
                Model::HunyuanHunyuanT1Vision,
                Model::HunyuanHunyuanEmbedding,
            ],
            Provider::Moonshot => vec![
                Model::MoonshotKimiLatest,
                Model::MoonshotKimiThinkingPreview,
            ],
            Provider::Deepseek => {
                vec![Model::DeepseekDeepseekChat, Model::DeepseekDeepseekReasoner]
            }
            Provider::Zhipuai => vec![
                Model::ZhipuaiGlm4Plus,
                Model::ZhipuaiGlm4Air,
                Model::ZhipuaiGlm4Long,
                Model::ZhipuaiGlm4Flash250414,
                Model::ZhipuaiGlm4vPlus0111,
                Model::ZhipuaiGlm4vFlash,
                Model::ZhipuaiGlmZ1Air,
                Model::ZhipuaiGlmZ1Flash,
                Model::ZhipuaiEmbedding3,
                Model::ZhipuaiRerank,
            ],
            Provider::Minimax => vec![Model::MinimaxMinimaxText01, Model::MinimaxMinimaxM1],
            Provider::Openrouter => vec![
                Model::OpenrouterOpenaiGpt41,
                Model::OpenrouterOpenaiGpt41Mini,
                Model::OpenrouterOpenaiGpt41Nano,
                Model::OpenrouterOpenaiGpt4o,
                Model::OpenrouterOpenaiGpt4oSearchPreview,
                Model::OpenrouterOpenaiGpt4oMini,
                Model::OpenrouterOpenaiGpt4oMiniSearchPreview,
                Model::OpenrouterOpenaiChatgpt4oLatest,
                Model::OpenrouterOpenaiO4Mini,
                Model::OpenrouterOpenaiO4MiniHigh,
                Model::OpenrouterOpenaiO3Pro,
                Model::OpenrouterOpenaiO3,
                Model::OpenrouterOpenaiO3Mini,
                Model::OpenrouterOpenaiO3MiniHigh,
                Model::OpenrouterGoogleGemini25Flash,
                Model::OpenrouterGoogleGemini25Pro,
                Model::OpenrouterGoogleGemini25FlashLitePreview0617,
                Model::OpenrouterGoogleGemini20Flash001,
                Model::OpenrouterGoogleGemini20FlashLite001,
                Model::OpenrouterGoogleGemma327bIt,
                Model::OpenrouterAnthropicClaudeOpus4,
                Model::OpenrouterAnthropicClaudeSonnet4,
                Model::OpenrouterAnthropicClaude37Sonnet,
                Model::OpenrouterAnthropicClaude37SonnetThinking,
                Model::OpenrouterAnthropicClaude35Sonnet,
                Model::OpenrouterAnthropicClaude35Haiku,
                Model::OpenrouterMetaLlamaLlama4Maverick,
                Model::OpenrouterMetaLlamaLlama4Scout,
                Model::OpenrouterMetaLlamaLlama3370bInstruct,
                Model::OpenrouterMistralaiMistralMedium3,
                Model::OpenrouterMistralaiMistralSmall3224bInstruct,
                Model::OpenrouterMistralaiMagistralMedium2506,
                Model::OpenrouterMistralaiMagistralMedium2506Thinking,
                Model::OpenrouterMistralaiMagistralSmall2506,
                Model::OpenrouterMistralaiDevstralSmall,
                Model::OpenrouterMistralaiCodestral2501,
                Model::OpenrouterAi21Jamba16Large,
                Model::OpenrouterAi21Jamba16Mini,
                Model::OpenrouterCohereCommandA,
                Model::OpenrouterCohereCommandR7b122024,
                Model::OpenrouterDeepseekDeepseekChatV30324,
                Model::OpenrouterDeepseekDeepseekR10528,
                Model::OpenrouterQwenQwenMax,
                Model::OpenrouterQwenQwenPlus,
                Model::OpenrouterQwenQwenTurbo,
                Model::OpenrouterQwenQwenVlPlus,
                Model::OpenrouterQwenQwen3235bA22b,
                Model::OpenrouterQwenQwen330bA3b,
                Model::OpenrouterQwenQwen332b,
                Model::OpenrouterQwenQwq32b,
                Model::OpenrouterQwenQwen2572bInstruct,
                Model::OpenrouterQwenQwen25Vl72bInstruct,
                Model::OpenrouterQwenQwen25Coder32bInstruct,
                Model::OpenrouterXAiGrok3,
                Model::OpenrouterXAiGrok3Mini,
                Model::OpenrouterAmazonNovaProV1,
                Model::OpenrouterAmazonNovaLiteV1,
                Model::OpenrouterAmazonNovaMicroV1,
                Model::OpenrouterPerplexitySonarPro,
                Model::OpenrouterPerplexitySonar,
                Model::OpenrouterPerplexitySonarReasoningPro,
                Model::OpenrouterPerplexitySonarReasoning,
                Model::OpenrouterPerplexitySonarDeepResearch,
                Model::OpenrouterPerplexityR11776,
                Model::OpenrouterMinimaxMinimax01,
                Model::OpenrouterThudmGlm432b,
                Model::OpenrouterThudmGlmZ132b,
                Model::OpenrouterMicrosoftPhi4ReasoningPlus,
            ],
            Provider::Github => vec![
                Model::GithubGpt41,
                Model::GithubGpt41Mini,
                Model::GithubGpt41Nano,
                Model::GithubGpt4o,
                Model::GithubGpt4oMini,
                Model::GithubO4Mini,
                Model::GithubO4MiniHigh,
                Model::GithubO3,
                Model::GithubO3Mini,
                Model::GithubO3MiniHigh,
                Model::GithubTextEmbedding3Large,
                Model::GithubTextEmbedding3Small,
                Model::GithubLlama4Maverick17b128eInstructFp8,
                Model::GithubLlama4Scout17b16eInstruct,
                Model::GithubLlama3370bInstruct,
                Model::GithubMistralMedium2505,
                Model::GithubMistralSmall2503,
                Model::GithubCodestral2501,
                Model::GithubCohereEmbedV3English,
                Model::GithubCohereEmbedV3Multilingual,
                Model::GithubDeepseekR10528,
                Model::GithubDeepseekV30324,
                Model::GithubMaiDsR1,
                Model::GithubPhi4,
                Model::GithubPhi4MiniInstruct,
                Model::GithubPhi4Reasoning,
                Model::GithubPhi4MiniReasoning,
                Model::GithubGrok3,
                Model::GithubGrok3Mini,
            ],
            Provider::Deepinfra => vec![
                Model::DeepinfraMetaLlamaLlama4Maverick17b128eInstructFp8,
                Model::DeepinfraMetaLlamaLlama4Scout17b16eInstruct,
                Model::DeepinfraMetaLlamaLlama3370bInstruct,
                Model::DeepinfraQwenQwen3235bA22b,
                Model::DeepinfraQwenQwen330bA3b,
                Model::DeepinfraQwenQwen332b,
                Model::DeepinfraQwenQwq32b,
                Model::DeepinfraQwenQwen2572bInstruct,
                Model::DeepinfraQwenQwen25Coder32bInstruct,
                Model::DeepinfraDeepseekAiDeepseekV30324,
                Model::DeepinfraDeepseekAiDeepseekR10528,
                Model::DeepinfraGoogleGemma327bIt,
                Model::DeepinfraMistralaiMistralSmall3224bInstruct2506,
                Model::DeepinfraMistralaiDevstralSmall2505,
                Model::DeepinfraMicrosoftPhi4ReasoningPlus,
                Model::DeepinfraBaaiBgeLargeEnV15,
                Model::DeepinfraBaaiBgeM3,
                Model::DeepinfraIntfloatE5LargeV2,
                Model::DeepinfraIntfloatMultilingualE5Large,
                Model::DeepinfraThenlperGteLarge,
            ],
            Provider::Jina => vec![
                Model::JinaJinaEmbeddingsV3,
                Model::JinaJinaClipV2,
                Model::JinaJinaColbertV2,
                Model::JinaJinaRerankerV2BaseMultilingual,
                Model::JinaJinaColbertV2,
            ],
            Provider::Voyageai => vec![
                Model::VoyageaiVoyage3Large,
                Model::VoyageaiVoyage3,
                Model::VoyageaiVoyage3Lite,
                Model::VoyageaiRerank2,
                Model::VoyageaiRerank2Lite,
            ],
        }
    }
}
impl Model {
    #[doc = r" Get detailed information about this model"]
    pub fn info(&self) -> ModelInfo {
        match self {
            Model::OpenaiGpt41 => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4.1".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiGpt41Mini => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4.1-mini".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: Some(0.4f64),
                output_price: Some(1.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiGpt41Nano => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4.1-nano".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: Some(0.1f64),
                output_price: Some(0.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiGpt4o => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4o".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: Some(2.5f64),
                output_price: Some(10f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiGpt4oSearchPreview => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4o-search-preview".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: Some(2.5f64),
                output_price: Some(10f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenaiGpt4oMini => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4o-mini".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiGpt4oMiniSearchPreview => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4o-mini-search-preview".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenaiChatgpt4oLatest => ModelInfo {
                provider: Provider::Openai,
                name: "chatgpt-4o-latest".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: Some(5f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiO4Mini => ModelInfo {
                provider: Provider::Openai,
                name: "o4-mini".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiO4MiniHigh => ModelInfo {
                provider: Provider::Openai,
                name: "o4-mini-high".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiO3 => ModelInfo {
                provider: Provider::Openai,
                name: "o3".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(10f64),
                output_price: Some(40f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiO3Mini => ModelInfo {
                provider: Provider::Openai,
                name: "o3-mini".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiO3MiniHigh => ModelInfo {
                provider: Provider::Openai,
                name: "o3-mini-high".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiGpt4Turbo => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-4-turbo".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(4096u64),
                input_price: Some(10f64),
                output_price: Some(30f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiGpt35Turbo => ModelInfo {
                provider: Provider::Openai,
                name: "gpt-3.5-turbo".to_string(),
                max_input_tokens: Some(16385u64),
                max_output_tokens: Some(4096u64),
                input_price: Some(0.5f64),
                output_price: Some(1.5f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenaiTextEmbedding3Large => ModelInfo {
                provider: Provider::Openai,
                name: "text-embedding-3-large".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.13f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenaiTextEmbedding3Small => ModelInfo {
                provider: Provider::Openai,
                name: "text-embedding-3-small".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.02f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GeminiGemini25Flash => ModelInfo {
                provider: Provider::Gemini,
                name: "gemini-2.5-flash".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(65536u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GeminiGemini25Pro => ModelInfo {
                provider: Provider::Gemini,
                name: "gemini-2.5-pro".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(65536u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GeminiGemini25FlashLitePreview0617 => ModelInfo {
                provider: Provider::Gemini,
                name: "gemini-2.5-flash-lite-preview-06-17".to_string(),
                max_input_tokens: Some(1000000u64),
                max_output_tokens: Some(64000u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GeminiGemini20Flash => ModelInfo {
                provider: Provider::Gemini,
                name: "gemini-2.0-flash".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GeminiGemini20FlashLite => ModelInfo {
                provider: Provider::Gemini,
                name: "gemini-2.0-flash-lite".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GeminiGemma327bIt => ModelInfo {
                provider: Provider::Gemini,
                name: "gemma-3-27b-it".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GeminiTextEmbedding004 => ModelInfo {
                provider: Provider::Gemini,
                name: "text-embedding-004".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ClaudeClaudeOpus420250514 => ModelInfo {
                provider: Provider::Claude,
                name: "claude-opus-4-20250514".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(15f64),
                output_price: Some(75f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::ClaudeClaudeOpus420250514Thinking => ModelInfo {
                provider: Provider::Claude,
                name: "claude-opus-4-20250514:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(15f64),
                output_price: Some(75f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::ClaudeClaudeSonnet420250514 => ModelInfo {
                provider: Provider::Claude,
                name: "claude-sonnet-4-20250514".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::ClaudeClaudeSonnet420250514Thinking => ModelInfo {
                provider: Provider::Claude,
                name: "claude-sonnet-4-20250514:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::ClaudeClaude37Sonnet20250219 => ModelInfo {
                provider: Provider::Claude,
                name: "claude-3-7-sonnet-20250219".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::ClaudeClaude37Sonnet20250219Thinking => ModelInfo {
                provider: Provider::Claude,
                name: "claude-3-7-sonnet-20250219:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::ClaudeClaude35Sonnet20241022 => ModelInfo {
                provider: Provider::Claude,
                name: "claude-3-5-sonnet-20241022".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::ClaudeClaude35Haiku20241022 => ModelInfo {
                provider: Provider::Claude,
                name: "claude-3-5-haiku-20241022".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.8f64),
                output_price: Some(4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::MistralMistralMediumLatest => ModelInfo {
                provider: Provider::Mistral,
                name: "mistral-medium-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.4f64),
                output_price: Some(2f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::MistralMistralSmallLatest => ModelInfo {
                provider: Provider::Mistral,
                name: "mistral-small-latest".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::MistralMagistralMediumLatest => ModelInfo {
                provider: Provider::Mistral,
                name: "magistral-medium-latest".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::MistralMagistralSmallLatest => ModelInfo {
                provider: Provider::Mistral,
                name: "magistral-small-latest".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.5f64),
                output_price: Some(1.5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::MistralDevstralSmallLatest => ModelInfo {
                provider: Provider::Mistral,
                name: "devstral-small-latest".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::MistralCodestralLatest => ModelInfo {
                provider: Provider::Mistral,
                name: "codestral-latest".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(0.3f64),
                output_price: Some(0.9f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::MistralMistralEmbed => ModelInfo {
                provider: Provider::Mistral,
                name: "mistral-embed".to_string(),
                max_input_tokens: Some(8092u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::Ai21JambaLarge => ModelInfo {
                provider: Provider::Ai21,
                name: "jamba-large".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::Ai21JambaMini => ModelInfo {
                provider: Provider::Ai21,
                name: "jamba-mini".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(0.2f64),
                output_price: Some(0.4f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::CohereCommandA032025 => ModelInfo {
                provider: Provider::Cohere,
                name: "command-a-03-2025".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(2.5f64),
                output_price: Some(10f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::CohereCommandR7b122024 => ModelInfo {
                provider: Provider::Cohere,
                name: "command-r7b-12-2024".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(4096u64),
                input_price: Some(0.0375f64),
                output_price: Some(0.15f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::CohereEmbedV40 => ModelInfo {
                provider: Provider::Cohere,
                name: "embed-v4.0".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.12f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::CohereEmbedEnglishV30 => ModelInfo {
                provider: Provider::Cohere,
                name: "embed-english-v3.0".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::CohereEmbedMultilingualV30 => ModelInfo {
                provider: Provider::Cohere,
                name: "embed-multilingual-v3.0".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::CohereRerankV35 => ModelInfo {
                provider: Provider::Cohere,
                name: "rerank-v3.5".to_string(),
                max_input_tokens: Some(4096u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::CohereRerankEnglishV30 => ModelInfo {
                provider: Provider::Cohere,
                name: "rerank-english-v3.0".to_string(),
                max_input_tokens: Some(4096u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::CohereRerankMultilingualV30 => ModelInfo {
                provider: Provider::Cohere,
                name: "rerank-multilingual-v3.0".to_string(),
                max_input_tokens: Some(4096u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::XaiGrok3Latest => ModelInfo {
                provider: Provider::Xai,
                name: "grok-3-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::XaiGrok3FastLatest => ModelInfo {
                provider: Provider::Xai,
                name: "grok-3-fast-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(5f64),
                output_price: Some(25f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::XaiGrok3MiniLatest => ModelInfo {
                provider: Provider::Xai,
                name: "grok-3-mini-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.3f64),
                output_price: Some(0.5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::XaiGrok3MiniFastLatest => ModelInfo {
                provider: Provider::Xai,
                name: "grok-3-mini-fast-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.6f64),
                output_price: Some(4f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::PerplexitySonarPro => ModelInfo {
                provider: Provider::Perplexity,
                name: "sonar-pro".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::PerplexitySonar => ModelInfo {
                provider: Provider::Perplexity,
                name: "sonar".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(1f64),
                output_price: Some(1f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::PerplexitySonarReasoningPro => ModelInfo {
                provider: Provider::Perplexity,
                name: "sonar-reasoning-pro".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::PerplexitySonarReasoning => ModelInfo {
                provider: Provider::Perplexity,
                name: "sonar-reasoning".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(1f64),
                output_price: Some(5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::PerplexitySonarDeepResearch => ModelInfo {
                provider: Provider::Perplexity,
                name: "sonar-deep-research".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::PerplexityR11776 => ModelInfo {
                provider: Provider::Perplexity,
                name: "r1-1776".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GroqMetaLlamaLlama4Maverick17b128eInstruct => ModelInfo {
                provider: Provider::Groq,
                name: "meta-llama/llama-4-maverick-17b-128e-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GroqMetaLlamaLlama4Scout17b16eInstruct => ModelInfo {
                provider: Provider::Groq,
                name: "meta-llama/llama-4-scout-17b-16e-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GroqLlama3370bVersatile => ModelInfo {
                provider: Provider::Groq,
                name: "llama-3.3-70b-versatile".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GroqQwenQwq32b => ModelInfo {
                provider: Provider::Groq,
                name: "qwen-qwq-32b".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GroqQwenQwen332b => ModelInfo {
                provider: Provider::Groq,
                name: "qwen/qwen3-32b".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::VertexaiGemini25Flash => ModelInfo {
                provider: Provider::Vertexai,
                name: "gemini-2.5-flash".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(65536u64),
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::VertexaiGemini25Pro => ModelInfo {
                provider: Provider::Vertexai,
                name: "gemini-2.5-pro".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(65536u64),
                input_price: Some(1.25f64),
                output_price: Some(10f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::VertexaiGemini25FlashLitePreview0617 => ModelInfo {
                provider: Provider::Vertexai,
                name: "gemini-2.5-flash-lite-preview-06-17".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(65536u64),
                input_price: Some(0.1f64),
                output_price: Some(0.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::VertexaiGemini20Flash001 => ModelInfo {
                provider: Provider::Vertexai,
                name: "gemini-2.0-flash-001".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::VertexaiGemini20FlashLite001 => ModelInfo {
                provider: Provider::Vertexai,
                name: "gemini-2.0-flash-lite-001".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.075f64),
                output_price: Some(0.3f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::VertexaiClaudeOpus420250514 => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-opus-4@20250514".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(15f64),
                output_price: Some(75f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::VertexaiClaudeOpus420250514Thinking => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-opus-4@20250514:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(15f64),
                output_price: Some(75f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::VertexaiClaudeSonnet420250514 => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-sonnet-4@20250514".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::VertexaiClaudeSonnet420250514Thinking => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-sonnet-4@20250514:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::VertexaiClaude37Sonnet20250219 => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-3-7-sonnet@20250219".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::VertexaiClaude37Sonnet20250219Thinking => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-3-7-sonnet@20250219:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::VertexaiClaude35SonnetV220241022 => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-3-5-sonnet-v2@20241022".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::VertexaiClaude35Haiku20241022 => ModelInfo {
                provider: Provider::Vertexai,
                name: "claude-3-5-haiku@20241022".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.8f64),
                output_price: Some(4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::VertexaiMistralSmall2503 => ModelInfo {
                provider: Provider::Vertexai,
                name: "mistral-small-2503".to_string(),
                max_input_tokens: Some(32000u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::VertexaiCodestral2501 => ModelInfo {
                provider: Provider::Vertexai,
                name: "codestral-2501".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(0.3f64),
                output_price: Some(0.9f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::VertexaiTextEmbedding005 => ModelInfo {
                provider: Provider::Vertexai,
                name: "text-embedding-005".to_string(),
                max_input_tokens: Some(20000u64),
                max_output_tokens: None,
                input_price: Some(0.025f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::VertexaiTextMultilingualEmbedding002 => ModelInfo {
                provider: Provider::Vertexai,
                name: "text-multilingual-embedding-002".to_string(),
                max_input_tokens: Some(20000u64),
                max_output_tokens: None,
                input_price: Some(0.2f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::BedrockUsAnthropicClaudeOpus420250514V10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.anthropic.claude-opus-4-20250514-v1:0".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(15f64),
                output_price: Some(75f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockUsAnthropicClaudeOpus420250514V10Thinking => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.anthropic.claude-opus-4-20250514-v1:0:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(15f64),
                output_price: Some(75f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::BedrockUsAnthropicClaudeSonnet420250514V10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.anthropic.claude-sonnet-4-20250514-v1:0".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockUsAnthropicClaudeSonnet420250514V10Thinking => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.anthropic.claude-sonnet-4-20250514-v1:0:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::BedrockUsAnthropicClaude37Sonnet20250219V10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.anthropic.claude-3-7-sonnet-20250219-v1:0".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockUsAnthropicClaude37Sonnet20250219V10Thinking => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.anthropic.claude-3-7-sonnet-20250219-v1:0:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::BedrockAnthropicClaude35Sonnet20241022V20 => ModelInfo {
                provider: Provider::Bedrock,
                name: "anthropic.claude-3-5-sonnet-20241022-v2:0".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockAnthropicClaude35Haiku20241022V10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "anthropic.claude-3-5-haiku-20241022-v1:0".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.8f64),
                output_price: Some(4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockUsMetaLlama4Maverick17bInstructV10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.meta.llama4-maverick-17b-instruct-v1:0".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.24f64),
                output_price: Some(0.97f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockUsMetaLlama4Scout17bInstructV10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.meta.llama4-scout-17b-instruct-v1:0".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.17f64),
                output_price: Some(0.66f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockUsMetaLlama3370bInstructV10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.meta.llama3-3-70b-instruct-v1:0".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.72f64),
                output_price: Some(0.72f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::BedrockUsAmazonNovaPremierV10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.amazon.nova-premier-v1:0".to_string(),
                max_input_tokens: Some(300000u64),
                max_output_tokens: Some(5120u64),
                input_price: Some(2.5f64),
                output_price: Some(12.5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::BedrockUsAmazonNovaProV10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.amazon.nova-pro-v1:0".to_string(),
                max_input_tokens: Some(300000u64),
                max_output_tokens: Some(5120u64),
                input_price: Some(0.8f64),
                output_price: Some(3.2f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::BedrockUsAmazonNovaLiteV10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.amazon.nova-lite-v1:0".to_string(),
                max_input_tokens: Some(300000u64),
                max_output_tokens: Some(5120u64),
                input_price: Some(0.06f64),
                output_price: Some(0.24f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::BedrockUsAmazonNovaMicroV10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.amazon.nova-micro-v1:0".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(5120u64),
                input_price: Some(0.035f64),
                output_price: Some(0.14f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::BedrockCohereEmbedEnglishV3 => ModelInfo {
                provider: Provider::Bedrock,
                name: "cohere.embed-english-v3".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::BedrockCohereEmbedMultilingualV3 => ModelInfo {
                provider: Provider::Bedrock,
                name: "cohere.embed-multilingual-v3".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::BedrockUsDeepseekR1V10 => ModelInfo {
                provider: Provider::Bedrock,
                name: "us.deepseek.r1-v1:0".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(1.35f64),
                output_price: Some(5.4f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::CloudflareCfMetaLlama4Scout17b16eInstruct => ModelInfo {
                provider: Provider::Cloudflare,
                name: "@cf/meta/llama-4-scout-17b-16e-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::CloudflareCfMetaLlama3370bInstructFp8Fast => ModelInfo {
                provider: Provider::Cloudflare,
                name: "@cf/meta/llama-3.3-70b-instruct-fp8-fast".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::CloudflareCfQwenQwq32b => ModelInfo {
                provider: Provider::Cloudflare,
                name: "@cf/qwen/qwq-32b".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::CloudflareCfQwenQwen25Coder32bInstruct => ModelInfo {
                provider: Provider::Cloudflare,
                name: "@cf/qwen/qwen2.5-coder-32b-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::CloudflareCfGoogleGemma312bIt => ModelInfo {
                provider: Provider::Cloudflare,
                name: "@cf/google/gemma-3-12b-it".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::CloudflareCfMistralaiMistralSmall3124bInstruct => ModelInfo {
                provider: Provider::Cloudflare,
                name: "@cf/mistralai/mistral-small-3.1-24b-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::CloudflareCfBaaiBgeLargeEnV15 => ModelInfo {
                provider: Provider::Cloudflare,
                name: "@cf/baai/bge-large-en-v1.5".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ErnieErnie45Turbo128k => ModelInfo {
                provider: Provider::Ernie,
                name: "ernie-4.5-turbo-128k".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.112f64),
                output_price: Some(0.448f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ErnieErnie45TurboVl32k => ModelInfo {
                provider: Provider::Ernie,
                name: "ernie-4.5-turbo-vl-32k".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.42f64),
                output_price: Some(1.26f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ErnieErnieX1Turbo32k => ModelInfo {
                provider: Provider::Ernie,
                name: "ernie-x1-turbo-32k".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.14f64),
                output_price: Some(0.56f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ErnieBgeLargeZh => ModelInfo {
                provider: Provider::Ernie,
                name: "bge-large-zh".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ErnieBgeLargeEn => ModelInfo {
                provider: Provider::Ernie,
                name: "bge-large-en".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ErnieBceRerankerBase => ModelInfo {
                provider: Provider::Ernie,
                name: "bce-reranker-base".to_string(),
                max_input_tokens: Some(1024u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwenMaxLatest => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen-max-latest".to_string(),
                max_input_tokens: Some(32678u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(1.6f64),
                output_price: Some(6.4f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::QianwenQwenPlusLatest => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen-plus-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.112f64),
                output_price: Some(0.28f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::QianwenQwenTurboLatest => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen-turbo-latest".to_string(),
                max_input_tokens: Some(1000000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.042f64),
                output_price: Some(0.084f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::QianwenQwenLong => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen-long".to_string(),
                max_input_tokens: Some(1000000u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: Some(0.28f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwenOmniTurboLatest => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen-omni-turbo-latest".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: Some(2048u64),
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwqPlusLatest => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwq-plus-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.224f64),
                output_price: Some(0.56f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwenVlMaxLatest => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen-vl-max-latest".to_string(),
                max_input_tokens: Some(30720u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0.42f64),
                output_price: Some(1.26f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwenVlPlusLatest => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen-vl-plus-latest".to_string(),
                max_input_tokens: Some(30000u64),
                max_output_tokens: Some(2048u64),
                input_price: Some(0.21f64),
                output_price: Some(0.63f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwen3235bA22b => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen3-235b-a22b".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.56f64),
                output_price: Some(1.68f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwen330bA3b => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen3-30b-a3b".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.21f64),
                output_price: Some(0.84f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwen332b => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen3-32b".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.28f64),
                output_price: Some(1.12f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwq32b => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwq-32b".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.28f64),
                output_price: Some(0.84f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwen2572bInstruct => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen2.5-72b-instruct".to_string(),
                max_input_tokens: Some(129024u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.56f64),
                output_price: Some(1.68f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::QianwenQwen25Vl72bInstruct => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen2.5-vl-72b-instruct".to_string(),
                max_input_tokens: Some(129024u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(2.24f64),
                output_price: Some(6.72f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenQwen25Coder32bInstruct => ModelInfo {
                provider: Provider::Qianwen,
                name: "qwen2.5-coder-32b-instruct".to_string(),
                max_input_tokens: Some(129024u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.49f64),
                output_price: Some(0.98f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::QianwenDeepseekV3 => ModelInfo {
                provider: Provider::Qianwen,
                name: "deepseek-v3".to_string(),
                max_input_tokens: Some(65536u64),
                max_output_tokens: None,
                input_price: Some(0.14f64),
                output_price: Some(0.56f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenDeepseekR10528 => ModelInfo {
                provider: Provider::Qianwen,
                name: "deepseek-r1-0528".to_string(),
                max_input_tokens: Some(65536u64),
                max_output_tokens: None,
                input_price: Some(0.28f64),
                output_price: Some(1.12f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenTextEmbeddingV4 => ModelInfo {
                provider: Provider::Qianwen,
                name: "text-embedding-v4".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::QianwenTextEmbeddingV3 => ModelInfo {
                provider: Provider::Qianwen,
                name: "text-embedding-v3".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::HunyuanHunyuanTurbosLatest => ModelInfo {
                provider: Provider::Hunyuan,
                name: "hunyuan-turbos-latest".to_string(),
                max_input_tokens: Some(28000u64),
                max_output_tokens: None,
                input_price: Some(0.112f64),
                output_price: Some(0.28f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::HunyuanHunyuanT1Latest => ModelInfo {
                provider: Provider::Hunyuan,
                name: "hunyuan-t1-latest".to_string(),
                max_input_tokens: Some(28000u64),
                max_output_tokens: None,
                input_price: Some(0.14f64),
                output_price: Some(0.56f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::HunyuanHunyuanLite => ModelInfo {
                provider: Provider::Hunyuan,
                name: "hunyuan-lite".to_string(),
                max_input_tokens: Some(250000u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::HunyuanHunyuanTurbosVision => ModelInfo {
                provider: Provider::Hunyuan,
                name: "hunyuan-turbos-vision".to_string(),
                max_input_tokens: Some(6144u64),
                max_output_tokens: None,
                input_price: Some(0.42f64),
                output_price: Some(0.84f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::HunyuanHunyuanT1Vision => ModelInfo {
                provider: Provider::Hunyuan,
                name: "hunyuan-t1-vision".to_string(),
                max_input_tokens: Some(24000u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::HunyuanHunyuanEmbedding => ModelInfo {
                provider: Provider::Hunyuan,
                name: "hunyuan-embedding".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.01f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::MoonshotKimiLatest => ModelInfo {
                provider: Provider::Moonshot,
                name: "kimi-latest".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(1.4f64),
                output_price: Some(4.2f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::MoonshotKimiThinkingPreview => ModelInfo {
                provider: Provider::Moonshot,
                name: "kimi-thinking-preview".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(28f64),
                output_price: Some(28f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepseekDeepseekChat => ModelInfo {
                provider: Provider::Deepseek,
                name: "deepseek-chat".to_string(),
                max_input_tokens: Some(64000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.27f64),
                output_price: Some(1.1f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::DeepseekDeepseekReasoner => ModelInfo {
                provider: Provider::Deepseek,
                name: "deepseek-reasoner".to_string(),
                max_input_tokens: Some(64000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.55f64),
                output_price: Some(2.19f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ZhipuaiGlm4Plus => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-4-plus".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.7f64),
                output_price: Some(0.7f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::ZhipuaiGlm4Air => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-4-air".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: Some(0.07f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::ZhipuaiGlm4Long => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-4-long".to_string(),
                max_input_tokens: Some(1000000u64),
                max_output_tokens: Some(4096u64),
                input_price: Some(0.14f64),
                output_price: Some(0.14f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::ZhipuaiGlm4Flash250414 => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-4-flash-250414".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::ZhipuaiGlm4vPlus0111 => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-4v-plus-0111".to_string(),
                max_input_tokens: Some(8192u64),
                max_output_tokens: None,
                input_price: Some(0.56f64),
                output_price: Some(0.56f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ZhipuaiGlm4vFlash => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-4v-flash".to_string(),
                max_input_tokens: Some(8192u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ZhipuaiGlmZ1Air => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-z1-air".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.7f64),
                output_price: Some(0.7f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ZhipuaiGlmZ1Flash => ModelInfo {
                provider: Provider::Zhipuai,
                name: "glm-z1-flash".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: Some(0f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ZhipuaiEmbedding3 => ModelInfo {
                provider: Provider::Zhipuai,
                name: "embedding-3".to_string(),
                max_input_tokens: Some(8192u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::ZhipuaiRerank => ModelInfo {
                provider: Provider::Zhipuai,
                name: "rerank".to_string(),
                max_input_tokens: Some(4096u64),
                max_output_tokens: None,
                input_price: Some(0.112f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::MinimaxMinimaxText01 => ModelInfo {
                provider: Provider::Minimax,
                name: "minimax-text-01".to_string(),
                max_input_tokens: Some(1000192u64),
                max_output_tokens: None,
                input_price: Some(0.14f64),
                output_price: Some(1.12f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::MinimaxMinimaxM1 => ModelInfo {
                provider: Provider::Minimax,
                name: "minimax-m1".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.112f64),
                output_price: Some(1.12f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiGpt41 => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/gpt-4.1".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiGpt41Mini => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/gpt-4.1-mini".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: Some(0.4f64),
                output_price: Some(1.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiGpt41Nano => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/gpt-4.1-nano".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: Some(0.1f64),
                output_price: Some(0.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiGpt4o => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/gpt-4o".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(2.5f64),
                output_price: Some(10f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiGpt4oSearchPreview => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/gpt-4o-search-preview".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: Some(2.5f64),
                output_price: Some(10f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiGpt4oMini => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/gpt-4o-mini".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiGpt4oMiniSearchPreview => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/gpt-4o-mini-search-preview".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiChatgpt4oLatest => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/chatgpt-4o-latest".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(5f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiO4Mini => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/o4-mini".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiO4MiniHigh => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/o4-mini-high".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiO3Pro => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/o3-pro".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(20f64),
                output_price: Some(80f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiO3 => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/o3".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(10f64),
                output_price: Some(40f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiO3Mini => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/o3-mini".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterOpenaiO3MiniHigh => ModelInfo {
                provider: Provider::Openrouter,
                name: "openai/o3-mini-high".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(1.1f64),
                output_price: Some(4.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterGoogleGemini25Flash => ModelInfo {
                provider: Provider::Openrouter,
                name: "google/gemini-2.5-flash".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: None,
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterGoogleGemini25Pro => ModelInfo {
                provider: Provider::Openrouter,
                name: "google/gemini-2.5-pro".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: None,
                input_price: Some(1.25f64),
                output_price: Some(10f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterGoogleGemini25FlashLitePreview0617 => ModelInfo {
                provider: Provider::Openrouter,
                name: "google/gemini-2.5-flash-lite-preview-06-17".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.4f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterGoogleGemini20Flash001 => ModelInfo {
                provider: Provider::Openrouter,
                name: "google/gemini-2.0-flash-001".to_string(),
                max_input_tokens: Some(1000000u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterGoogleGemini20FlashLite001 => ModelInfo {
                provider: Provider::Openrouter,
                name: "google/gemini-2.0-flash-lite-001".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: None,
                input_price: Some(0.075f64),
                output_price: Some(0.3f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterGoogleGemma327bIt => ModelInfo {
                provider: Provider::Openrouter,
                name: "google/gemma-3-27b-it".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.2f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterAnthropicClaudeOpus4 => ModelInfo {
                provider: Provider::Openrouter,
                name: "anthropic/claude-opus-4".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(15f64),
                output_price: Some(75f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::OpenrouterAnthropicClaudeSonnet4 => ModelInfo {
                provider: Provider::Openrouter,
                name: "anthropic/claude-sonnet-4".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::OpenrouterAnthropicClaude37Sonnet => ModelInfo {
                provider: Provider::Openrouter,
                name: "anthropic/claude-3.7-sonnet".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::OpenrouterAnthropicClaude37SonnetThinking => ModelInfo {
                provider: Provider::Openrouter,
                name: "anthropic/claude-3.7-sonnet:thinking".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(24000u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: Some(true),
            },
            Model::OpenrouterAnthropicClaude35Sonnet => ModelInfo {
                provider: Provider::Openrouter,
                name: "anthropic/claude-3.5-sonnet".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::OpenrouterAnthropicClaude35Haiku => ModelInfo {
                provider: Provider::Openrouter,
                name: "anthropic/claude-3-5-haiku".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.8f64),
                output_price: Some(4f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: Some(true),
            },
            Model::OpenrouterMetaLlamaLlama4Maverick => ModelInfo {
                provider: Provider::Openrouter,
                name: "meta-llama/llama-4-maverick".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: None,
                input_price: Some(0.18f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterMetaLlamaLlama4Scout => ModelInfo {
                provider: Provider::Openrouter,
                name: "meta-llama/llama-4-scout".to_string(),
                max_input_tokens: Some(327680u64),
                max_output_tokens: None,
                input_price: Some(0.08f64),
                output_price: Some(0.3f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterMetaLlamaLlama3370bInstruct => ModelInfo {
                provider: Provider::Openrouter,
                name: "meta-llama/llama-3.3-70b-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.12f64),
                output_price: Some(0.3f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterMistralaiMistralMedium3 => ModelInfo {
                provider: Provider::Openrouter,
                name: "mistralai/mistral-medium-3".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.4f64),
                output_price: Some(2f64),
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterMistralaiMistralSmall3224bInstruct => ModelInfo {
                provider: Provider::Openrouter,
                name: "mistralai/mistral-small-3.2-24b-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterMistralaiMagistralMedium2506 => ModelInfo {
                provider: Provider::Openrouter,
                name: "mistralai/magistral-medium-2506".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterMistralaiMagistralMedium2506Thinking => ModelInfo {
                provider: Provider::Openrouter,
                name: "mistralai/magistral-medium-2506:thinking".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterMistralaiMagistralSmall2506 => ModelInfo {
                provider: Provider::Openrouter,
                name: "mistralai/magistral-small-2506".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.5f64),
                output_price: Some(1.5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterMistralaiDevstralSmall => ModelInfo {
                provider: Provider::Openrouter,
                name: "mistralai/devstral-small".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: Some(0.1f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterMistralaiCodestral2501 => ModelInfo {
                provider: Provider::Openrouter,
                name: "mistralai/codestral-2501".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(0.3f64),
                output_price: Some(0.9f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterAi21Jamba16Large => ModelInfo {
                provider: Provider::Openrouter,
                name: "ai21/jamba-1.6-large".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterAi21Jamba16Mini => ModelInfo {
                provider: Provider::Openrouter,
                name: "ai21/jamba-1.6-mini".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(0.2f64),
                output_price: Some(0.4f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterCohereCommandA => ModelInfo {
                provider: Provider::Openrouter,
                name: "cohere/command-a".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: Some(2.5f64),
                output_price: Some(10f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterCohereCommandR7b122024 => ModelInfo {
                provider: Provider::Openrouter,
                name: "cohere/command-r7b-12-2024".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(4096u64),
                input_price: Some(0.0375f64),
                output_price: Some(0.15f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterDeepseekDeepseekChatV30324 => ModelInfo {
                provider: Provider::Openrouter,
                name: "deepseek/deepseek-chat-v3-0324".to_string(),
                max_input_tokens: Some(64000u64),
                max_output_tokens: None,
                input_price: Some(0.27f64),
                output_price: Some(1.1f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterDeepseekDeepseekR10528 => ModelInfo {
                provider: Provider::Openrouter,
                name: "deepseek/deepseek-r1-0528".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(0.5f64),
                output_price: Some(2.15f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwenMax => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen-max".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(1.6f64),
                output_price: Some(6.4f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwenPlus => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen-plus".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.4f64),
                output_price: Some(1.2f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwenTurbo => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen-turbo".to_string(),
                max_input_tokens: Some(1000000u64),
                max_output_tokens: Some(8192u64),
                input_price: Some(0.05f64),
                output_price: Some(0.2f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwenVlPlus => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen-vl-plus".to_string(),
                max_input_tokens: Some(7500u64),
                max_output_tokens: None,
                input_price: Some(0.21f64),
                output_price: Some(0.63f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwen3235bA22b => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen3-235b-a22b".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwen330bA3b => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen3-30b-a3b".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwen332b => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen3-32b".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwq32b => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwq-32b".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(0.29f64),
                output_price: Some(0.39f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwen2572bInstruct => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen-2.5-72b-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.35f64),
                output_price: Some(0.4f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwen25Vl72bInstruct => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen2.5-vl-72b-instruct".to_string(),
                max_input_tokens: Some(32000u64),
                max_output_tokens: None,
                input_price: Some(0.7f64),
                output_price: Some(0.7f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterQwenQwen25Coder32bInstruct => ModelInfo {
                provider: Provider::Openrouter,
                name: "qwen/qwen-2.5-coder-32b-instruct".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.18f64),
                output_price: Some(0.18f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterXAiGrok3 => ModelInfo {
                provider: Provider::Openrouter,
                name: "x-ai/grok-3".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::OpenrouterXAiGrok3Mini => ModelInfo {
                provider: Provider::Openrouter,
                name: "x-ai/grok-3-mini".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.3f64),
                output_price: Some(0.5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterAmazonNovaProV1 => ModelInfo {
                provider: Provider::Openrouter,
                name: "amazon/nova-pro-v1".to_string(),
                max_input_tokens: Some(300000u64),
                max_output_tokens: Some(5120u64),
                input_price: Some(0.8f64),
                output_price: Some(3.2f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterAmazonNovaLiteV1 => ModelInfo {
                provider: Provider::Openrouter,
                name: "amazon/nova-lite-v1".to_string(),
                max_input_tokens: Some(300000u64),
                max_output_tokens: Some(5120u64),
                input_price: Some(0.06f64),
                output_price: Some(0.24f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterAmazonNovaMicroV1 => ModelInfo {
                provider: Provider::Openrouter,
                name: "amazon/nova-micro-v1".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(5120u64),
                input_price: Some(0.035f64),
                output_price: Some(0.14f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterPerplexitySonarPro => ModelInfo {
                provider: Provider::Openrouter,
                name: "perplexity/sonar-pro".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(3f64),
                output_price: Some(15f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterPerplexitySonar => ModelInfo {
                provider: Provider::Openrouter,
                name: "perplexity/sonar".to_string(),
                max_input_tokens: Some(127072u64),
                max_output_tokens: None,
                input_price: Some(1f64),
                output_price: Some(1f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterPerplexitySonarReasoningPro => ModelInfo {
                provider: Provider::Openrouter,
                name: "perplexity/sonar-reasoning-pro".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterPerplexitySonarReasoning => ModelInfo {
                provider: Provider::Openrouter,
                name: "perplexity/sonar-reasoning".to_string(),
                max_input_tokens: Some(127000u64),
                max_output_tokens: None,
                input_price: Some(1f64),
                output_price: Some(5f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterPerplexitySonarDeepResearch => ModelInfo {
                provider: Provider::Openrouter,
                name: "perplexity/sonar-deep-research".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterPerplexityR11776 => ModelInfo {
                provider: Provider::Openrouter,
                name: "perplexity/r1-1776".to_string(),
                max_input_tokens: Some(127000u64),
                max_output_tokens: None,
                input_price: Some(2f64),
                output_price: Some(8f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterMinimaxMinimax01 => ModelInfo {
                provider: Provider::Openrouter,
                name: "minimax/minimax-01".to_string(),
                max_input_tokens: Some(1000192u64),
                max_output_tokens: None,
                input_price: Some(0.2f64),
                output_price: Some(1.1f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterThudmGlm432b => ModelInfo {
                provider: Provider::Openrouter,
                name: "thudm/glm-4-32b".to_string(),
                max_input_tokens: Some(32000u64),
                max_output_tokens: None,
                input_price: Some(0.24f64),
                output_price: Some(0.24f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterThudmGlmZ132b => ModelInfo {
                provider: Provider::Openrouter,
                name: "thudm/glm-z1-32b".to_string(),
                max_input_tokens: Some(32000u64),
                max_output_tokens: None,
                input_price: Some(0.24f64),
                output_price: Some(0.24f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::OpenrouterMicrosoftPhi4ReasoningPlus => ModelInfo {
                provider: Provider::Openrouter,
                name: "microsoft/phi-4-reasoning-plus".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: Some(0.35f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubGpt41 => ModelInfo {
                provider: Provider::Github,
                name: "gpt-4.1".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubGpt41Mini => ModelInfo {
                provider: Provider::Github,
                name: "gpt-4.1-mini".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubGpt41Nano => ModelInfo {
                provider: Provider::Github,
                name: "gpt-4.1-nano".to_string(),
                max_input_tokens: Some(1047576u64),
                max_output_tokens: Some(32768u64),
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubGpt4o => ModelInfo {
                provider: Provider::Github,
                name: "gpt-4o".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubGpt4oMini => ModelInfo {
                provider: Provider::Github,
                name: "gpt-4o-mini".to_string(),
                max_input_tokens: Some(128000u64),
                max_output_tokens: Some(16384u64),
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubO4Mini => ModelInfo {
                provider: Provider::Github,
                name: "o4-mini".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubO4MiniHigh => ModelInfo {
                provider: Provider::Github,
                name: "o4-mini-high".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubO3 => ModelInfo {
                provider: Provider::Github,
                name: "o3".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubO3Mini => ModelInfo {
                provider: Provider::Github,
                name: "o3-mini".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubO3MiniHigh => ModelInfo {
                provider: Provider::Github,
                name: "o3-mini-high".to_string(),
                max_input_tokens: Some(200000u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubTextEmbedding3Large => ModelInfo {
                provider: Provider::Github,
                name: "text-embedding-3-large".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubTextEmbedding3Small => ModelInfo {
                provider: Provider::Github,
                name: "text-embedding-3-small".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubLlama4Maverick17b128eInstructFp8 => ModelInfo {
                provider: Provider::Github,
                name: "llama-4-maverick-17b-128e-instruct-fp8".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubLlama4Scout17b16eInstruct => ModelInfo {
                provider: Provider::Github,
                name: "llama-4-scout-17b-16e-instruct".to_string(),
                max_input_tokens: Some(327680u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubLlama3370bInstruct => ModelInfo {
                provider: Provider::Github,
                name: "llama-3.3-70b-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubMistralMedium2505 => ModelInfo {
                provider: Provider::Github,
                name: "mistral-medium-2505".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubMistralSmall2503 => ModelInfo {
                provider: Provider::Github,
                name: "mistral-small-2503".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubCodestral2501 => ModelInfo {
                provider: Provider::Github,
                name: "codestral-2501".to_string(),
                max_input_tokens: Some(256000u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::GithubCohereEmbedV3English => ModelInfo {
                provider: Provider::Github,
                name: "cohere-embed-v3-english".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubCohereEmbedV3Multilingual => ModelInfo {
                provider: Provider::Github,
                name: "cohere-embed-v3-multilingual".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubDeepseekR10528 => ModelInfo {
                provider: Provider::Github,
                name: "deepseek-r1-0528".to_string(),
                max_input_tokens: Some(163840u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubDeepseekV30324 => ModelInfo {
                provider: Provider::Github,
                name: "deepseek-v3-0324".to_string(),
                max_input_tokens: Some(163840u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubMaiDsR1 => ModelInfo {
                provider: Provider::Github,
                name: "mai-ds-r1".to_string(),
                max_input_tokens: Some(163840u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubPhi4 => ModelInfo {
                provider: Provider::Github,
                name: "phi-4".to_string(),
                max_input_tokens: Some(16384u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubPhi4MiniInstruct => ModelInfo {
                provider: Provider::Github,
                name: "phi-4-mini-instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubPhi4Reasoning => ModelInfo {
                provider: Provider::Github,
                name: "phi-4-reasoning".to_string(),
                max_input_tokens: Some(33792u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubPhi4MiniReasoning => ModelInfo {
                provider: Provider::Github,
                name: "phi-4-mini-reasoning".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubGrok3 => ModelInfo {
                provider: Provider::Github,
                name: "grok-3".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::GithubGrok3Mini => ModelInfo {
                provider: Provider::Github,
                name: "grok-3-mini".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: None,
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraMetaLlamaLlama4Maverick17b128eInstructFp8 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8".to_string(),
                max_input_tokens: Some(1048576u64),
                max_output_tokens: None,
                input_price: Some(0.18f64),
                output_price: Some(0.6f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraMetaLlamaLlama4Scout17b16eInstruct => ModelInfo {
                provider: Provider::Deepinfra,
                name: "meta-llama/Llama-4-Scout-17B-16E-Instruct".to_string(),
                max_input_tokens: Some(327680u64),
                max_output_tokens: None,
                input_price: Some(0.08f64),
                output_price: Some(0.3f64),
                supports_vision: Some(true),
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraMetaLlamaLlama3370bInstruct => ModelInfo {
                provider: Provider::Deepinfra,
                name: "meta-llama/Llama-3.3-70B-Instruct".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.23f64),
                output_price: Some(0.4f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraQwenQwen3235bA22b => ModelInfo {
                provider: Provider::Deepinfra,
                name: "Qwen/Qwen3-235B-A22B".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.15f64),
                output_price: Some(0.6f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraQwenQwen330bA3b => ModelInfo {
                provider: Provider::Deepinfra,
                name: "Qwen/Qwen3-30B-A3B".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraQwenQwen332b => ModelInfo {
                provider: Provider::Deepinfra,
                name: "Qwen/Qwen3-32B".to_string(),
                max_input_tokens: Some(40960u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.3f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraQwenQwq32b => ModelInfo {
                provider: Provider::Deepinfra,
                name: "Qwen/QwQ-32B".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.12f64),
                output_price: Some(0.18f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraQwenQwen2572bInstruct => ModelInfo {
                provider: Provider::Deepinfra,
                name: "Qwen/Qwen2.5-72B-Instruct".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.23f64),
                output_price: Some(0.4f64),
                supports_vision: None,
                supports_function_calling: Some(true),
                require_max_tokens: None,
            },
            Model::DeepinfraQwenQwen25Coder32bInstruct => ModelInfo {
                provider: Provider::Deepinfra,
                name: "Qwen/Qwen2.5-Coder-32B-Instruct".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: Some(0.16f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraDeepseekAiDeepseekV30324 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "deepseek-ai/DeepSeek-V3-0324".to_string(),
                max_input_tokens: Some(163840u64),
                max_output_tokens: None,
                input_price: Some(0.4f64),
                output_price: Some(0.89f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraDeepseekAiDeepseekR10528 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "deepseek-ai/DeepSeek-R1-0528".to_string(),
                max_input_tokens: Some(163840u64),
                max_output_tokens: None,
                input_price: Some(0.5f64),
                output_price: Some(2.15f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraGoogleGemma327bIt => ModelInfo {
                provider: Provider::Deepinfra,
                name: "google/gemma-3-27b-it".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.1f64),
                output_price: Some(0.2f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraMistralaiMistralSmall3224bInstruct2506 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "mistralai/Mistral-Small-3.2-24B-Instruct-2506".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.06f64),
                output_price: Some(0.12f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraMistralaiDevstralSmall2505 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "mistralai/Devstral-Small-2505".to_string(),
                max_input_tokens: Some(131072u64),
                max_output_tokens: None,
                input_price: Some(0.06f64),
                output_price: Some(0.12f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraMicrosoftPhi4ReasoningPlus => ModelInfo {
                provider: Provider::Deepinfra,
                name: "microsoft/phi-4-reasoning-plus".to_string(),
                max_input_tokens: Some(32768u64),
                max_output_tokens: None,
                input_price: Some(0.07f64),
                output_price: Some(0.35f64),
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraBaaiBgeLargeEnV15 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "BAAI/bge-large-en-v1.5".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.01f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraBaaiBgeM3 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "BAAI/bge-m3".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.01f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraIntfloatE5LargeV2 => ModelInfo {
                provider: Provider::Deepinfra,
                name: "intfloat/e5-large-v2".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.01f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraIntfloatMultilingualE5Large => ModelInfo {
                provider: Provider::Deepinfra,
                name: "intfloat/multilingual-e5-large".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.01f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::DeepinfraThenlperGteLarge => ModelInfo {
                provider: Provider::Deepinfra,
                name: "thenlper/gte-large".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0.01f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::JinaJinaEmbeddingsV3 => ModelInfo {
                provider: Provider::Jina,
                name: "jina-embeddings-v3".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::JinaJinaClipV2 => ModelInfo {
                provider: Provider::Jina,
                name: "jina-clip-v2".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::JinaJinaColbertV2 => ModelInfo {
                provider: Provider::Jina,
                name: "jina-colbert-v2".to_string(),
                max_input_tokens: None,
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::JinaJinaRerankerV2BaseMultilingual => ModelInfo {
                provider: Provider::Jina,
                name: "jina-reranker-v2-base-multilingual".to_string(),
                max_input_tokens: Some(8192u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::JinaJinaColbertV2 => ModelInfo {
                provider: Provider::Jina,
                name: "jina-colbert-v2".to_string(),
                max_input_tokens: Some(8192u64),
                max_output_tokens: None,
                input_price: Some(0f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::VoyageaiVoyage3Large => ModelInfo {
                provider: Provider::Voyageai,
                name: "voyage-3-large".to_string(),
                max_input_tokens: Some(120000u64),
                max_output_tokens: None,
                input_price: Some(0.18f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::VoyageaiVoyage3 => ModelInfo {
                provider: Provider::Voyageai,
                name: "voyage-3".to_string(),
                max_input_tokens: Some(320000u64),
                max_output_tokens: None,
                input_price: Some(0.06f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::VoyageaiVoyage3Lite => ModelInfo {
                provider: Provider::Voyageai,
                name: "voyage-3-lite".to_string(),
                max_input_tokens: Some(1000000u64),
                max_output_tokens: None,
                input_price: Some(0.02f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::VoyageaiRerank2 => ModelInfo {
                provider: Provider::Voyageai,
                name: "rerank-2".to_string(),
                max_input_tokens: Some(16000u64),
                max_output_tokens: None,
                input_price: Some(0.05f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
            Model::VoyageaiRerank2Lite => ModelInfo {
                provider: Provider::Voyageai,
                name: "rerank-2-lite".to_string(),
                max_input_tokens: Some(8000u64),
                max_output_tokens: None,
                input_price: Some(0.02f64),
                output_price: None,
                supports_vision: None,
                supports_function_calling: None,
                require_max_tokens: None,
            },
        }
    }
    #[doc = r" Get the provider for this model"]
    pub fn provider(&self) -> Provider {
        self.info().provider
    }
    #[doc = r" Get the original model name"]
    pub fn name(&self) -> &str {
        match self {
            Model::OpenaiGpt41 => "gpt-4.1",
            Model::OpenaiGpt41Mini => "gpt-4.1-mini",
            Model::OpenaiGpt41Nano => "gpt-4.1-nano",
            Model::OpenaiGpt4o => "gpt-4o",
            Model::OpenaiGpt4oSearchPreview => "gpt-4o-search-preview",
            Model::OpenaiGpt4oMini => "gpt-4o-mini",
            Model::OpenaiGpt4oMiniSearchPreview => "gpt-4o-mini-search-preview",
            Model::OpenaiChatgpt4oLatest => "chatgpt-4o-latest",
            Model::OpenaiO4Mini => "o4-mini",
            Model::OpenaiO4MiniHigh => "o4-mini-high",
            Model::OpenaiO3 => "o3",
            Model::OpenaiO3Mini => "o3-mini",
            Model::OpenaiO3MiniHigh => "o3-mini-high",
            Model::OpenaiGpt4Turbo => "gpt-4-turbo",
            Model::OpenaiGpt35Turbo => "gpt-3.5-turbo",
            Model::OpenaiTextEmbedding3Large => "text-embedding-3-large",
            Model::OpenaiTextEmbedding3Small => "text-embedding-3-small",
            Model::GeminiGemini25Flash => "gemini-2.5-flash",
            Model::GeminiGemini25Pro => "gemini-2.5-pro",
            Model::GeminiGemini25FlashLitePreview0617 => "gemini-2.5-flash-lite-preview-06-17",
            Model::GeminiGemini20Flash => "gemini-2.0-flash",
            Model::GeminiGemini20FlashLite => "gemini-2.0-flash-lite",
            Model::GeminiGemma327bIt => "gemma-3-27b-it",
            Model::GeminiTextEmbedding004 => "text-embedding-004",
            Model::ClaudeClaudeOpus420250514 => "claude-opus-4-20250514",
            Model::ClaudeClaudeOpus420250514Thinking => "claude-opus-4-20250514:thinking",
            Model::ClaudeClaudeSonnet420250514 => "claude-sonnet-4-20250514",
            Model::ClaudeClaudeSonnet420250514Thinking => "claude-sonnet-4-20250514:thinking",
            Model::ClaudeClaude37Sonnet20250219 => "claude-3-7-sonnet-20250219",
            Model::ClaudeClaude37Sonnet20250219Thinking => "claude-3-7-sonnet-20250219:thinking",
            Model::ClaudeClaude35Sonnet20241022 => "claude-3-5-sonnet-20241022",
            Model::ClaudeClaude35Haiku20241022 => "claude-3-5-haiku-20241022",
            Model::MistralMistralMediumLatest => "mistral-medium-latest",
            Model::MistralMistralSmallLatest => "mistral-small-latest",
            Model::MistralMagistralMediumLatest => "magistral-medium-latest",
            Model::MistralMagistralSmallLatest => "magistral-small-latest",
            Model::MistralDevstralSmallLatest => "devstral-small-latest",
            Model::MistralCodestralLatest => "codestral-latest",
            Model::MistralMistralEmbed => "mistral-embed",
            Model::Ai21JambaLarge => "jamba-large",
            Model::Ai21JambaMini => "jamba-mini",
            Model::CohereCommandA032025 => "command-a-03-2025",
            Model::CohereCommandR7b122024 => "command-r7b-12-2024",
            Model::CohereEmbedV40 => "embed-v4.0",
            Model::CohereEmbedEnglishV30 => "embed-english-v3.0",
            Model::CohereEmbedMultilingualV30 => "embed-multilingual-v3.0",
            Model::CohereRerankV35 => "rerank-v3.5",
            Model::CohereRerankEnglishV30 => "rerank-english-v3.0",
            Model::CohereRerankMultilingualV30 => "rerank-multilingual-v3.0",
            Model::XaiGrok3Latest => "grok-3-latest",
            Model::XaiGrok3FastLatest => "grok-3-fast-latest",
            Model::XaiGrok3MiniLatest => "grok-3-mini-latest",
            Model::XaiGrok3MiniFastLatest => "grok-3-mini-fast-latest",
            Model::PerplexitySonarPro => "sonar-pro",
            Model::PerplexitySonar => "sonar",
            Model::PerplexitySonarReasoningPro => "sonar-reasoning-pro",
            Model::PerplexitySonarReasoning => "sonar-reasoning",
            Model::PerplexitySonarDeepResearch => "sonar-deep-research",
            Model::PerplexityR11776 => "r1-1776",
            Model::GroqMetaLlamaLlama4Maverick17b128eInstruct => {
                "meta-llama/llama-4-maverick-17b-128e-instruct"
            }
            Model::GroqMetaLlamaLlama4Scout17b16eInstruct => {
                "meta-llama/llama-4-scout-17b-16e-instruct"
            }
            Model::GroqLlama3370bVersatile => "llama-3.3-70b-versatile",
            Model::GroqQwenQwq32b => "qwen-qwq-32b",
            Model::GroqQwenQwen332b => "qwen/qwen3-32b",
            Model::VertexaiGemini25Flash => "gemini-2.5-flash",
            Model::VertexaiGemini25Pro => "gemini-2.5-pro",
            Model::VertexaiGemini25FlashLitePreview0617 => "gemini-2.5-flash-lite-preview-06-17",
            Model::VertexaiGemini20Flash001 => "gemini-2.0-flash-001",
            Model::VertexaiGemini20FlashLite001 => "gemini-2.0-flash-lite-001",
            Model::VertexaiClaudeOpus420250514 => "claude-opus-4@20250514",
            Model::VertexaiClaudeOpus420250514Thinking => "claude-opus-4@20250514:thinking",
            Model::VertexaiClaudeSonnet420250514 => "claude-sonnet-4@20250514",
            Model::VertexaiClaudeSonnet420250514Thinking => "claude-sonnet-4@20250514:thinking",
            Model::VertexaiClaude37Sonnet20250219 => "claude-3-7-sonnet@20250219",
            Model::VertexaiClaude37Sonnet20250219Thinking => "claude-3-7-sonnet@20250219:thinking",
            Model::VertexaiClaude35SonnetV220241022 => "claude-3-5-sonnet-v2@20241022",
            Model::VertexaiClaude35Haiku20241022 => "claude-3-5-haiku@20241022",
            Model::VertexaiMistralSmall2503 => "mistral-small-2503",
            Model::VertexaiCodestral2501 => "codestral-2501",
            Model::VertexaiTextEmbedding005 => "text-embedding-005",
            Model::VertexaiTextMultilingualEmbedding002 => "text-multilingual-embedding-002",
            Model::BedrockUsAnthropicClaudeOpus420250514V10 => {
                "us.anthropic.claude-opus-4-20250514-v1:0"
            }
            Model::BedrockUsAnthropicClaudeOpus420250514V10Thinking => {
                "us.anthropic.claude-opus-4-20250514-v1:0:thinking"
            }
            Model::BedrockUsAnthropicClaudeSonnet420250514V10 => {
                "us.anthropic.claude-sonnet-4-20250514-v1:0"
            }
            Model::BedrockUsAnthropicClaudeSonnet420250514V10Thinking => {
                "us.anthropic.claude-sonnet-4-20250514-v1:0:thinking"
            }
            Model::BedrockUsAnthropicClaude37Sonnet20250219V10 => {
                "us.anthropic.claude-3-7-sonnet-20250219-v1:0"
            }
            Model::BedrockUsAnthropicClaude37Sonnet20250219V10Thinking => {
                "us.anthropic.claude-3-7-sonnet-20250219-v1:0:thinking"
            }
            Model::BedrockAnthropicClaude35Sonnet20241022V20 => {
                "anthropic.claude-3-5-sonnet-20241022-v2:0"
            }
            Model::BedrockAnthropicClaude35Haiku20241022V10 => {
                "anthropic.claude-3-5-haiku-20241022-v1:0"
            }
            Model::BedrockUsMetaLlama4Maverick17bInstructV10 => {
                "us.meta.llama4-maverick-17b-instruct-v1:0"
            }
            Model::BedrockUsMetaLlama4Scout17bInstructV10 => {
                "us.meta.llama4-scout-17b-instruct-v1:0"
            }
            Model::BedrockUsMetaLlama3370bInstructV10 => "us.meta.llama3-3-70b-instruct-v1:0",
            Model::BedrockUsAmazonNovaPremierV10 => "us.amazon.nova-premier-v1:0",
            Model::BedrockUsAmazonNovaProV10 => "us.amazon.nova-pro-v1:0",
            Model::BedrockUsAmazonNovaLiteV10 => "us.amazon.nova-lite-v1:0",
            Model::BedrockUsAmazonNovaMicroV10 => "us.amazon.nova-micro-v1:0",
            Model::BedrockCohereEmbedEnglishV3 => "cohere.embed-english-v3",
            Model::BedrockCohereEmbedMultilingualV3 => "cohere.embed-multilingual-v3",
            Model::BedrockUsDeepseekR1V10 => "us.deepseek.r1-v1:0",
            Model::CloudflareCfMetaLlama4Scout17b16eInstruct => {
                "@cf/meta/llama-4-scout-17b-16e-instruct"
            }
            Model::CloudflareCfMetaLlama3370bInstructFp8Fast => {
                "@cf/meta/llama-3.3-70b-instruct-fp8-fast"
            }
            Model::CloudflareCfQwenQwq32b => "@cf/qwen/qwq-32b",
            Model::CloudflareCfQwenQwen25Coder32bInstruct => "@cf/qwen/qwen2.5-coder-32b-instruct",
            Model::CloudflareCfGoogleGemma312bIt => "@cf/google/gemma-3-12b-it",
            Model::CloudflareCfMistralaiMistralSmall3124bInstruct => {
                "@cf/mistralai/mistral-small-3.1-24b-instruct"
            }
            Model::CloudflareCfBaaiBgeLargeEnV15 => "@cf/baai/bge-large-en-v1.5",
            Model::ErnieErnie45Turbo128k => "ernie-4.5-turbo-128k",
            Model::ErnieErnie45TurboVl32k => "ernie-4.5-turbo-vl-32k",
            Model::ErnieErnieX1Turbo32k => "ernie-x1-turbo-32k",
            Model::ErnieBgeLargeZh => "bge-large-zh",
            Model::ErnieBgeLargeEn => "bge-large-en",
            Model::ErnieBceRerankerBase => "bce-reranker-base",
            Model::QianwenQwenMaxLatest => "qwen-max-latest",
            Model::QianwenQwenPlusLatest => "qwen-plus-latest",
            Model::QianwenQwenTurboLatest => "qwen-turbo-latest",
            Model::QianwenQwenLong => "qwen-long",
            Model::QianwenQwenOmniTurboLatest => "qwen-omni-turbo-latest",
            Model::QianwenQwqPlusLatest => "qwq-plus-latest",
            Model::QianwenQwenVlMaxLatest => "qwen-vl-max-latest",
            Model::QianwenQwenVlPlusLatest => "qwen-vl-plus-latest",
            Model::QianwenQwen3235bA22b => "qwen3-235b-a22b",
            Model::QianwenQwen330bA3b => "qwen3-30b-a3b",
            Model::QianwenQwen332b => "qwen3-32b",
            Model::QianwenQwq32b => "qwq-32b",
            Model::QianwenQwen2572bInstruct => "qwen2.5-72b-instruct",
            Model::QianwenQwen25Vl72bInstruct => "qwen2.5-vl-72b-instruct",
            Model::QianwenQwen25Coder32bInstruct => "qwen2.5-coder-32b-instruct",
            Model::QianwenDeepseekV3 => "deepseek-v3",
            Model::QianwenDeepseekR10528 => "deepseek-r1-0528",
            Model::QianwenTextEmbeddingV4 => "text-embedding-v4",
            Model::QianwenTextEmbeddingV3 => "text-embedding-v3",
            Model::HunyuanHunyuanTurbosLatest => "hunyuan-turbos-latest",
            Model::HunyuanHunyuanT1Latest => "hunyuan-t1-latest",
            Model::HunyuanHunyuanLite => "hunyuan-lite",
            Model::HunyuanHunyuanTurbosVision => "hunyuan-turbos-vision",
            Model::HunyuanHunyuanT1Vision => "hunyuan-t1-vision",
            Model::HunyuanHunyuanEmbedding => "hunyuan-embedding",
            Model::MoonshotKimiLatest => "kimi-latest",
            Model::MoonshotKimiThinkingPreview => "kimi-thinking-preview",
            Model::DeepseekDeepseekChat => "deepseek-chat",
            Model::DeepseekDeepseekReasoner => "deepseek-reasoner",
            Model::ZhipuaiGlm4Plus => "glm-4-plus",
            Model::ZhipuaiGlm4Air => "glm-4-air",
            Model::ZhipuaiGlm4Long => "glm-4-long",
            Model::ZhipuaiGlm4Flash250414 => "glm-4-flash-250414",
            Model::ZhipuaiGlm4vPlus0111 => "glm-4v-plus-0111",
            Model::ZhipuaiGlm4vFlash => "glm-4v-flash",
            Model::ZhipuaiGlmZ1Air => "glm-z1-air",
            Model::ZhipuaiGlmZ1Flash => "glm-z1-flash",
            Model::ZhipuaiEmbedding3 => "embedding-3",
            Model::ZhipuaiRerank => "rerank",
            Model::MinimaxMinimaxText01 => "minimax-text-01",
            Model::MinimaxMinimaxM1 => "minimax-m1",
            Model::OpenrouterOpenaiGpt41 => "openai/gpt-4.1",
            Model::OpenrouterOpenaiGpt41Mini => "openai/gpt-4.1-mini",
            Model::OpenrouterOpenaiGpt41Nano => "openai/gpt-4.1-nano",
            Model::OpenrouterOpenaiGpt4o => "openai/gpt-4o",
            Model::OpenrouterOpenaiGpt4oSearchPreview => "openai/gpt-4o-search-preview",
            Model::OpenrouterOpenaiGpt4oMini => "openai/gpt-4o-mini",
            Model::OpenrouterOpenaiGpt4oMiniSearchPreview => "openai/gpt-4o-mini-search-preview",
            Model::OpenrouterOpenaiChatgpt4oLatest => "openai/chatgpt-4o-latest",
            Model::OpenrouterOpenaiO4Mini => "openai/o4-mini",
            Model::OpenrouterOpenaiO4MiniHigh => "openai/o4-mini-high",
            Model::OpenrouterOpenaiO3Pro => "openai/o3-pro",
            Model::OpenrouterOpenaiO3 => "openai/o3",
            Model::OpenrouterOpenaiO3Mini => "openai/o3-mini",
            Model::OpenrouterOpenaiO3MiniHigh => "openai/o3-mini-high",
            Model::OpenrouterGoogleGemini25Flash => "google/gemini-2.5-flash",
            Model::OpenrouterGoogleGemini25Pro => "google/gemini-2.5-pro",
            Model::OpenrouterGoogleGemini25FlashLitePreview0617 => {
                "google/gemini-2.5-flash-lite-preview-06-17"
            }
            Model::OpenrouterGoogleGemini20Flash001 => "google/gemini-2.0-flash-001",
            Model::OpenrouterGoogleGemini20FlashLite001 => "google/gemini-2.0-flash-lite-001",
            Model::OpenrouterGoogleGemma327bIt => "google/gemma-3-27b-it",
            Model::OpenrouterAnthropicClaudeOpus4 => "anthropic/claude-opus-4",
            Model::OpenrouterAnthropicClaudeSonnet4 => "anthropic/claude-sonnet-4",
            Model::OpenrouterAnthropicClaude37Sonnet => "anthropic/claude-3.7-sonnet",
            Model::OpenrouterAnthropicClaude37SonnetThinking => {
                "anthropic/claude-3.7-sonnet:thinking"
            }
            Model::OpenrouterAnthropicClaude35Sonnet => "anthropic/claude-3.5-sonnet",
            Model::OpenrouterAnthropicClaude35Haiku => "anthropic/claude-3-5-haiku",
            Model::OpenrouterMetaLlamaLlama4Maverick => "meta-llama/llama-4-maverick",
            Model::OpenrouterMetaLlamaLlama4Scout => "meta-llama/llama-4-scout",
            Model::OpenrouterMetaLlamaLlama3370bInstruct => "meta-llama/llama-3.3-70b-instruct",
            Model::OpenrouterMistralaiMistralMedium3 => "mistralai/mistral-medium-3",
            Model::OpenrouterMistralaiMistralSmall3224bInstruct => {
                "mistralai/mistral-small-3.2-24b-instruct"
            }
            Model::OpenrouterMistralaiMagistralMedium2506 => "mistralai/magistral-medium-2506",
            Model::OpenrouterMistralaiMagistralMedium2506Thinking => {
                "mistralai/magistral-medium-2506:thinking"
            }
            Model::OpenrouterMistralaiMagistralSmall2506 => "mistralai/magistral-small-2506",
            Model::OpenrouterMistralaiDevstralSmall => "mistralai/devstral-small",
            Model::OpenrouterMistralaiCodestral2501 => "mistralai/codestral-2501",
            Model::OpenrouterAi21Jamba16Large => "ai21/jamba-1.6-large",
            Model::OpenrouterAi21Jamba16Mini => "ai21/jamba-1.6-mini",
            Model::OpenrouterCohereCommandA => "cohere/command-a",
            Model::OpenrouterCohereCommandR7b122024 => "cohere/command-r7b-12-2024",
            Model::OpenrouterDeepseekDeepseekChatV30324 => "deepseek/deepseek-chat-v3-0324",
            Model::OpenrouterDeepseekDeepseekR10528 => "deepseek/deepseek-r1-0528",
            Model::OpenrouterQwenQwenMax => "qwen/qwen-max",
            Model::OpenrouterQwenQwenPlus => "qwen/qwen-plus",
            Model::OpenrouterQwenQwenTurbo => "qwen/qwen-turbo",
            Model::OpenrouterQwenQwenVlPlus => "qwen/qwen-vl-plus",
            Model::OpenrouterQwenQwen3235bA22b => "qwen/qwen3-235b-a22b",
            Model::OpenrouterQwenQwen330bA3b => "qwen/qwen3-30b-a3b",
            Model::OpenrouterQwenQwen332b => "qwen/qwen3-32b",
            Model::OpenrouterQwenQwq32b => "qwen/qwq-32b",
            Model::OpenrouterQwenQwen2572bInstruct => "qwen/qwen-2.5-72b-instruct",
            Model::OpenrouterQwenQwen25Vl72bInstruct => "qwen/qwen2.5-vl-72b-instruct",
            Model::OpenrouterQwenQwen25Coder32bInstruct => "qwen/qwen-2.5-coder-32b-instruct",
            Model::OpenrouterXAiGrok3 => "x-ai/grok-3",
            Model::OpenrouterXAiGrok3Mini => "x-ai/grok-3-mini",
            Model::OpenrouterAmazonNovaProV1 => "amazon/nova-pro-v1",
            Model::OpenrouterAmazonNovaLiteV1 => "amazon/nova-lite-v1",
            Model::OpenrouterAmazonNovaMicroV1 => "amazon/nova-micro-v1",
            Model::OpenrouterPerplexitySonarPro => "perplexity/sonar-pro",
            Model::OpenrouterPerplexitySonar => "perplexity/sonar",
            Model::OpenrouterPerplexitySonarReasoningPro => "perplexity/sonar-reasoning-pro",
            Model::OpenrouterPerplexitySonarReasoning => "perplexity/sonar-reasoning",
            Model::OpenrouterPerplexitySonarDeepResearch => "perplexity/sonar-deep-research",
            Model::OpenrouterPerplexityR11776 => "perplexity/r1-1776",
            Model::OpenrouterMinimaxMinimax01 => "minimax/minimax-01",
            Model::OpenrouterThudmGlm432b => "thudm/glm-4-32b",
            Model::OpenrouterThudmGlmZ132b => "thudm/glm-z1-32b",
            Model::OpenrouterMicrosoftPhi4ReasoningPlus => "microsoft/phi-4-reasoning-plus",
            Model::GithubGpt41 => "gpt-4.1",
            Model::GithubGpt41Mini => "gpt-4.1-mini",
            Model::GithubGpt41Nano => "gpt-4.1-nano",
            Model::GithubGpt4o => "gpt-4o",
            Model::GithubGpt4oMini => "gpt-4o-mini",
            Model::GithubO4Mini => "o4-mini",
            Model::GithubO4MiniHigh => "o4-mini-high",
            Model::GithubO3 => "o3",
            Model::GithubO3Mini => "o3-mini",
            Model::GithubO3MiniHigh => "o3-mini-high",
            Model::GithubTextEmbedding3Large => "text-embedding-3-large",
            Model::GithubTextEmbedding3Small => "text-embedding-3-small",
            Model::GithubLlama4Maverick17b128eInstructFp8 => {
                "llama-4-maverick-17b-128e-instruct-fp8"
            }
            Model::GithubLlama4Scout17b16eInstruct => "llama-4-scout-17b-16e-instruct",
            Model::GithubLlama3370bInstruct => "llama-3.3-70b-instruct",
            Model::GithubMistralMedium2505 => "mistral-medium-2505",
            Model::GithubMistralSmall2503 => "mistral-small-2503",
            Model::GithubCodestral2501 => "codestral-2501",
            Model::GithubCohereEmbedV3English => "cohere-embed-v3-english",
            Model::GithubCohereEmbedV3Multilingual => "cohere-embed-v3-multilingual",
            Model::GithubDeepseekR10528 => "deepseek-r1-0528",
            Model::GithubDeepseekV30324 => "deepseek-v3-0324",
            Model::GithubMaiDsR1 => "mai-ds-r1",
            Model::GithubPhi4 => "phi-4",
            Model::GithubPhi4MiniInstruct => "phi-4-mini-instruct",
            Model::GithubPhi4Reasoning => "phi-4-reasoning",
            Model::GithubPhi4MiniReasoning => "phi-4-mini-reasoning",
            Model::GithubGrok3 => "grok-3",
            Model::GithubGrok3Mini => "grok-3-mini",
            Model::DeepinfraMetaLlamaLlama4Maverick17b128eInstructFp8 => {
                "meta-llama/Llama-4-Maverick-17B-128E-Instruct-FP8"
            }
            Model::DeepinfraMetaLlamaLlama4Scout17b16eInstruct => {
                "meta-llama/Llama-4-Scout-17B-16E-Instruct"
            }
            Model::DeepinfraMetaLlamaLlama3370bInstruct => "meta-llama/Llama-3.3-70B-Instruct",
            Model::DeepinfraQwenQwen3235bA22b => "Qwen/Qwen3-235B-A22B",
            Model::DeepinfraQwenQwen330bA3b => "Qwen/Qwen3-30B-A3B",
            Model::DeepinfraQwenQwen332b => "Qwen/Qwen3-32B",
            Model::DeepinfraQwenQwq32b => "Qwen/QwQ-32B",
            Model::DeepinfraQwenQwen2572bInstruct => "Qwen/Qwen2.5-72B-Instruct",
            Model::DeepinfraQwenQwen25Coder32bInstruct => "Qwen/Qwen2.5-Coder-32B-Instruct",
            Model::DeepinfraDeepseekAiDeepseekV30324 => "deepseek-ai/DeepSeek-V3-0324",
            Model::DeepinfraDeepseekAiDeepseekR10528 => "deepseek-ai/DeepSeek-R1-0528",
            Model::DeepinfraGoogleGemma327bIt => "google/gemma-3-27b-it",
            Model::DeepinfraMistralaiMistralSmall3224bInstruct2506 => {
                "mistralai/Mistral-Small-3.2-24B-Instruct-2506"
            }
            Model::DeepinfraMistralaiDevstralSmall2505 => "mistralai/Devstral-Small-2505",
            Model::DeepinfraMicrosoftPhi4ReasoningPlus => "microsoft/phi-4-reasoning-plus",
            Model::DeepinfraBaaiBgeLargeEnV15 => "BAAI/bge-large-en-v1.5",
            Model::DeepinfraBaaiBgeM3 => "BAAI/bge-m3",
            Model::DeepinfraIntfloatE5LargeV2 => "intfloat/e5-large-v2",
            Model::DeepinfraIntfloatMultilingualE5Large => "intfloat/multilingual-e5-large",
            Model::DeepinfraThenlperGteLarge => "thenlper/gte-large",
            Model::JinaJinaEmbeddingsV3 => "jina-embeddings-v3",
            Model::JinaJinaClipV2 => "jina-clip-v2",
            Model::JinaJinaColbertV2 => "jina-colbert-v2",
            Model::JinaJinaRerankerV2BaseMultilingual => "jina-reranker-v2-base-multilingual",
            Model::JinaJinaColbertV2 => "jina-colbert-v2",
            Model::VoyageaiVoyage3Large => "voyage-3-large",
            Model::VoyageaiVoyage3 => "voyage-3",
            Model::VoyageaiVoyage3Lite => "voyage-3-lite",
            Model::VoyageaiRerank2 => "rerank-2",
            Model::VoyageaiRerank2Lite => "rerank-2-lite",
        }
    }
}
