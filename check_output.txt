   Compiling fluent_ai_provider v0.1.0 (/Volumes/samsung_t9/fluent-ai/packages/provider)
    Checking fluent_ai_candle v0.1.0 (/Volumes/samsung_t9/fluent-ai/packages/fluent-ai-candle)
warning: fluent_ai_provider@0.1.0: Starting provider generation...
warning: fluent_ai_provider@0.1.0: Generated providers.rs and models.rs with 6 providers
warning: fluent_ai_provider@0.1.0: Provider generation completed successfully
warning: unused imports: `SeekFrom`, `Seek`, and `self`
  --> packages/fluent-ai-candle/src/hub.rs:13:15
   |
13 | use std::io::{self, Read, Seek, SeekFrom, Write};
   |               ^^^^        ^^^^  ^^^^^^^^
   |
   = note: `#[warn(unused_imports)]` on by default

warning: unused import: `arc_swap::ArcSwap`
  --> packages/fluent-ai-candle/src/hub.rs:19:5
   |
19 | use arc_swap::ArcSwap;
   |     ^^^^^^^^^^^^^^^^^

warning: unused import: `HttpError`
  --> packages/fluent-ai-candle/src/hub.rs:25:60
   |
25 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpRequest, HttpError};
   |                                                            ^^^^^^^^^

warning: unused import: `ArrayString`
  --> packages/fluent-ai-candle/src/kv_cache/mod.rs:77:16
   |
77 | use arrayvec::{ArrayString, ArrayVec};
   |                ^^^^^^^^^^^

warning: unused imports: `DType`, `Device`, `Result as CandleResult`, and `Shape`
  --> packages/fluent-ai-candle/src/kv_cache/mod.rs:78:19
   |
78 | use candle_core::{Device, DType, Result as CandleResult, Shape, Tensor};
   |                   ^^^^^^  ^^^^^  ^^^^^^^^^^^^^^^^^^^^^^  ^^^^^

warning: unused imports: `Receiver`, `Sender`, `bounded`, and `unbounded`
  --> packages/fluent-ai-candle/src/kv_cache/mod.rs:79:25
   |
79 | use crossbeam_channel::{bounded, unbounded, Receiver, Sender};
   |                         ^^^^^^^  ^^^^^^^^^  ^^^^^^^^  ^^^^^^

warning: unused imports: `AtomicBool`, `Duration`, `Instant`, and `mem::MaybeUninit`
  --> packages/fluent-ai-candle/src/kv_cache/mod.rs:82:5
   |
82 |     mem::MaybeUninit,
   |     ^^^^^^^^^^^^^^^^
83 |     sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering},
   |                    ^^^^^^^^^^
84 |     time::{Duration, Instant},
   |            ^^^^^^^^  ^^^^^^^

warning: unused import: `wide::u32x8`
  --> packages/fluent-ai-candle/src/kv_cache/mod.rs:86:5
   |
86 | use wide::u32x8;
   |     ^^^^^^^^^^^

warning: unused import: `candle_core::Tensor`
 --> packages/fluent-ai-candle/src/logits.rs:8:5
  |
8 | use candle_core::Tensor;
  |     ^^^^^^^^^^^^^^^^^^^

warning: unused import: `RwLock`
 --> packages/fluent-ai-candle/src/model.rs:5:22
  |
5 | use std::sync::{Arc, RwLock};
  |                      ^^^^^^

warning: unused import: `DEFAULT_KV_CACHE_SIZE`
  --> packages/fluent-ai-candle/src/model.rs:14:24
   |
14 | use crate::constants::{DEFAULT_KV_CACHE_SIZE, DEFAULT_TOKEN_BUFFER_SIZE, MAX_MODEL_FILE_SIZE};
   |                        ^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `DType`
  --> packages/fluent-ai-candle/src/sampling/mod.rs:10:51
   |
10 | use candle_core::{Result as CandleResult, Tensor, DType};
   |                                                   ^^^^^

warning: unused import: `std::sync::Arc`
  --> packages/fluent-ai-candle/src/sampling/mod.rs:11:5
   |
11 | use std::sync::Arc;
   |     ^^^^^^^^^^^^^^

warning: unused import: `arrayvec::ArrayVec`
  --> packages/fluent-ai-candle/src/sampling/mod.rs:12:5
   |
12 | use arrayvec::ArrayVec;
   |     ^^^^^^^^^^^^^^^^^^

warning: unused import: `Result as CandleResult`
 --> packages/fluent-ai-candle/src/sampling/temperature.rs:6:19
  |
6 | use candle_core::{Result as CandleResult, Tensor, D};
  |                   ^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `Result as CandleResult`
 --> packages/fluent-ai-candle/src/sampling/nucleus.rs:7:19
  |
7 | use candle_core::{Result as CandleResult, Tensor, D};
  |                   ^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `Result as CandleResult`
 --> packages/fluent-ai-candle/src/sampling/composite.rs:6:19
  |
6 | use candle_core::{Result as CandleResult, Tensor};
  |                   ^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> packages/fluent-ai-candle/src/sampling/composite.rs:7:5
  |
7 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `Result as CandleResult`
 --> packages/fluent-ai-candle/src/sampling/gumbel.rs:6:19
  |
6 | use candle_core::{Result as CandleResult, Tensor, Device, DType, D};
  |                   ^^^^^^^^^^^^^^^^^^^^^^

warning: unused imports: `DType` and `Result as CandleResult`
 --> packages/fluent-ai-candle/src/sampling/typical.rs:6:19
  |
6 | use candle_core::{Result as CandleResult, Tensor, DType, D};
  |                   ^^^^^^^^^^^^^^^^^^^^^^          ^^^^^

warning: unused import: `arrayvec::ArrayVec`
  --> packages/fluent-ai-candle/src/streaming/mod.rs:20:5
   |
20 | use arrayvec::ArrayVec;
   |     ^^^^^^^^^^^^^^^^^^

warning: unused imports: `sleep` and `timeout`
  --> packages/fluent-ai-candle/src/streaming/mod.rs:24:19
   |
24 | use tokio::time::{timeout, sleep};
   |                   ^^^^^^^  ^^^^^

warning: unused import: `Stream`
   --> packages/fluent-ai-candle/src/streaming/mod.rs:787:39
    |
787 |         use futures::stream::{unfold, Stream};
    |                                       ^^^^^^

warning: unused import: `Result as CandleCoreResult`
  --> packages/fluent-ai-candle/src/var_builder.rs:35:34
   |
35 | use candle_core::{DType, Device, Result as CandleCoreResult, Shape, Tensor};
   |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `smallvec::SmallVec`
  --> packages/fluent-ai-candle/src/var_builder.rs:37:5
   |
37 | use smallvec::SmallVec;
   |     ^^^^^^^^^^^^^^^^^^

warning: unused imports: `AtomicBool`, `Duration`, `Instant`, and `mem::MaybeUninit`
  --> packages/fluent-ai-candle/src/var_builder.rs:39:5
   |
39 |     mem::MaybeUninit,
   |     ^^^^^^^^^^^^^^^^
40 |     sync::atomic::{AtomicBool, AtomicU64, AtomicUsize, Ordering},
   |                    ^^^^^^^^^^
41 |     time::{Duration, Instant},
   |            ^^^^^^^^  ^^^^^^^

error[E0782]: expected a type, found a trait
   --> packages/fluent-ai-candle/src/generator.rs:487:30
    |
487 |     logits_processor: Option<LogitsProcessor>,
    |                              ^^^^^^^^^^^^^^^
    |
help: you can add the `dyn` keyword if you want a trait object
    |
487 |     logits_processor: Option<dyn LogitsProcessor>,
    |                              +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:933:73
    |
933 |     fn select_victims(&self, count: usize, entries: &[KVCacheEntry]) -> SmallVec<[usize; 32]> {
    |                                                                         ^^^^^^^^ ----------- supplied 1 generic argument
    |                                                                         |
    |                                                                         expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
933 |     fn select_victims(&self, count: usize, entries: &[KVCacheEntry]) -> SmallVec<[usize; 32], N> {
    |                                                                                             +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:962:23
    |
962 |         victims: &mut SmallVec<[usize; 32]>,
    |                       ^^^^^^^^ ----------- supplied 1 generic argument
    |                       |
    |                       expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
962 |         victims: &mut SmallVec<[usize; 32], N>,
    |                                           +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:989:23
    |
989 |         victims: &mut SmallVec<[usize; 32]>,
    |                       ^^^^^^^^ ----------- supplied 1 generic argument
    |                       |
    |                       expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
989 |         victims: &mut SmallVec<[usize; 32], N>,
    |                                           +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
    --> packages/fluent-ai-candle/src/kv_cache/mod.rs:1016:23
     |
1016 |         victims: &mut SmallVec<[usize; 32]>,
     |                       ^^^^^^^^ ----------- supplied 1 generic argument
     |                       |
     |                       expected 2 generic arguments
     |
note: struct defined here, with 2 generic parameters: `T`, `N`
    --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
     |
302  | pub struct SmallVec<T, const N: usize> {
     |            ^^^^^^^^ -  --------------
help: add missing generic argument
     |
1016 |         victims: &mut SmallVec<[usize; 32], N>,
     |                                           +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
    --> packages/fluent-ai-candle/src/kv_cache/mod.rs:1032:23
     |
1032 |         victims: &mut SmallVec<[usize; 32]>,
     |                       ^^^^^^^^ ----------- supplied 1 generic argument
     |                       |
     |                       expected 2 generic arguments
     |
note: struct defined here, with 2 generic parameters: `T`, `N`
    --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
     |
302  | pub struct SmallVec<T, const N: usize> {
     |            ^^^^^^^^ -  --------------
help: add missing generic argument
     |
1032 |         victims: &mut SmallVec<[usize; 32], N>,
     |                                           +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
    --> packages/fluent-ai-candle/src/kv_cache/mod.rs:1059:23
     |
1059 |         victims: &mut SmallVec<[usize; 32]>,
     |                       ^^^^^^^^ ----------- supplied 1 generic argument
     |                       |
     |                       expected 2 generic arguments
     |
note: struct defined here, with 2 generic parameters: `T`, `N`
    --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
     |
302  | pub struct SmallVec<T, const N: usize> {
     |            ^^^^^^^^ -  --------------
help: add missing generic argument
     |
1059 |         victims: &mut SmallVec<[usize; 32], N>,
     |                                           +++

error[E0599]: the method `next` exists for struct `StreamingCoreResponse`, but its trait bounds were not satisfied
   --> packages/fluent-ai-candle/src/client.rs:386:58
    |
386 |                     while let Some(text_result) = stream.next().await {
    |                                                          ^^^^ method cannot be called on `StreamingCoreResponse` due to unsatisfied trait bounds
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:438:1
    |
438 | pub struct StreamingCoreResponse {
    | -------------------------------- doesn't satisfy `StreamingCoreResponse: StreamExt` or `StreamingCoreResponse: Stream`
    |
    = note: the following trait bounds were not satisfied:
            `StreamingCoreResponse: Stream`
            which is required by `StreamingCoreResponse: StreamExt`

error[E0277]: the size for values of type `str` cannot be known at compilation time
   --> packages/fluent-ai-candle/src/client.rs:388:32
    |
388 | ...                   Ok(text) => {
    |                          ^^^^ doesn't have a size known at compile-time
    |
    = help: the trait `Sized` is not implemented for `str`
    = note: all local variables must have a statically known size

error[E0277]: the size for values of type `str` cannot be known at compilation time
   --> packages/fluent-ai-candle/src/client.rs:388:29
    |
388 | ...                   Ok(text) => {
    |                       ^^^^^^^^ doesn't have a size known at compile-time
    |
    = help: the trait `Sized` is not implemented for `str`
note: required by a bound in `Ok`
   --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/result.rs:548:17
    |
548 | pub enum Result<T, E> {
    |                 ^ required by this bound in `Ok`
...
552 |     Ok(#[stable(feature = "rust1", since = "1.0.0")] T),
    |     -- required by a bound in this tuple variant

error[E0277]: the size for values of type `str` cannot be known at compilation time
   --> packages/fluent-ai-candle/src/client.rs:403:29
    |
403 | ...                   Err(error_text) => {
    |                       ^^^^^^^^^^^^^^^ doesn't have a size known at compile-time
    |
    = help: the trait `Sized` is not implemented for `str`
note: required by a bound in `std::prelude::v1::Err`
   --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/result.rs:548:17
    |
548 | pub enum Result<T, E> {
    |                 ^ required by this bound in `std::prelude::v1::Err`
...
557 |     Err(#[stable(feature = "rust1", since = "1.0.0")] E),
    |     --- required by a bound in this tuple variant

error[E0277]: the size for values of type `str` cannot be known at compilation time
   --> packages/fluent-ai-candle/src/client.rs:386:65
    |
386 |                     while let Some(text_result) = stream.next().await {
    |                                                                 ^^^^^ doesn't have a size known at compile-time
    |
    = help: the trait `Sized` is not implemented for `str`
note: required by an implicit `Sized` bound in `std::result::Result`
   --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/result.rs:548:17
    |
548 | pub enum Result<T, E> {
    |                 ^ required by the implicit `Sized` requirement on this type parameter in `Result`

error[E0599]: no method named `eos_token_id` found for struct `Arc<tokenizer::CandleTokenizer>` in the current scope
   --> packages/fluent-ai-candle/src/generator.rs:702:50
    |
702 |             if let Some(eos_id) = self.tokenizer.eos_token_id() {
    |                                                  ^^^^^^^^^^^^ method not found in `Arc<tokenizer::CandleTokenizer>`

error[E0599]: no method named `eos_token_id` found for struct `Arc<tokenizer::CandleTokenizer>` in the current scope
   --> packages/fluent-ai-candle/src/generator.rs:834:50
    |
834 |             if let Some(eos_id) = self.tokenizer.eos_token_id() {
    |                                                  ^^^^^^^^^^^^ method not found in `Arc<tokenizer::CandleTokenizer>`

error[E0599]: no function or associated item named `head` found for struct `HttpRequest` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:287:36
    |
287 |         let request = HttpRequest::head(&url)
    |                                    ^^^^ function or associated item not found in `HttpRequest`
    |
note: if you're trying to build a new `HttpRequest`, consider using `HttpRequest::new` which returns `HttpRequest`
   --> /Volumes/samsung_t9/fluent-ai/packages/http3/src/request.rs:35:5
    |
35  |     pub fn new(method: HttpMethod, url: String) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is a method `header` with a similar name, but with different arguments
   --> /Volumes/samsung_t9/fluent-ai/packages/http3/src/request.rs:83:5
    |
83  | /     pub fn header<K, V>(mut self, key: K, value: V) -> Self
84  | |     where
85  | |         K: Into<String>,
86  | |         V: Into<String>,
    | |________________________^

error[E0599]: no method named `to_str` found for reference `&std::string::String` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:304:29
    |
304 |             .and_then(|h| h.to_str().ok())
    |                             ^^^^^^
    |
help: there is a method `to_string` with a similar name
    |
304 |             .and_then(|h| h.to_string().ok())
    |                                   +++

error[E0432]: unresolved imports `crate::completion_provider::CompletionResponse`, `crate::completion_provider::StreamingResponse`
  --> packages/provider/src/clients/bedrock/completion.rs:26:42
   |
26 |     CompletionError, CompletionProvider, CompletionResponse, StreamingResponse,
   |                                          ^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^ no `StreamingResponse` in `completion_provider`
   |                                          |
   |                                          no `CompletionResponse` in `completion_provider`
   |
   = help: consider importing one of these structs instead:
           crate::clients::mistral::completion::CompletionResponse
           crate::clients::openrouter::completion::CompletionResponse
           crate::clients::perplexity::completion::CompletionResponse
           crate::clients::xai::completion::xai_api_types::CompletionResponse
           crate::domain::CompletionResponse
           fluent_ai_domain::CompletionResponse
note: struct `crate::clients::ollama::completion::CompletionResponse` exists but is inaccessible
  --> packages/provider/src/clients/ollama/completion.rs:55:1
   |
55 | pub struct CompletionResponse {
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible
   = help: consider importing one of these items instead:
           crate::clients::gemini::StreamingResponse
           crate::domain::completion::StreamingResponse
           fluent_ai_domain::completion::StreamingResponse

error[E0432]: unresolved imports `super::error::InferenceErrorCode`, `super::error::InferenceStage`
   --> packages/provider/src/clients/candle/client.rs:399:28
    |
399 |         use super::error::{InferenceErrorCode, InferenceStage};
    |                            ^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^ no `InferenceStage` in `clients::candle::error`
    |                            |
    |                            no `InferenceErrorCode` in `clients::candle::error`

error[E0432]: unresolved import `super::completion::CompletionModel`
  --> packages/provider/src/clients/gemini/client.rs:19:25
   |
19 | use super::completion::{CompletionModel, GEMINI_1_5_PRO};
   |                         ^^^^^^^^^^^^^^^ no `CompletionModel` in `clients::gemini::completion`
   |
   = help: consider importing one of these traits instead:
           crate::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0432]: unresolved import `super::embedding::EmbeddingModel`
  --> packages/provider/src/clients/gemini/client.rs:20:5
   |
20 | use super::embedding::EmbeddingModel;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ no `EmbeddingModel` in `clients::gemini::embedding`
   |
help: consider importing one of these items instead
   |
20 - use super::embedding::EmbeddingModel;
20 + use crate::EmbeddingModel;
   |
20 - use super::embedding::EmbeddingModel;
20 + use crate::domain::EmbeddingModel;
   |
20 - use super::embedding::EmbeddingModel;
20 + use candle_transformers::models::stella_en_v5::EmbeddingModel;
   |
20 - use super::embedding::EmbeddingModel;
20 + use fluent_ai_domain::EmbeddingModel;
   |

error[E0432]: unresolved import `super::transcription::TranscriptionModel`
  --> packages/provider/src/clients/gemini/client.rs:21:5
   |
21 | use super::transcription::TranscriptionModel;
   |     ^^^^^^^^^^^^^^^^^^^^^^------------------
   |     |                     |
   |     |                     help: a similar name exists in the module: `TranscriptionError`
   |     no `TranscriptionModel` in `clients::gemini::transcription`

error[E0364]: `create_request_body` is only public within the crate, and cannot be re-exported outside
  --> packages/provider/src/clients/gemini/completion.rs:14:67
   |
14 |     CompletionModel, GeminiCompletionBuilder, completion_builder, create_request_body,
   |                                                                   ^^^^^^^^^^^^^^^^^^^
   |
note: consider marking `create_request_body` as `pub` in the imported module
  --> packages/provider/src/clients/gemini/completion.rs:14:67
   |
14 |     CompletionModel, GeminiCompletionBuilder, completion_builder, create_request_body,
   |                                                                   ^^^^^^^^^^^^^^^^^^^

error[E0432]: unresolved import `super::gemini_client::CompletionModel`
  --> packages/provider/src/clients/gemini/completion.rs:14:5
   |
14 |     CompletionModel, GeminiCompletionBuilder, completion_builder, create_request_body,
   |     ^^^^^^^^^^^^^^^
   |     |
   |     no `CompletionModel` in `clients::gemini::gemini_client`
   |     help: a similar name exists in the module: `CompletionChunk`
   |
   = help: consider importing one of these traits instead:
           crate::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0432]: unresolved imports `crate::completion`, `crate::completion`
  --> packages/provider/src/clients/gemini/completion_old.rs:50:5
   |
50 |     completion::{self, CompletionError, CompletionRequest},
   |     ^^^^^^^^^^   ^^^^ no `completion` in the root
   |     |
   |     unresolved import
   |     help: a similar path exists: `fluent_ai_domain::completion`
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible

error[E0599]: no method named `to_str` found for reference `&std::string::String` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:310:29
    |
310 |             .and_then(|h| h.to_str().ok())
    |                             ^^^^^^
    |
help: there is a method `to_string` with a similar name
    |
310 |             .and_then(|h| h.to_string().ok())
    |                                   +++

error[E0432]: unresolved imports `crate::completion`, `crate::message`, `crate::message`
   --> packages/provider/src/clients/gemini/completion_old.rs:857:9
    |
857 |         completion::CompletionError,
    |         ^^^^^^^^^^ unresolved import
858 |         message::{self, MimeType as _},
    |         ^^^^^^^   ^^^^ no `message` in the root
    |         |
    |         unresolved import
    |
    = help: consider importing one of these modules instead:
            crate::domain::message
            fluent_ai_domain::message
help: a similar path exists
    |
857 |         fluent_ai_domain::completion::CompletionError,
    |         ++++++++++++++++++
help: a similar path exists
    |
858 |         fluent_ai_domain::message::{self, MimeType as _},
    |         ++++++++++++++++++

error[E0432]: unresolved imports `crate::embeddings`, `crate::embeddings`
  --> packages/provider/src/clients/gemini/embedding.rs:10:12
   |
10 | use crate::embeddings::{self, EmbeddingError};
   |            ^^^^^^^^^^   ^^^^ no `embeddings` in the root
   |            |
   |            unresolved import
   |            help: a similar path exists: `candle_transformers::models::stable_diffusion::embeddings`
   |
   = help: consider importing this module instead:
           candle_transformers::models::stable_diffusion::embeddings
note: module `crate::clients::openai::embeddings` exists but is inaccessible
  --> packages/provider/src/clients/openai/mod.rs:50:1
   |
50 | mod embeddings;
   | ^^^^^^^^^^^^^^^ not accessible

error[E0432]: unresolved imports `crate::completion`, `crate::streaming`
  --> packages/provider/src/clients/gemini/streaming.rs:7:5
   |
7  |     completion::{CompletionError, CompletionRequest},
   |     ^^^^^^^^^^
   |     |
   |     unresolved import
   |     help: a similar path exists: `fluent_ai_domain::completion`
8  |     streaming::{self},
   |                 ^^^^ no `streaming` in the root
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::streaming
           crate::clients::azure::streaming
           crate::clients::candle::streaming
           crate::clients::deepseek::streaming
           crate::clients::gemini::streaming
           crate::clients::huggingface::streaming
           crate::clients::openrouter::streaming
           crate::clients::perplexity::streaming
           crate::clients::together::streaming
           crate::clients::xai::streaming
           candle_core::streaming
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:49:1
   |
49 | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::bedrock::streaming`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:9:1
   |
9  | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:9:1
   |
9  | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:55:1
   |
55 | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible

error[E0432]: unresolved imports `crate::transcription`, `crate::transcription`
  --> packages/provider/src/clients/gemini/transcription.rs:12:12
   |
12 | use crate::transcription::{self, TranscriptionError};
   |            ^^^^^^^^^^^^^   ^^^^ no `transcription` in the root
   |            |
   |            unresolved import
   |            help: a similar path exists: `clients::azure::transcription`
   |
   = help: consider importing one of these modules instead:
           crate::clients::azure::transcription
           crate::clients::gemini::transcription
           crate::clients::huggingface::transcription

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::streaming`
  --> packages/provider/src/clients/gemini/gemini_client.rs:24:5
   |
24 |     completion::{self, CompletionError, CompletionRequest},
   |     ^^^^^^^^^^   ^^^^ no `completion` in the root
   |     |
   |     unresolved import
25 |     completion_provider::{ChunkHandler, CompletionProvider, ModelConfig, ModelInfo},
26 |     streaming::StreamingCompletionResponse,
   |     ^^^^^^^^^ unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: a similar path exists
   |
24 |     fluent_ai_domain::completion::{self, CompletionError, CompletionRequest},
   |     ++++++++++++++++++
help: a similar path exists
   |
26 |     candle_core::streaming::StreamingCompletionResponse,
   |     +++++++++++++

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::message`
  --> packages/provider/src/clients/gemini/gemini_types.rs:15:5
   |
15 |     completion::{self, CompletionError},
   |     ^^^^^^^^^^   ^^^^ no `completion` in the root
   |     |
   |     unresolved import
   |     help: a similar path exists: `fluent_ai_domain::completion`
16 |     message,
   |     ^^^^^^^ no `message` in the root
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing one of these modules instead:
           crate::domain::message
           fluent_ai_domain::message

error[E0432]: unresolved import `super::completion::CompletionModel`
  --> packages/provider/src/clients/groq/client.rs:17:25
   |
17 | use super::completion::{CompletionModel, LLAMA_3_70B_8192};
   |                         ^^^^^^^^^^^^^^^
   |                         |
   |                         no `CompletionModel` in `clients::groq::completion`
   |                         help: a similar name exists in the module: `CompletionChunk`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::gemini::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::message`
  --> packages/provider/src/clients/groq/client.rs:20:5
   |
20 |     completion::{
   |     ^^^^^^^^^^ unresolved import
21 |         self, CompletionError, CompletionRequest, CompletionRequestBuilder, Prompt, PromptError,
   |         ^^^^ no `completion` in the root
22 |     },
23 |     message::Message,
   |     ^^^^^^^ unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::groq::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: a similar path exists
   |
20 |     fluent_ai_domain::completion::{
   |     ++++++++++++++++++
help: a similar path exists
   |
23 |     fluent_ai_domain::message::Message,
   |     ++++++++++++++++++

error[E0599]: no function or associated item named `get` found for struct `HttpRequest` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:359:40
    |
359 |         let mut request = HttpRequest::get(&url, Vec::new())
    |                                        ^^^ function or associated item not found in `HttpRequest`
    |
note: if you're trying to build a new `HttpRequest`, consider using `HttpRequest::new` which returns `HttpRequest`
   --> /Volumes/samsung_t9/fluent-ai/packages/http3/src/request.rs:35:5
    |
35  |     pub fn new(method: HttpMethod, url: String) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::message`, `crate::message`, `crate::streaming`
  --> packages/provider/src/clients/groq/completion.rs:22:5
   |
22 |     completion::{self, CompletionError, CompletionRequest},
   |     ^^^^^^^^^^   ^^^^ no `completion` in the root
   |     |
   |     unresolved import
...
26 |     message::{self, MessageError},
   |     ^^^^^^^   ^^^^ no `message` in the root
   |     |
   |     unresolved import
27 |     streaming::StreamingCompletionResponse,
   |     ^^^^^^^^^ unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::groq::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing one of these modules instead:
           crate::domain::message
           fluent_ai_domain::message
help: a similar path exists
   |
22 |     fluent_ai_domain::completion::{self, CompletionError, CompletionRequest},
   |     ++++++++++++++++++
help: a similar path exists
   |
26 |     fluent_ai_domain::message::{self, MessageError},
   |     ++++++++++++++++++
help: a similar path exists
   |
27 |     candle_core::streaming::StreamingCompletionResponse,
   |     +++++++++++++

error[E0432]: unresolved import `crate::clients::openai::CompletionResponse`
   --> packages/provider/src/clients/groq/completion.rs:179:9
    |
179 | pub use crate::clients::openai::CompletionResponse;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ no `CompletionResponse` in `clients::openai`
    |
note: struct `crate::clients::ollama::completion::CompletionResponse` exists but is inaccessible
   --> packages/provider/src/clients/ollama/completion.rs:55:1
    |
55  | pub struct CompletionResponse {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible
help: consider importing one of these structs instead
    |
179 - pub use crate::clients::openai::CompletionResponse;
179 + pub use crate::clients::mistral::completion::CompletionResponse;
    |
179 - pub use crate::clients::openai::CompletionResponse;
179 + pub use crate::clients::openrouter::completion::CompletionResponse;
    |
179 - pub use crate::clients::openai::CompletionResponse;
179 + pub use crate::clients::perplexity::completion::CompletionResponse;
    |
179 - pub use crate::clients::openai::CompletionResponse;
179 + pub use crate::clients::xai::completion::xai_api_types::CompletionResponse;
    |
      and 2 other candidates

error[E0432]: unresolved imports `crate::clients::openai::CompletionResponse`, `crate::completion`, `crate::http`
  --> packages/provider/src/clients/groq/streaming.rs:13:23
   |
13 |     clients::openai::{CompletionResponse, StreamingChoice, StreamingMessage},
   |                       ^^^^^^^^^^^^^^^^^^ no `CompletionResponse` in `clients::openai`
14 |     completion::CompletionError,
   |     ^^^^^^^^^^
   |     |
   |     unresolved import
   |     help: a similar path exists: `fluent_ai_domain::completion`
15 |     http::{HttpClient, HttpRequest},
   |     ^^^^ could not find `http` in the crate root
   |
   = help: consider importing one of these items instead:
           crate::clients::groq::completion::CompletionResponse
           crate::clients::mistral::completion::CompletionResponse
           crate::clients::openrouter::completion::CompletionResponse
           crate::clients::perplexity::completion::CompletionResponse
           crate::clients::xai::completion::xai_api_types::CompletionResponse
           crate::domain::CompletionResponse
           fluent_ai_domain::CompletionResponse
note: struct `crate::clients::ollama::completion::CompletionResponse` exists but is inaccessible
  --> packages/provider/src/clients/ollama/completion.rs:55:1
   |
55 | pub struct CompletionResponse {
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0432]: unresolved import `completion::CompletionModel`
  --> packages/provider/src/clients/groq/mod.rs:12:22
   |
12 | pub use completion::{CompletionModel, GroqCompletionBuilder as GroqProvider};
   |                      ^^^^^^^^^^^^^^^
   |                      |
   |                      no `CompletionModel` in `clients::groq::completion`
   |                      help: a similar name exists in the module: `CompletionChunk`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::gemini::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0432]: unresolved import `super::completion::CompletionModel`
 --> packages/provider/src/clients/huggingface/streaming.rs:8:5
  |
8 | use super::completion::CompletionModel;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ no `CompletionModel` in `clients::huggingface::completion`
  |
help: a similar name exists in the module
  |
8 - use super::completion::CompletionModel;
8 + use super::completion::CompletionChunk;
  |
help: consider importing one of these items instead
  |
8 - use super::completion::CompletionModel;
8 + use crate::CompletionModel;
  |
8 - use super::completion::CompletionModel;
8 + use crate::clients::groq::CompletionModel;
  |
8 - use super::completion::CompletionModel;
8 + use crate::clients::xai::CompletionModel;
  |
8 - use super::completion::CompletionModel;
8 + use fluent_ai_domain::CompletionModel;
  |

error[E0432]: unresolved import `crate::streaming`
  --> packages/provider/src/clients/huggingface/streaming.rs:18:5
   |
18 | use crate::streaming;
   |     ^^^^^^^^^^^^^^^^ no `streaming` in the root
   |
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:49:1
   |
49 | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::bedrock::streaming`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:9:1
   |
9  | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:9:1
   |
9  | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:55:1
   |
55 | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: consider importing one of these modules instead
   |
18 | use crate::clients::anthropic::streaming;
   |            ++++++++++++++++++++
18 | use crate::clients::azure::streaming;
   |            ++++++++++++++++
18 | use crate::clients::candle::streaming;
   |            +++++++++++++++++
18 | use crate::clients::deepseek::streaming;
   |            +++++++++++++++++++
     and 7 other candidates

error[E0432]: unresolved import `super::completion::ApiResponse`
  --> packages/provider/src/clients/huggingface/transcription.rs:8:5
   |
8  | use super::completion::ApiResponse;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ no `ApiResponse` in `clients::huggingface::completion`
   |
note: these enums exist but are inaccessible
  --> packages/provider/src/clients/azure/completion.rs:64:1
   |
64 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::completion::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/azure/embedding.rs:70:1
   |
70 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::embedding::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/azure/transcription.rs:29:1
   |
29 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::transcription::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/groq/completion.rs:82:1
   |
82 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::groq::completion::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/ollama/completion.rs:46:1
   |
46 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::ollama::completion::ApiResponse`: not accessible
help: consider importing one of these items instead
   |
8  - use super::completion::ApiResponse;
8  + use crate::clients::anthropic::ApiResponse;
   |
8  - use super::completion::ApiResponse;
8  + use crate::clients::gemini::ApiResponse;
   |
8  - use super::completion::ApiResponse;
8  + use crate::clients::openrouter::client::ApiResponse;
   |
8  - use super::completion::ApiResponse;
8  + use crate::clients::perplexity::client::ApiResponse;
   |
     and 1 other candidate

error[E0432]: unresolved import `crate::transcription`
 --> packages/provider/src/clients/huggingface/transcription.rs:9:5
  |
9 | use crate::transcription;
  |     ^^^^^^^^^^^^^^^^^^^^ no `transcription` in the root
  |
help: consider importing one of these modules instead
  |
9 | use crate::clients::azure::transcription;
  |            ++++++++++++++++
9 | use crate::clients::gemini::transcription;
  |            +++++++++++++++++
9 | use crate::clients::huggingface::transcription;
  |            ++++++++++++++++++++++

error[E0432]: unresolved import `crate::transcription`
  --> packages/provider/src/clients/huggingface/transcription.rs:10:12
   |
10 | use crate::transcription::TranscriptionError;
   |            ^^^^^^^^^^^^^
   |            |
   |            unresolved import
   |            help: a similar path exists: `clients::azure::transcription`

error[E0432]: unresolved imports `super::client::Client`, `super::client::Usage`
 --> packages/provider/src/clients/mistral/completion.rs:7:21
  |
7 | use super::client::{Client, Usage};
  |                     ^^^^^^  ^^^^^ no `Usage` in `clients::mistral::client`
  |                     |
  |                     no `Client` in `clients::mistral::client`
  |
  = help: consider importing one of these structs instead:
          crate::clients::azure::Client
          crate::clients::gemini::Client
          crate::clients::groq::Client
          crate::clients::huggingface::Client
          crate::clients::ollama::Client
          crate::clients::openrouter::Client
          crate::clients::perplexity::Client
          crate::clients::together::Client
          crate::clients::xai::Client
          crate::domain::tool::mcp::Client
          fluent_ai_domain::tool::mcp::Client
          progresshub::Client
          progresshub::bandwidth::dns::Client
          reqwest::Client
  = help: consider importing one of these items instead:
          crate::clients::azure::Usage
          crate::clients::openrouter::client::Usage
          crate::clients::perplexity::completion::Usage
          crate::clients::together::embedding::Usage
          crate::clients::xai::completion::xai_api_types::Usage
          crate::domain::chat::commands::StatsType::Usage
          crate::domain::usage::Usage
          fluent_ai_domain::chat::commands::StatsType::Usage
          fluent_ai_domain::usage::Usage

error[E0432]: unresolved import `crate::streaming`
 --> packages/provider/src/clients/mistral/completion.rs:8:12
  |
8 | use crate::streaming::{RawStreamingChoice, StreamingCompletionResponse};
  |            ^^^^^^^^^
  |            |
  |            unresolved import
  |            help: a similar path exists: `candle_core::streaming`

error[E0599]: no method named `to_str` found for reference `&std::string::String` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:380:29
    |
380 |             .and_then(|h| h.to_str().ok())
    |                             ^^^^^^
    |
help: there is a method `to_string` with a similar name
    |
380 |             .and_then(|h| h.to_string().ok())
    |                                   +++

error[E0432]: unresolved imports `crate::clients::mistral::client::ApiResponse`, `crate::completion`, `crate::completion`, `crate::json_util`, `crate::message`
  --> packages/provider/src/clients/mistral/completion.rs:11:5
   |
11 |     clients::mistral::client::ApiResponse,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ no `ApiResponse` in `clients::mistral::client`
12 |     completion::{self, CompletionError, CompletionRequest},
   |     ^^^^^^^^^^   ^^^^ no `completion` in the root
   |     |
   |     unresolved import
   |     help: a similar path exists: `fluent_ai_domain::completion`
13 |     json_util, message,
   |     ^^^^^^^^^  ^^^^^^^ no `message` in the root
   |     |
   |     no `json_util` in the root
   |
   = help: consider importing one of these items instead:
           crate::clients::anthropic::ApiResponse
           crate::clients::gemini::ApiResponse
           crate::clients::openrouter::client::ApiResponse
           crate::clients::perplexity::client::ApiResponse
           crate::clients::together::client::together_ai_api_types::ApiResponse
note: these enums exist but are inaccessible
  --> packages/provider/src/clients/azure/completion.rs:64:1
   |
64 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::completion::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/azure/embedding.rs:70:1
   |
70 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::embedding::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/azure/transcription.rs:29:1
   |
29 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::transcription::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/groq/completion.rs:82:1
   |
82 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::groq::completion::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/ollama/completion.rs:46:1
   |
46 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::ollama::completion::ApiResponse`: not accessible
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing one of these modules instead:
           crate::domain::message
           fluent_ai_domain::message

error[E0432]: unresolved imports `super::client::ApiResponse`, `super::client::Client`, `super::client::Usage`
  --> packages/provider/src/clients/mistral/embedding.rs:5:21
   |
5  | use super::client::{ApiResponse, Client, Usage};
   |                     ^^^^^^^^^^^  ^^^^^^  ^^^^^ no `Usage` in `clients::mistral::client`
   |                     |            |
   |                     |            no `Client` in `clients::mistral::client`
   |                     no `ApiResponse` in `clients::mistral::client`
   |
   = help: consider importing one of these items instead:
           crate::clients::anthropic::ApiResponse
           crate::clients::gemini::ApiResponse
           crate::clients::openrouter::client::ApiResponse
           crate::clients::perplexity::client::ApiResponse
           crate::clients::together::client::together_ai_api_types::ApiResponse
note: these enums exist but are inaccessible
  --> packages/provider/src/clients/azure/completion.rs:64:1
   |
64 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::completion::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/azure/embedding.rs:70:1
   |
70 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::embedding::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/azure/transcription.rs:29:1
   |
29 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::azure::transcription::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/groq/completion.rs:82:1
   |
82 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::groq::completion::ApiResponse`: not accessible
   |
  ::: packages/provider/src/clients/ollama/completion.rs:46:1
   |
46 | enum ApiResponse<T> {
   | ^^^^^^^^^^^^^^^^^^^ `crate::clients::ollama::completion::ApiResponse`: not accessible
   = help: consider importing one of these structs instead:
           crate::clients::azure::Client
           crate::clients::gemini::Client
           crate::clients::groq::Client
           crate::clients::huggingface::Client
           crate::clients::ollama::Client
           crate::clients::openrouter::Client
           crate::clients::perplexity::Client
           crate::clients::together::Client
           crate::clients::xai::Client
           crate::domain::tool::mcp::Client
           fluent_ai_domain::tool::mcp::Client
           progresshub::Client
           progresshub::bandwidth::dns::Client
           reqwest::Client
   = help: consider importing one of these items instead:
           crate::clients::azure::Usage
           crate::clients::openrouter::client::Usage
           crate::clients::perplexity::completion::Usage
           crate::clients::together::embedding::Usage
           crate::clients::xai::completion::xai_api_types::Usage
           crate::domain::chat::commands::StatsType::Usage
           crate::domain::usage::Usage
           fluent_ai_domain::chat::commands::StatsType::Usage
           fluent_ai_domain::usage::Usage

error[E0432]: unresolved imports `crate::embeddings`, `crate::embeddings`
  --> packages/provider/src/clients/mistral/embedding.rs:6:12
   |
6  | use crate::embeddings::{self, EmbeddingError};
   |            ^^^^^^^^^^   ^^^^ no `embeddings` in the root
   |            |
   |            unresolved import
   |            help: a similar path exists: `candle_transformers::models::stable_diffusion::embeddings`
   |
   = help: consider importing this module instead:
           candle_transformers::models::stable_diffusion::embeddings
note: module `crate::clients::openai::embeddings` exists but is inaccessible
  --> packages/provider/src/clients/openai/mod.rs:50:1
   |
50 | mod embeddings;
   | ^^^^^^^^^^^^^^^ not accessible

error[E0432]: unresolved import `client::Client`
 --> packages/provider/src/clients/mistral/mod.rs:6:18
  |
6 | pub use client::{Client, MistralCompletionBuilder};
  |                  ^^^^^^ no `Client` in `clients::mistral::client`
  |
  = help: consider importing one of these structs instead:
          crate::clients::azure::Client
          crate::clients::gemini::Client
          crate::clients::groq::Client
          crate::clients::huggingface::Client
          crate::clients::ollama::Client
          crate::clients::openrouter::Client
          crate::clients::perplexity::Client
          crate::clients::together::Client
          crate::clients::xai::Client
          crate::domain::tool::mcp::Client
          fluent_ai_domain::tool::mcp::Client
          progresshub::Client
          progresshub::bandwidth::dns::Client
          reqwest::Client

error[E0432]: unresolved import `completion::CompletionModel`
 --> packages/provider/src/clients/mistral/mod.rs:8:33
  |
8 |     CODESTRAL, CODESTRAL_MAMBA, CompletionModel, MINISTRAL_3B, MINISTRAL_8B, MISTRAL_LARGE,
  |                                 ^^^^^^^^^^^^^^^
  |                                 |
  |                                 no `CompletionModel` in `clients::mistral::completion`
  |                                 help: a similar name exists in the module: `CompletionChunk`
  |
  = help: consider importing one of these items instead:
          crate::CompletionModel
          crate::clients::groq::CompletionModel
          crate::clients::xai::CompletionModel
          fluent_ai_domain::CompletionModel

error[E0432]: unresolved import `embedding::EmbeddingModel`
  --> packages/provider/src/clients/mistral/mod.rs:13:21
   |
13 | pub use embedding::{EmbeddingModel, MISTRAL_EMBED};
   |                     ^^^^^^^^^^^^^^ no `EmbeddingModel` in `clients::mistral::embedding`
   |
   = help: consider importing one of these items instead:
           crate::EmbeddingModel
           crate::domain::EmbeddingModel
           candle_transformers::models::stella_en_v5::EmbeddingModel
           fluent_ai_domain::EmbeddingModel

error[E0432]: unresolved imports `super::completion::CompletionModel`, `super::completion::EmbeddingModel`
  --> packages/provider/src/clients/ollama/client.rs:18:25
   |
18 | use super::completion::{CompletionModel, EmbeddingModel, MISTRAL_MAGISTRAR_SMALL};
   |                         ^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^ no `EmbeddingModel` in `clients::ollama::completion`
   |                         |
   |                         no `CompletionModel` in `clients::ollama::completion`
   |                         help: a similar name exists in the module: `CompletionError`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::mistral::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel
   = help: consider importing one of these items instead:
           crate::EmbeddingModel
           crate::clients::mistral::EmbeddingModel
           crate::domain::EmbeddingModel
           candle_transformers::models::stella_en_v5::EmbeddingModel
           fluent_ai_domain::EmbeddingModel

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::embeddings`, `crate::json_util`, `crate::message`, `crate::runtime`, `crate::runtime`
  --> packages/provider/src/clients/ollama/client.rs:21:5
   |
21 |     completion::{
   |     ^^^^^^^^^^ unresolved import
22 |         self, CompletionError, CompletionRequest, CompletionRequestBuilder, Prompt, PromptError,
   |         ^^^^ no `completion` in the root
23 |     },
24 |     embeddings::{Embed, Embedding, EmbeddingBuilder},
   |     ^^^^^^^^^^ unresolved import
25 |     json_util,
   |     ^^^^^^^^^ no `json_util` in the root
26 |     message::Message,
   |     ^^^^^^^ unresolved import
27 |     runtime::{self, AsyncTask},
   |     ^^^^^^^   ^^^^ no `runtime` in the root
   |     |
   |     unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::ollama::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing this module instead:
           tokio::runtime
help: a similar path exists
   |
21 |     fluent_ai_domain::completion::{
   |     ++++++++++++++++++
help: a similar path exists
   |
24 |     candle_transformers::models::stable_diffusion::embeddings::{Embed, Embedding, EmbeddingBuilder},
   |     +++++++++++++++++++++++++++++++++++++++++++++++
help: a similar path exists
   |
26 |     fluent_ai_domain::message::Message,
   |     ++++++++++++++++++
help: a similar path exists
   |
27 |     tokio::runtime::{self, AsyncTask},
   |     +++++++

error[E0599]: no method named `stream` found for struct `HttpResponse` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:417:35
    |
417 |         let mut stream = response.stream();
    |                                   ^^^^^^ method not found in `HttpResponse`

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::embeddings`, `crate::embeddings`, `crate::json_util`, `crate::message`, `crate::message`, `crate::runtime`, `crate::runtime`, `crate::streaming`
  --> packages/provider/src/clients/ollama/completion.rs:14:5
   |
14 |     completion::{
   |     ^^^^^^^^^^ unresolved import
15 |         self, AssistantContent, CompletionError, CompletionRequest, Message as CompletionMessage,
   |         ^^^^ no `completion` in the root
16 |     },
17 |     embeddings::{self, Embedding, EmbeddingError, EmbeddingModel as EmbeddingModelTrait},
   |     ^^^^^^^^^^   ^^^^ no `embeddings` in the root
   |     |
   |     unresolved import
18 |     json_util,
   |     ^^^^^^^^^ no `json_util` in the root
19 |     message::{self, Message, MessageError, Text, ToolResultContent, UserContent},
   |     ^^^^^^^   ^^^^ no `message` in the root
   |     |
   |     unresolved import
20 |     runtime::{self, AsyncTask},
   |     ^^^^^^^   ^^^^ no `runtime` in the root
   |     |
   |     unresolved import
21 |     streaming::StreamingCompletionResponse,
   |     ^^^^^^^^^ unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::ollama::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing this module instead:
           candle_transformers::models::stable_diffusion::embeddings
note: module `crate::clients::openai::embeddings` exists but is inaccessible
  --> packages/provider/src/clients/openai/mod.rs:50:1
   |
50 | mod embeddings;
   | ^^^^^^^^^^^^^^^ not accessible
   = help: consider importing one of these modules instead:
           crate::domain::message
           fluent_ai_domain::message
   = help: consider importing this module instead:
           tokio::runtime
help: a similar path exists
   |
14 |     fluent_ai_domain::completion::{
   |     ++++++++++++++++++
help: a similar path exists
   |
17 |     candle_transformers::models::stable_diffusion::embeddings::{self, Embedding, EmbeddingError, EmbeddingModel as EmbeddingModelTrait},
   |     +++++++++++++++++++++++++++++++++++++++++++++++
help: a similar path exists
   |
19 |     fluent_ai_domain::message::{self, Message, MessageError, Text, ToolResultContent, UserContent},
   |     ++++++++++++++++++
help: a similar path exists
   |
20 |     tokio::runtime::{self, AsyncTask},
   |     +++++++
help: a similar path exists
   |
21 |     candle_core::streaming::StreamingCompletionResponse,
   |     +++++++++++++

error[E0432]: unresolved imports `crate::completion`, `crate::runtime`, `crate::runtime`, `crate::streaming`
  --> packages/provider/src/clients/ollama/streaming.rs:13:5
   |
13 |     completion::CompletionError,
   |     ^^^^^^^^^^ unresolved import
14 |     runtime::{self, AsyncStream},
   |     ^^^^^^^   ^^^^ no `runtime` in the root
   |     |
   |     unresolved import
15 |     streaming::{RawStreamingChoice, StreamingCompletionResponse},
   |     ^^^^^^^^^ unresolved import
   |
   = help: consider importing this module instead:
           tokio::runtime
help: a similar path exists
   |
13 |     fluent_ai_domain::completion::CompletionError,
   |     ++++++++++++++++++
help: a similar path exists
   |
14 |     tokio::runtime::{self, AsyncStream},
   |     +++++++
help: a similar path exists
   |
15 |     candle_core::streaming::{RawStreamingChoice, StreamingCompletionResponse},
   |     +++++++++++++

error[E0432]: unresolved imports `completion::CompletionModel`, `completion::EmbeddingModel`
  --> packages/provider/src/clients/ollama/mod.rs:14:22
   |
14 | pub use completion::{CompletionModel, EmbeddingModel};
   |                      ^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^ no `EmbeddingModel` in `clients::ollama::completion`
   |                      |
   |                      no `CompletionModel` in `clients::ollama::completion`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::mistral::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel
   = help: consider importing one of these items instead:
           crate::EmbeddingModel
           crate::clients::mistral::EmbeddingModel
           crate::domain::EmbeddingModel
           candle_transformers::models::stella_en_v5::EmbeddingModel
           fluent_ai_domain::EmbeddingModel

error[E0432]: unresolved import `audio::OpenAIAudioClient`
  --> packages/provider/src/clients/openai/mod.rs:31:17
   |
31 | pub use audio::{OpenAIAudioClient, TranscriptionResponse};
   |                 ^^^^^^^^^^^^^^^^^ no `OpenAIAudioClient` in `clients::openai::audio`

error[E0432]: unresolved import `client::OpenAIProvider`
  --> packages/provider/src/clients/openai/mod.rs:33:32
   |
33 | pub use client::{OpenAIClient, OpenAIProvider};
   |                                ^^^^^^^^^^^^^^ no `OpenAIProvider` in `clients::openai::client`

error[E0432]: unresolved imports `completion::CompletionResponse`, `completion::OpenAICompletionResponse`
  --> packages/provider/src/clients/openai/mod.rs:34:47
   |
34 | pub use completion::{OpenAICompletionBuilder, CompletionResponse, OpenAICompletionRequest, OpenAICompletionResponse};
   |                                               ^^^^^^^^^^^^^^^^^^                           ^^^^^^^^^^^^^^^^^^^^^^^^
   |                                               |                                            |
   |                                               |                                            no `OpenAICompletionResponse` in `clients::openai::completion`
   |                                               |                                            help: a similar name exists in the module: `OpenAICompletionRequest`
   |                                               no `CompletionResponse` in `clients::openai::completion`
   |
   = help: consider importing one of these structs instead:
           crate::clients::mistral::completion::CompletionResponse
           crate::clients::openrouter::completion::CompletionResponse
           crate::clients::perplexity::completion::CompletionResponse
           crate::clients::xai::completion::xai_api_types::CompletionResponse
           crate::domain::CompletionResponse
           fluent_ai_domain::CompletionResponse
note: these items exist but are inaccessible:
      crate::clients::groq::completion::CompletionResponse
  --> packages/provider/src/clients/ollama/completion.rs:55:1
   |
55 | pub struct CompletionResponse {
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ `crate::clients::ollama::completion::CompletionResponse`: not accessible

error[E0432]: unresolved import `embeddings::OpenAIEmbeddingClient`
  --> packages/provider/src/clients/openai/mod.rs:36:9
   |
36 | pub use embeddings::OpenAIEmbeddingClient;
   |         ^^^^^^^^^^^^---------------------
   |         |           |
   |         |           help: a similar name exists in the module: `OpenAIEmbeddingRequest`
   |         no `OpenAIEmbeddingClient` in `clients::openai::embeddings`

error[E0432]: unresolved import `streaming::OpenAIStream`
  --> packages/provider/src/clients/openai/mod.rs:39:21
   |
39 | pub use streaming::{OpenAIStream, StreamingCompletionResponse, StreamingChoice, StreamingMessage, send_compatible_streaming_request};
   |                     ^^^^^^^^^^^^ no `OpenAIStream` in `clients::openai::streaming`

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/openai/discovery.rs:21:12
   |
21 | use crate::model::{
   |            ^^^^^
   |            |
   |            unresolved import
   |            help: a similar path exists: `fluent_ai_domain::model`

error[E0432]: unresolved import `vision::OpenAIVisionClient`
  --> packages/provider/src/clients/openai/mod.rs:40:9
   |
40 | pub use vision::OpenAIVisionClient;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^ no `OpenAIVisionClient` in `clients::openai::vision`

error[E0432]: unresolved import `super::completion::CompletionModel`
  --> packages/provider/src/clients/openrouter/client.rs:18:25
   |
18 | use super::completion::{CompletionModel, GPT_4_1};
   |                         ^^^^^^^^^^^^^^^
   |                         |
   |                         no `CompletionModel` in `clients::openrouter::completion`
   |                         help: a similar name exists in the module: `CompletionError`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::ollama::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0599]: no function or associated item named `get` found for struct `HttpRequest` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:613:36
    |
613 |         let request = HttpRequest::get(&url, Vec::new())
    |                                    ^^^ function or associated item not found in `HttpRequest`
    |
note: if you're trying to build a new `HttpRequest`, consider using `HttpRequest::new` which returns `HttpRequest`
   --> /Volumes/samsung_t9/fluent-ai/packages/http3/src/request.rs:35:5
    |
35  |     pub fn new(method: HttpMethod, url: String) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::json_util`, `crate::message`
  --> packages/provider/src/clients/openrouter/client.rs:21:5
   |
21 |     completion::{
   |     ^^^^^^^^^^ unresolved import
22 |         self, CompletionError, CompletionRequest, CompletionRequestBuilder, Prompt, PromptError,
   |         ^^^^ no `completion` in the root
23 |     },
24 |     json_util,
   |     ^^^^^^^^^ no `json_util` in the root
25 |     message::Message,
   |     ^^^^^^^ unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: a similar path exists
   |
21 |     fluent_ai_domain::completion::{
   |     ++++++++++++++++++
help: a similar path exists
   |
25 |     fluent_ai_domain::message::Message,
   |     ++++++++++++++++++

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::json_util`
  --> packages/provider/src/clients/openrouter/completion.rs:10:5
   |
10 |     completion::{self, CompletionError, CompletionRequest},
   |     ^^^^^^^^^^   ^^^^ no `completion` in the root
   |     |
   |     unresolved import
   |     help: a similar path exists: `fluent_ai_domain::completion`
11 |     json_util,
   |     ^^^^^^^^^ no `json_util` in the root
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible

error[E0432]: unresolved import `completion::CompletionModel`
  --> packages/provider/src/clients/openrouter/mod.rs:18:24
   |
18 |     CLAUDE_3_7_SONNET, CompletionModel, GEMINI_FLASH_2_0, GPT_4_1, PERPLEXITY_SONAR_PRO,
   |                        ^^^^^^^^^^^^^^^ no `CompletionModel` in `clients::openrouter::completion`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::ollama::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0432]: unresolved import `super::completion::CompletionModel`
  --> packages/provider/src/clients/perplexity/client.rs:18:25
   |
18 | use super::completion::{CompletionModel, SONAR_PRO};
   |                         ^^^^^^^^^^^^^^^
   |                         |
   |                         no `CompletionModel` in `clients::perplexity::completion`
   |                         help: a similar name exists in the module: `CompletionError`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::openrouter::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::json_util`, `crate::message`, `crate::runtime`, `crate::runtime`
  --> packages/provider/src/clients/perplexity/client.rs:21:5
   |
21 |     completion::{
   |     ^^^^^^^^^^ unresolved import
22 |         self, CompletionError, CompletionRequest, CompletionRequestBuilder, Prompt, PromptError,
   |         ^^^^ no `completion` in the root
23 |     },
24 |     json_util,
   |     ^^^^^^^^^ no `json_util` in the root
25 |     message::Message,
   |     ^^^^^^^ unresolved import
26 |     runtime::{self, AsyncTask},
   |     ^^^^^^^   ^^^^ no `runtime` in the root
   |     |
   |     unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing this module instead:
           tokio::runtime
help: a similar path exists
   |
21 |     fluent_ai_domain::completion::{
   |     ++++++++++++++++++
help: a similar path exists
   |
25 |     fluent_ai_domain::message::Message,
   |     ++++++++++++++++++
help: a similar path exists
   |
26 |     tokio::runtime::{self, AsyncTask},
   |     +++++++

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::json_util`, `crate::message`
  --> packages/provider/src/clients/perplexity/completion.rs:13:5
   |
13 |     completion::{self, CompletionError, CompletionRequest},
   |     ^^^^^^^^^^   ^^^^ no `completion` in the root
   |     |
   |     unresolved import
   |     help: a similar path exists: `fluent_ai_domain::completion`
14 |     json_util, message,
   |     ^^^^^^^^^  ^^^^^^^ no `message` in the root
   |     |
   |     no `json_util` in the root
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing one of these modules instead:
           crate::domain::message
           fluent_ai_domain::message

error[E0432]: unresolved import `completion::CompletionModel`
  --> packages/provider/src/clients/perplexity/mod.rs:17:22
   |
17 | pub use completion::{CompletionModel, SONAR, SONAR_PRO};
   |                      ^^^^^^^^^^^^^^^ no `CompletionModel` in `clients::perplexity::completion`
   |
   = help: consider importing one of these items instead:
           crate::CompletionModel
           crate::clients::openrouter::CompletionModel
           crate::clients::xai::CompletionModel
           fluent_ai_domain::CompletionModel

error[E0432]: unresolved import `super::embedding::EmbeddingModel`
  --> packages/provider/src/clients/together/client.rs:19:17
   |
19 |     embedding::{EmbeddingModel, M2_BERT_80M_8K_RETRIEVAL},
   |                 ^^^^^^^^^^^^^^ no `EmbeddingModel` in `clients::together::embedding`
   |
   = help: consider importing one of these items instead:
           crate::EmbeddingModel
           crate::clients::ollama::EmbeddingModel
           crate::domain::EmbeddingModel
           candle_transformers::models::stella_en_v5::EmbeddingModel
           fluent_ai_domain::EmbeddingModel

error[E0599]: no method named `stream` found for struct `HttpResponse` in the current scope
   --> packages/fluent-ai-candle/src/hub.rs:625:39
    |
625 |             let mut stream = response.stream();
    |                                       ^^^^^^ method not found in `HttpResponse`

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::json_util`, `crate::message`
  --> packages/provider/src/clients/together/client.rs:23:5
   |
23 |     completion::{
   |     ^^^^^^^^^^ unresolved import
24 |         self, CompletionError, CompletionRequest, CompletionRequestBuilder, Prompt, PromptError,
   |         ^^^^ no `completion` in the root
25 |     },
26 |     json_util,
   |     ^^^^^^^^^ no `json_util` in the root
27 |     message::Message,
   |     ^^^^^^^ unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: a similar path exists
   |
23 |     fluent_ai_domain::completion::{
   |     ++++++++++++++++++
help: a similar path exists
   |
27 |     fluent_ai_domain::message::Message,
   |     ++++++++++++++++++

error[E0432]: unresolved import `crate::streaming`
  --> packages/provider/src/clients/together/completion.rs:10:12
   |
10 | use crate::streaming::StreamingCompletionResponse;
   |            ^^^^^^^^^
   |            |
   |            unresolved import
   |            help: a similar path exists: `candle_core::streaming`

error[E0432]: unresolved import `crate::json_util`
  --> packages/provider/src/clients/together/completion.rs:11:30
   |
11 | use crate::{clients::openai, json_util};
   |                              ^^^^^^^^^ no `json_util` in the root

error[E0432]: unresolved imports `crate::embeddings`, `crate::embeddings`
  --> packages/provider/src/clients/together/embedding.rs:13:12
   |
13 | use crate::embeddings::{self, EmbeddingError};
   |            ^^^^^^^^^^   ^^^^ no `embeddings` in the root
   |            |
   |            unresolved import
   |            help: a similar path exists: `candle_transformers::models::stable_diffusion::embeddings`
   |
   = help: consider importing this module instead:
           candle_transformers::models::stable_diffusion::embeddings
note: module `crate::clients::openai::embeddings` exists but is inaccessible
  --> packages/provider/src/clients/openai/mod.rs:50:1
   |
50 | mod embeddings;
   | ^^^^^^^^^^^^^^^ not accessible

error[E0432]: unresolved import `crate::streaming`
 --> packages/provider/src/clients/together/streaming.rs:6:12
  |
6 | use crate::streaming::StreamingCompletionResponse;
  |            ^^^^^^^^^
  |            |
  |            unresolved import
  |            help: a similar path exists: `candle_core::streaming`

warning: variable does not need to be mutable
   --> packages/fluent-ai-candle/src/hub.rs:667:13
    |
667 |         let mut entries_by_access: Vec<(String, Arc<CacheEntry>)> = {
    |             ----^^^^^^^^^^^^^^^^^
    |             |
    |             help: remove this `mut`
    |
    = note: `#[warn(unused_mut)]` on by default

error[E0432]: unresolved imports `crate::completion`, `crate::json_util`
 --> packages/provider/src/clients/together/streaming.rs:8:5
  |
8 |     completion::{CompletionError, CompletionRequest},
  |     ^^^^^^^^^^
  |     |
  |     unresolved import
  |     help: a similar path exists: `fluent_ai_domain::completion`
9 |     json_util::merge,
  |     ^^^^^^^^^ could not find `json_util` in the crate root

error[E0432]: unresolved imports `crate::completion`, `crate::completion`, `crate::json_util`, `crate::message`, `crate::runtime`, `crate::runtime`
  --> packages/provider/src/clients/xai/client.rs:21:5
   |
21 |     completion::{
   |     ^^^^^^^^^^ unresolved import
22 |         self, CompletionError, CompletionRequest, CompletionRequestBuilder, Prompt, PromptError,
   |         ^^^^ no `completion` in the root
23 |     },
24 |     json_util,
   |     ^^^^^^^^^ no `json_util` in the root
25 |     message::Message,
   |     ^^^^^^^ unresolved import
26 |     runtime::{self, AsyncTask},
   |     ^^^^^^^   ^^^^ no `runtime` in the root
   |     |
   |     unresolved import
   |
   = help: consider importing one of these modules instead:
           crate::clients::anthropic::completion
           crate::clients::azure::completion
           crate::clients::deepseek::completion
           crate::clients::gemini::completion
           crate::clients::huggingface::completion
           crate::clients::mistral::completion
           crate::clients::openrouter::completion
           crate::clients::perplexity::completion
           crate::clients::together::completion
           crate::clients::xai::completion
           crate::domain::completion
           fluent_ai_domain::completion
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/bedrock/mod.rs:45:1
   |
45 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
   |
  ::: packages/provider/src/clients/groq/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
   |
  ::: packages/provider/src/clients/ollama/mod.rs:8:1
   |
8  | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:48:1
   |
48 | mod completion;
   | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
   = help: consider importing this module instead:
           tokio::runtime
help: a similar path exists
   |
21 |     fluent_ai_domain::completion::{
   |     ++++++++++++++++++
help: a similar path exists
   |
25 |     fluent_ai_domain::message::Message,
   |     ++++++++++++++++++
help: a similar path exists
   |
26 |     tokio::runtime::{self, AsyncTask},
   |     +++++++

error[E0432]: unresolved import `crate::streaming`
  --> packages/provider/src/clients/xai/completion.rs:16:12
   |
16 | use crate::streaming::StreamingCompletionResponse;
   |            ^^^^^^^^^
   |            |
   |            unresolved import
   |            help: a similar path exists: `candle_core::streaming`

error[E0432]: unresolved import `crate::json_util`
  --> packages/provider/src/clients/xai/completion.rs:17:77
   |
17 | use crate::{clients::openai::Message, completion_provider::CompletionError, json_util};
   |                                                                             ^^^^^^^^^ no `json_util` in the root

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/discovery.rs:15:12
   |
15 | use crate::model::{
   |            ^^^^^
   |            |
   |            unresolved import
   |            help: a similar path exists: `fluent_ai_domain::model`

error[E0432]: unresolved import `crate::streaming`
  --> packages/provider/src/clients/xai/streaming.rs:17:12
   |
17 | use crate::streaming::StreamingCompletionResponse;
   |            ^^^^^^^^^
   |            |
   |            unresolved import
   |            help: a similar path exists: `candle_core::streaming`

error[E0432]: unresolved import `crate::http`
  --> packages/provider/src/client_factory.rs:21:12
   |
21 | use crate::http::HttpRequest;
   |            ^^^^ could not find `http` in the crate root

error[E0365]: `CompletionCoreError` is private, and cannot be re-exported
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ re-export of private `CompletionCoreError`
   |
   = note: consider declaring type or module `CompletionCoreError` with `pub`

error[E0432]: unresolved import `crate::providers`
  --> packages/provider/src/client_factory.rs:22:12
   |
22 | use crate::providers::Providers;
   |            ^^^^^^^^^ could not find `providers` in the crate root

error[E0432]: unresolved import `zeroize`
  --> packages/provider/src/security/credentials.rs:19:5
   |
19 | use zeroize::{Zeroize, ZeroizeOnDrop};
   |     ^^^^^^^ use of unresolved module or unlinked crate `zeroize`
   |
   = help: if you wanted to use a crate named `zeroize`, use `cargo add zeroize` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `chacha20poly1305`
  --> packages/provider/src/security/encryption.rs:13:5
   |
13 | use chacha20poly1305::{
   |     ^^^^^^^^^^^^^^^^ use of unresolved module or unlinked crate `chacha20poly1305`
   |
   = help: if you wanted to use a crate named `chacha20poly1305`, use `cargo add chacha20poly1305` to add it to your `Cargo.toml`

error[E0432]: unresolved import `chacha20poly1305`
  --> packages/provider/src/security/encryption.rs:13:5
   |
13 | use chacha20poly1305::{
   |     ^^^^^^^^^^^^^^^^ use of unresolved module or unlinked crate `chacha20poly1305`
   |
   = help: if you wanted to use a crate named `chacha20poly1305`, use `cargo add chacha20poly1305` to add it to your `Cargo.toml`

error[E0432]: unresolved import `zeroize`
  --> packages/provider/src/security/encryption.rs:19:5
   |
19 | use zeroize::{Zeroize, ZeroizeOnDrop};
   |     ^^^^^^^ use of unresolved module or unlinked crate `zeroize`
   |
   = help: if you wanted to use a crate named `zeroize`, use `cargo add zeroize` to add it to your `Cargo.toml`

error: cannot find attribute `zeroize` in this scope
  --> packages/provider/src/security/credentials.rs:32:7
   |
32 |     #[zeroize(skip)]
   |       ^^^^^^^

error: cannot find attribute `zeroize` in this scope
  --> packages/provider/src/security/encryption.rs:30:7
   |
30 |     #[zeroize(skip)]
   |       ^^^^^^^

error: cannot find attribute `zeroize` in this scope
  --> packages/provider/src/security/encryption.rs:34:7
   |
34 |     #[zeroize(skip)]
   |       ^^^^^^^

error: cannot find attribute `zeroize` in this scope
  --> packages/provider/src/security/encryption.rs:38:7
   |
38 |     #[zeroize(skip)]
   |       ^^^^^^^

error: cannot find attribute `zeroize` in this scope
  --> packages/provider/src/security/encryption.rs:52:7
   |
52 |     #[zeroize(skip)]
   |       ^^^^^^^

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:163:39
    |
163 |             .map_err(|e| CandleError::tokenization(format!("Failed to create HF Hub API: {}", e)))?;
    |                                       ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
163 -             .map_err(|e| CandleError::tokenization(format!("Failed to create HF Hub API: {}", e)))?;
163 +             .map_err(|e| CandleError::tokenizer(format!("Failed to create HF Hub API: {}", e)))?;
    |

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:183:26
    |
183 |             CandleError::tokenization(format!("No tokenizer file found in model {}", model_id))
    |                          ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
183 -             CandleError::tokenization(format!("No tokenizer file found in model {}", model_id))
183 +             CandleError::tokenizer(format!("No tokenizer file found in model {}", model_id))
    |

error[E0433]: failed to resolve: could not find `util` in the crate root
  --> packages/provider/src/clients/anthropic/messages.rs:70:24
   |
70 |         #[serde(with = "crate::util::json_util::stringified_json")]
   |                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ could not find `util` in the crate root

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:196:39
    |
196 |             .map_err(|e| CandleError::tokenization(format!("Failed to create HF Hub API: {}", e)))?;
    |                                       ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
196 -             .map_err(|e| CandleError::tokenization(format!("Failed to create HF Hub API: {}", e)))?;
196 +             .map_err(|e| CandleError::tokenizer(format!("Failed to create HF Hub API: {}", e)))?;
    |

error[E0433]: failed to resolve: could not find `util` in the crate root
   --> packages/provider/src/clients/anthropic/messages.rs:120:20
    |
120 |     #[serde(with = "crate::util::json_util::stringified_json")]
    |                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ could not find `util` in the crate root

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:201:39
    |
201 |             .map_err(|e| CandleError::tokenization(format!("Failed to download tokenizer: {}", e)))?;
    |                                       ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
201 -             .map_err(|e| CandleError::tokenization(format!("Failed to download tokenizer: {}", e)))?;
201 +             .map_err(|e| CandleError::tokenizer(format!("Failed to download tokenizer: {}", e)))?;
    |

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:523:42
    |
523 |             _ => return Err(CandleError::tokenization(format!("Unknown tokenizer: {}", name))),
    |                                          ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
523 -             _ => return Err(CandleError::tokenization(format!("Unknown tokenizer: {}", name))),
523 +             _ => return Err(CandleError::tokenizer(format!("Unknown tokenizer: {}", name))),
    |

error[E0726]: implicit elided lifetime not allowed here
  --> packages/provider/src/clients/anthropic/requests.rs:82:19
   |
82 |         request: &AnthropicCompletionRequest,
   |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^ expected lifetime parameter
   |
help: indicate the anonymous lifetime
   |
82 |         request: &AnthropicCompletionRequest<'_>,
   |                                             ++++

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/anthropic/requests.rs:130:19
    |
130 |         request: &AnthropicCompletionRequest,
    |                   ^^^^^^^^^^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
130 |         request: &AnthropicCompletionRequest<'_>,
    |                                             ++++

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/anthropic/requests.rs:251:15
    |
251 |     request: &AnthropicCompletionRequest,
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
251 |     request: &AnthropicCompletionRequest<'_>,
    |                                         ++++

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/anthropic/requests.rs:262:15
    |
262 |     request: &AnthropicCompletionRequest,
    |               ^^^^^^^^^^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
262 |     request: &AnthropicCompletionRequest<'_>,
    |                                         ++++

error[E0106]: missing lifetime specifier
  --> packages/provider/src/clients/anthropic/responses.rs:31:26
   |
31 |     ) -> AnthropicResult<CompletionResponse> {
   |                          ^^^^^^^^^^^^^^^^^^ expected named lifetime parameter
   |
   = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from
help: consider using the `'static` lifetime, but this is uncommon unless you're returning a borrowed value from a `const` or a `static`, or if you will only have owned values
   |
31 |     ) -> AnthropicResult<CompletionResponse<'static>> {
   |                                            +++++++++

error[E0106]: missing lifetime specifier
   --> packages/provider/src/clients/anthropic/responses.rs:314:22
    |
314 | ) -> AnthropicResult<CompletionResponse> {
    |                      ^^^^^^^^^^^^^^^^^^ expected named lifetime parameter
    |
    = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from
help: consider using the `'static` lifetime, but this is uncommon unless you're returning a borrowed value from a `const` or a `static`, or if you will only have owned values
    |
314 | ) -> AnthropicResult<CompletionResponse<'static>> {
    |                                        +++++++++

error[E0277]: `var_builder::VarBuilderConfig` doesn't implement `std::fmt::Debug`
  --> packages/fluent-ai-candle/src/client.rs:51:5
   |
32 | #[derive(Debug, Clone)]
   |          ----- in this derive macro expansion
...
51 |     pub var_builder_config: VarBuilderConfig,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::fmt::Debug` is not implemented for `var_builder::VarBuilderConfig`
   |
   = note: add `#[derive(Debug)]` to `var_builder::VarBuilderConfig` or manually `impl std::fmt::Debug for var_builder::VarBuilderConfig`
help: consider annotating `var_builder::VarBuilderConfig` with `#[derive(Debug)]`
  --> packages/fluent-ai-candle/src/var_builder.rs:104:1
   |
104+ #[derive(Debug)]
105| pub struct VarBuilderConfig {
   |

error[E0277]: `kv_cache::KVCacheConfig` doesn't implement `std::fmt::Debug`
  --> packages/fluent-ai-candle/src/client.rs:53:5
   |
32 | #[derive(Debug, Clone)]
   |          ----- in this derive macro expansion
...
53 |     pub kv_cache_config: KVCacheConfig,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::fmt::Debug` is not implemented for `kv_cache::KVCacheConfig`
   |
   = note: add `#[derive(Debug)]` to `kv_cache::KVCacheConfig` or manually `impl std::fmt::Debug for kv_cache::KVCacheConfig`
help: consider annotating `kv_cache::KVCacheConfig` with `#[derive(Debug)]`
  --> packages/fluent-ai-candle/src/kv_cache/mod.rs:712:1
   |
712+ #[derive(Debug)]
713| pub struct KVCacheConfig {
   |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/streaming.rs:148:17
    |
148 |     ) -> crate::runtime::AsyncTask<
    |                 ^^^^^^^
    |                 |
    |                 unresolved import
    |                 help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/streaming.rs:156:16
    |
156 |         crate::runtime::spawn_async(async move {
    |                ^^^^^^^
    |                |
    |                unresolved import
    |                help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/streaming.rs:157:39
    |
157 |             let (tx, stream) = crate::runtime::async_stream::<
    |                                       ^^^^^^^
    |                                       |
    |                                       unresolved import
    |                                       help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/streaming.rs:162:20
    |
162 |             crate::runtime::spawn_async(async move {
    |                    ^^^^^^^
    |                    |
    |                    unresolved import
    |                    help: a similar path exists: `tokio::runtime`

error[E0106]: missing lifetime specifier
  --> packages/provider/src/clients/anthropic/tools/core.rs:36:59
   |
36 |     dyn Fn(&Conversation, &Emitter, Req, &D) -> BoxFuture<'_, AnthropicResult<()>> + Send + Sync,
   |            -------------  --------       --               ^^ expected named lifetime parameter
   |
   = help: this function's return type contains a borrowed value, but the signature does not say whether it is borrowed from argument 1, argument 2, or argument 4
   = note: for more information on higher-ranked polymorphism, visit https://doc.rust-lang.org/nomicon/hrtb.html
help: consider making the bound lifetime-generic with a new `'a` lifetime
   |
36 -     dyn Fn(&Conversation, &Emitter, Req, &D) -> BoxFuture<'_, AnthropicResult<()>> + Send + Sync,
36 +     dyn for<'a> Fn(&'a Conversation, &'a Emitter, Req, &'a D) -> BoxFuture<'a, AnthropicResult<()>> + Send + Sync,
   |
help: consider introducing a named lifetime parameter
   |
35 ~ pub type InvocationHandler<'a, D, Req, Res> = Box<
36 ~     dyn Fn(&'a Conversation, &'a Emitter, Req, &'a D) -> BoxFuture<'a, AnthropicResult<()>> + Send + Sync,
   |

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:419:24
    |
419 |         conversation: &Conversation,
    |                        ^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
419 |         conversation: &Conversation<'_>,
    |                                    ++++

error[E0106]: missing lifetime specifier
   --> packages/provider/src/clients/azure/client.rs:469:23
    |
469 |     fn build(self) -> CompletionRequest {
    |                       ^^^^^^^^^^^^^^^^^ expected named lifetime parameter
    |
    = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from
help: consider using the `'a` lifetime
    |
469 |     fn build(self) -> CompletionRequest<'a> {
    |                                        ++++

error[E0106]: missing lifetime specifier
   --> packages/provider/src/clients/azure/client.rs:490:46
    |
490 |         Result<completion::CompletionResponse<completion::CompletionResponseData>, CompletionError>,
    |                                              ^ expected named lifetime parameter
    |
    = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from
help: consider using the `'a` lifetime
    |
490 |         Result<completion::CompletionResponse<'a, completion::CompletionResponseData>, CompletionError>,
    |                                               +++

error[E0599]: no function or associated item named `new` found for struct `KVCache` in the current scope
   --> packages/fluent-ai-candle/src/generator.rs:547:34
    |
547 |             let cache = KVCache::new(cache_config)?;
    |                                  ^^^ function or associated item not found in `KVCache`
    |
   ::: packages/fluent-ai-candle/src/kv_cache/mod.rs:127:1
    |
127 | pub struct KVCache {
    | ------------------ function or associated item `new` not found for this struct
    |
note: if you're trying to build a new `KVCache`, consider using `KVCache::with_config` which returns `std::result::Result<KVCache, error::CandleError>`
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:155:5
    |
155 |     pub fn with_config(config: KVCacheConfig) -> Result<Self> {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    = help: items from traits can only be used if the trait is implemented and in scope
    = note: the following traits define an item `new`, perhaps you need to implement one of them:
            candidate #1: `AgentRole`
            candidate #2: `BackendDevice`
            candidate #3: `Bit`
            candidate #4: `ConversationTrait`
            candidate #5: `Digest`
            candidate #6: `Extractor`
            candidate #7: `KeyInit`
            candidate #8: `KeyIvInit`
            candidate #9: `Loader`
            candidate #10: `Mac`
            candidate #11: `McpTool`
            candidate #12: `Optimizer`
            candidate #13: `UniformSampler`
            candidate #14: `VariableOutput`
            candidate #15: `VariableOutputCore`
            candidate #16: `ahash::HashMapExt`
            candidate #17: `ahash::HashSetExt`
            candidate #18: `aws_lc_rs::aead::BoundKey`
            candidate #19: `brotli::enc::backward_references::hash_to_binary_tree::Allocable`
            candidate #20: `brotli::enc::threading::AnyBoxConstructor`
            candidate #21: `crypto_common::KeyInit`
            candidate #22: `crypto_common::KeyIvInit`
            candidate #23: `digest::VariableOutput`
            candidate #24: `digest::block_api::VariableOutputCore`
            candidate #25: `digest::digest::Digest`
            candidate #26: `ext_sort::chunk::ExternalChunk`
            candidate #27: `hickory_proto::runtime::Executor`
            candidate #28: `itertools::adaptors::coalesce::CountItem`
            candidate #29: `itertools::adaptors::coalesce::CountItem`
            candidate #30: `ndarray::data_traits::DataOwned`
            candidate #31: `parking_lot_core::thread_parker::ThreadParkerT`
            candidate #32: `prometheus::atomic64::Atomic`
            candidate #33: `protobuf::message::Message`
            candidate #34: `quick_cache::shard::SharedPlaceholder`
            candidate #35: `quick_cache::shard::SharedPlaceholder`
            candidate #36: `rand::distributions::uniform::UniformSampler`
            candidate #37: `ring::aead::BoundKey`
            candidate #38: `rstar::point::PointExt`
            candidate #39: `serde_with::duplicate_key_impls::error_on_duplicate::PreventDuplicateInsertsMap`
            candidate #40: `serde_with::duplicate_key_impls::error_on_duplicate::PreventDuplicateInsertsSet`
            candidate #41: `serde_with::duplicate_key_impls::first_value_wins::DuplicateInsertsFirstWinsMap`
            candidate #42: `serde_with::duplicate_key_impls::last_value_wins::DuplicateInsertsLastWinsSet`
            candidate #43: `spade::triangulation::Triangulation`
            candidate #44: `sysctl::traits::Sysctl`
            candidate #45: `sysctl::traits::Sysctl`
            candidate #46: `tendril::tendril::Atomicity`

error[E0782]: expected a type, found a trait
   --> packages/fluent-ai-candle/src/generator.rs:554:32
    |
554 |         let logits_processor = LogitsProcessor::from_sampling(&sampling_config)?;
    |                                ^^^^^^^^^^^^^^^
    |
help: you can add the `dyn` keyword if you want a trait object
    |
554 |         let logits_processor = <dyn LogitsProcessor>::from_sampling(&sampling_config)?;
    |                                ++++                +

error[E0437]: type `Response` is not a member of trait `completion::CompletionModel`
  --> packages/provider/src/clients/azure/completion.rs:86:5
   |
86 |     type Response = openai::CompletionResponse;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a member of trait `completion::CompletionModel`

error[E0437]: type `StreamingResponse` is not a member of trait `completion::CompletionModel`
  --> packages/provider/src/clients/azure/completion.rs:87:5
   |
87 |     type StreamingResponse = openai::StreamingCompletionResponse;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a member of trait `completion::CompletionModel`

error[E0407]: method `completion` is not a member of trait `completion::CompletionModel`
  --> packages/provider/src/clients/azure/completion.rs:89:5
   |
89 | /     fn completion(
90 | |         &self,
91 | |         req: CompletionRequest,
92 | |     ) -> AsyncTask<Result<completion::CompletionResponse<Self::Response>, CompletionError>> {
93 | |         let this = self.clone();
94 | |         rt::spawn_async(async move { this.perform_completion(req).await })
95 | |     }
   | |_____^ not a member of trait `completion::CompletionModel`

error[E0407]: method `stream` is not a member of trait `completion::CompletionModel`
   --> packages/provider/src/clients/azure/completion.rs:97:5
    |
97  | /     fn stream(
98  | |         &self,
99  | |         req: CompletionRequest,
100 | |     ) -> AsyncTask<Result<RigStreaming<Self::StreamingResponse>, CompletionError>> {
101 | |         let this = self.clone();
102 | |         rt::spawn_async(async move { this.perform_stream(req).await })
103 | |     }
    | |_____^ not a member of trait `completion::CompletionModel`

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/azure/completion.rs:112:29
    |
112 |         completion_request: CompletionRequest,
    |                             ^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
112 |         completion_request: CompletionRequest<'_>,
    |                                              ++++

error[E0106]: missing lifetime specifier
   --> packages/provider/src/clients/azure/completion.rs:113:47
    |
113 |     ) -> Result<completion::CompletionResponse<openai::CompletionResponse>, CompletionError> {
    |                                               ^ expected named lifetime parameter
    |
    = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from
help: consider using the `'static` lifetime, but this is uncommon unless you're returning a borrowed value from a `const` or a `static`, or if you will only have owned values
    |
113 |     ) -> Result<completion::CompletionResponse<'static, openai::CompletionResponse>, CompletionError> {
    |                                                ++++++++

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/azure/completion.rs:145:29
    |
145 |         completion_request: CompletionRequest,
    |                             ^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
145 |         completion_request: CompletionRequest<'_>,
    |                                              ++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/generator.rs:572:13
    |
572 |             token_output_stream,
    |             ^^^^^^^^^^^^^^^^^^^ expected `Option<Arc<Mutex<RawMutex, ...>>>`, found `Option<Arc<Mutex<RawMutex, (..., ...)>>>`
    |
    = note: expected enum `Option<Arc<parking_lot::lock_api::Mutex<_, TokenOutputStream>>>`
               found enum `Option<Arc<parking_lot::lock_api::Mutex<_, (TokenOutputStream, TokenStreamSender)>>>`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `dirs`
  --> packages/fluent-ai-candle/src/hub.rs:56:24
   |
56 |             cache_dir: dirs::cache_dir().unwrap_or_else(|| PathBuf::from("cache")).join("fluent_ai_hub"),
   |                        ^^^^ use of unresolved module or unlinked crate `dirs`
   |
   = help: if you wanted to use a crate named `dirs`, use `cargo add dirs` to add it to your `Cargo.toml`

error[E0277]: the trait bound `AtomicU64: Clone` is not satisfied
   --> packages/fluent-ai-candle/src/hub.rs:129:5
    |
120 | #[derive(Debug, Clone)]
    |                 ----- in this derive macro expansion
...
129 |     last_accessed: AtomicU64,
    |     ^^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicU64`

error[E0277]: the trait bound `AtomicUsize: Clone` is not satisfied
   --> packages/fluent-ai-candle/src/hub.rs:131:5
    |
120 | #[derive(Debug, Clone)]
    |                 ----- in this derive macro expansion
...
131 |     ref_count: AtomicUsize,
    |     ^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicUsize`

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:161:41
    |
161 |                 return Err(CandleError::ProcessingError("Too many attention heads"));
    |                                         ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:206:37
    |
206 |             return Err(CandleError::ProcessingError(ERR_INVALID_HEAD));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:211:37
    |
211 |             return Err(CandleError::ProcessingError(ERR_INVALID_POSITION));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0369]: binary operation `!=` cannot be applied to type `&candle_core::Device`
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:215:32
    |
215 |         if key_tensor.device() != value_tensor.device() {
    |            ------------------- ^^ --------------------- &candle_core::Device
    |            |
    |            &candle_core::Device
    |
note: the foreign item type `candle_core::Device` doesn't implement `PartialEq`
   --> /Users/davidmaple/.cargo/git/checkouts/candle-5b4d092929d18d36/1ef1341/candle-core/src/device.rs:16:1
    |
16  | pub enum Device {
    | ^^^^^^^^^^^^^^^ not implement `PartialEq`

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:217:37
    |
217 |             return Err(CandleError::ProcessingError(ERR_DEVICE_MISMATCH));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:222:37
    |
222 |             return Err(CandleError::ProcessingError(ERR_TENSOR_MISMATCH));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:247:37
    |
247 |             return Err(CandleError::ProcessingError(ERR_CACHE_FULL));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0726]: implicit elided lifetime not allowed here
  --> packages/provider/src/clients/azure/streaming.rs:51:29
   |
51 |         completion_request: CompletionRequest,
   |                             ^^^^^^^^^^^^^^^^^ expected lifetime parameter
   |
help: indicate the anonymous lifetime
   |
51 |         completion_request: CompletionRequest<'_>,
   |                                              ++++

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:298:37
    |
298 |             return Err(CandleError::ProcessingError("Batch size mismatch"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:346:37
    |
346 |             return Err(CandleError::ProcessingError(ERR_INVALID_HEAD));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:523:37
    |
523 |             return Err(CandleError::ProcessingError("Head index too large"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:527:37
    |
527 |             return Err(CandleError::ProcessingError("Sequence position too large"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0437]: type `Response` is not a member of trait `CompletionProvider`
   --> packages/provider/src/clients/bedrock/completion.rs:385:5
    |
385 |     type Response = CompletionResponse;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a member of trait `CompletionProvider`

error[E0437]: type `StreamingResponse` is not a member of trait `CompletionProvider`
   --> packages/provider/src/clients/bedrock/completion.rs:386:5
    |
386 |     type StreamingResponse = StreamingResponse;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a member of trait `CompletionProvider`

error[E0437]: type `Error` is not a member of trait `CompletionProvider`
   --> packages/provider/src/clients/bedrock/completion.rs:387:5
    |
387 |     type Error = CompletionError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a member of trait `CompletionProvider`

error[E0407]: method `completion` is not a member of trait `CompletionProvider`
   --> packages/provider/src/clients/bedrock/completion.rs:418:5
    |
418 | /     fn completion(
419 | |         &self,
420 | |         request: CompletionRequest,
421 | |     ) -> AsyncTask<Result<Self::Response, Self::Error>> {
...   |
429 | |         })
430 | |     }
    | |_____^ not a member of trait `CompletionProvider`

error[E0407]: method `stream` is not a member of trait `CompletionProvider`
   --> packages/provider/src/clients/bedrock/completion.rs:432:5
    |
432 | /     fn stream(
433 | |         &self,
434 | |         request: CompletionRequest,
435 | |     ) -> AsyncTask<Result<AsyncStream<Self::StreamingResponse>, Self::Error>> {
...   |
447 | |         })
448 | |     }
    | |_____^ not a member of trait `CompletionProvider`

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:618:37
    |
618 |             return Err(CandleError::ProcessingError("Head table full"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:626:37
    |
626 |             return Err(CandleError::ProcessingError("Failed to add entry"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:965:29
    |
965 |         let mut candidates: SmallVec<[(usize, u32); 64]> = SmallVec::new();
    |                             ^^^^^^^^ ------------------ supplied 1 generic argument
    |                             |
    |                             expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
965 |         let mut candidates: SmallVec<[(usize, u32); 64], N> = SmallVec::new();
    |                                                        +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/fluent-ai-candle/src/kv_cache/mod.rs:992:29
    |
992 |         let mut candidates: SmallVec<[(usize, u32); 64]> = SmallVec::new();
    |                             ^^^^^^^^ ------------------ supplied 1 generic argument
    |                             |
    |                             expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
992 |         let mut candidates: SmallVec<[(usize, u32); 64], N> = SmallVec::new();
    |                                                        +++

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `hf_hub`
   --> packages/provider/src/clients/candle/model_repo.rs:161:31
    |
161 |     hf_client: ArcSwap<Option<hf_hub::api::tokio::Api>>,
    |                               ^^^^^^ use of unresolved module or unlinked crate `hf_hub`
    |
    = help: if you wanted to use a crate named `hf_hub`, use `cargo add hf_hub` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `hf_hub`
   --> packages/provider/src/clients/candle/model_repo.rs:185:19
    |
185 |         let api = hf_hub::api::tokio::Api::new()
    |                   ^^^^^^ use of unresolved module or unlinked crate `hf_hub`
    |
    = help: if you wanted to use a crate named `hf_hub`, use `cargo add hf_hub` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `hf_hub`
   --> packages/provider/src/clients/candle/model_repo.rs:372:32
    |
372 |         let repo = hf_api.repo(hf_hub::Repo::with_revision(
    |                                ^^^^^^ use of unresolved module or unlinked crate `hf_hub`
    |
    = help: if you wanted to use a crate named `hf_hub`, use `cargo add hf_hub` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `hf_hub`
   --> packages/provider/src/clients/candle/model_repo.rs:374:13
    |
374 |             hf_hub::RepoType::Model,
    |             ^^^^^^ use of unresolved module or unlinked crate `hf_hub`
    |
    = help: if you wanted to use a crate named `hf_hub`, use `cargo add hf_hub` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `hf_hub`
   --> packages/provider/src/clients/candle/model_repo.rs:459:16
    |
459 |         repo: &hf_hub::api::tokio::ApiRepo,
    |                ^^^^^^ use of unresolved module or unlinked crate `hf_hub`
    |
    = help: if you wanted to use a crate named `hf_hub`, use `cargo add hf_hub` to add it to your `Cargo.toml`

error[E0106]: missing lifetime specifier
   --> packages/provider/src/clients/gemini/client.rs:607:43
    |
607 |             completion::CompletionResponse<super::completion::CompletionResponse>,
    |                                           ^ expected named lifetime parameter
    |
    = help: this function's return type contains a borrowed value, but there is no value for it to be borrowed from
help: consider using the `'a` lifetime
    |
607 |             completion::CompletionResponse<'a, super::completion::CompletionResponse>,
    |                                            +++

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/gemini/completion_old.rs:84:17
   |
84 |     ) -> crate::runtime::AsyncTask<
   |                 ^^^^^^^
   |                 |
   |                 unresolved import
   |                 help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/gemini/completion_old.rs:87:33
   |
87 |         let (tx, task) = crate::runtime::channel();
   |                                 ^^^^^^^
   |                                 |
   |                                 unresolved import
   |                                 help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/completion_old.rs:150:17
    |
150 |     ) -> crate::runtime::AsyncTask<
    |                 ^^^^^^^
    |                 |
    |                 unresolved import
    |                 help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/completion_old.rs:156:33
    |
156 |         let (tx, task) = crate::runtime::channel();
    |                                 ^^^^^^^
    |                                 |
    |                                 unresolved import
    |                                 help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: could not find `util` in the crate root
   --> packages/provider/src/clients/gemini/completion_old.rs:908:36
    |
908 |         #[serde(deserialize_with = "crate::util::string_or_one_or_many")]
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ could not find `util` in the crate root

error[E0277]: `(dyn logits::LogitsProcessor + 'static)` doesn't implement `std::fmt::Debug`
   --> packages/fluent-ai-candle/src/logits.rs:662:5
    |
659 | #[derive(Debug)]
    |          ----- in this derive macro expansion
...
662 |     processors: ArrayVec<Box<dyn LogitsProcessor>, MAX_PROCESSORS>,
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::fmt::Debug` is not implemented for `(dyn logits::LogitsProcessor + 'static)`
    |
    = help: the following other types implement trait `std::fmt::Debug`:
              &dyn protobuf::reflect::message::generated::MessageFactory
              dyn ammonia::AttributeFilter
              dyn std::any::Any + std::marker::Send + Sync
              dyn std::any::Any + std::marker::Send
              dyn std::any::Any
              dyn tracing::Value

error[E0277]: the trait bound `AtomicU32: Clone` is not satisfied
  --> packages/fluent-ai-candle/src/model.rs:24:5
   |
19 | #[derive(Clone)]
   |          ----- in this derive macro expansion
...
24 |     pub position: AtomicU32,
   |     ^^^^^^^^^^^^^^^^^^^^^^^ the trait `Clone` is not implemented for `AtomicU32`

error[E0605]: non-primitive cast: `&dyn Module + std::marker::Send + Sync` as `&(dyn std::any::Any + 'static)`
    --> packages/fluent-ai-candle/src/model.rs:1036:15
     |
1036 |         match state.model.as_ref() as &dyn std::any::Any {
     |               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ invalid cast
     |
help: consider borrowing the value
     |
1036 |         match &state.model.as_ref() as &dyn std::any::Any {
     |               +

error[E0609]: no field `cache_manager` on type `*mut CandleModel`
    --> packages/fluent-ai-candle/src/model.rs:1208:92
     |
1208 | ...   let old_cache_manager = std::mem::replace(&mut *(self as *const Self as *mut Self).cache_manager.as_ref() as *mut Arc<KVCacheManage...
     |                                                                                          ^^^^^^^^^^^^^ unknown field
     |
help: the value is a raw pointer; try dereferencing it
     |
1208 |         let old_cache_manager = std::mem::replace(&mut *(*(self as *const Self as *mut Self)).cache_manager.as_ref() as *mut Arc<KVCacheManager>, new_cache_manager);
     |                                                         ++                                  +

error[E0308]: mismatched types
  --> packages/fluent-ai-candle/src/sampling/temperature.rs:54:58
   |
54 |             return Err(SamplingError::InvalidTemperature(temperature));
   |                        --------------------------------- ^^^^^^^^^^^ expected `f64`, found `f32`
   |                        |
   |                        arguments to this enum variant are incorrect
   |
note: tuple variant defined here
  --> packages/fluent-ai-candle/src/sampling/mod.rs:42:5
   |
42 |     InvalidTemperature(f64),
   |     ^^^^^^^^^^^^^^^^^^
help: you can convert an `f32` to an `f64`
   |
54 |             return Err(SamplingError::InvalidTemperature(temperature.into()));
   |                                                                     +++++++

error[E0308]: mismatched types
  --> packages/fluent-ai-candle/src/sampling/temperature.rs:58:58
   |
58 |             return Err(SamplingError::InvalidTemperature(temperature));
   |                        --------------------------------- ^^^^^^^^^^^ expected `f64`, found `f32`
   |                        |
   |                        arguments to this enum variant are incorrect
   |
note: tuple variant defined here
  --> packages/fluent-ai-candle/src/sampling/mod.rs:42:5
   |
42 |     InvalidTemperature(f64),
   |     ^^^^^^^^^^^^^^^^^^
help: you can convert an `f32` to an `f64`
   |
58 |             return Err(SamplingError::InvalidTemperature(temperature.into()));
   |                                                                     +++++++

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/gemini/gemini_client.rs:59:17
   |
59 |     ) -> crate::runtime::AsyncTask<
   |                 ^^^^^^^
   |                 |
   |                 unresolved import
   |                 help: a similar path exists: `tokio::runtime`

error[E0308]: mismatched types
  --> packages/fluent-ai-candle/src/sampling/temperature.rs:62:58
   |
62 |             return Err(SamplingError::InvalidTemperature(temperature));
   |                        --------------------------------- ^^^^^^^^^^^ expected `f64`, found `f32`
   |                        |
   |                        arguments to this enum variant are incorrect
   |
note: tuple variant defined here
  --> packages/fluent-ai-candle/src/sampling/mod.rs:42:5
   |
42 |     InvalidTemperature(f64),
   |     ^^^^^^^^^^^^^^^^^^
help: you can convert an `f32` to an `f64`
   |
62 |             return Err(SamplingError::InvalidTemperature(temperature.into()));
   |                                                                     +++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:105:24
    |
105 |             return Err(SamplingError::NumericalInstability);
    |                    --- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected `SamplingError`, found enum constructor
    |                    |
    |                    arguments to this enum variant are incorrect
    |
   ::: packages/fluent-ai-candle/src/sampling/mod.rs:57:5
    |
57  |     NumericalInstability(String),
    |     -------------------- `NumericalInstability` defines an enum variant constructor here, which should be called
    |
    = note:          expected enum `sampling::SamplingError`
            found enum constructor `fn(std::string::String) -> sampling::SamplingError {sampling::SamplingError::NumericalInstability}`
help: the type constructed contains `fn(std::string::String) -> sampling::SamplingError {sampling::SamplingError::NumericalInstability}` due to the type of the argument passed
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:105:20
    |
105 |             return Err(SamplingError::NumericalInstability);
    |                    ^^^^-----------------------------------^
    |                        |
    |                        this argument influences the type of `Err`
note: tuple variant defined here
   --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/result.rs:557:5
    |
557 |     Err(#[stable(feature = "rust1", since = "1.0.0")] E),
    |     ^^^
help: use parentheses to construct this tuple variant
    |
105 |             return Err(SamplingError::NumericalInstability(/* std::string::String */));
    |                                                           +++++++++++++++++++++++++++

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:139:24
    |
139 |             return Err(SamplingError::NumericalInstability);
    |                    --- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected `SamplingError`, found enum constructor
    |                    |
    |                    arguments to this enum variant are incorrect
    |
   ::: packages/fluent-ai-candle/src/sampling/mod.rs:57:5
    |
57  |     NumericalInstability(String),
    |     -------------------- `NumericalInstability` defines an enum variant constructor here, which should be called
    |
    = note:          expected enum `sampling::SamplingError`
            found enum constructor `fn(std::string::String) -> sampling::SamplingError {sampling::SamplingError::NumericalInstability}`
help: the type constructed contains `fn(std::string::String) -> sampling::SamplingError {sampling::SamplingError::NumericalInstability}` due to the type of the argument passed
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:139:20
    |
139 |             return Err(SamplingError::NumericalInstability);
    |                    ^^^^-----------------------------------^
    |                        |
    |                        this argument influences the type of `Err`
note: tuple variant defined here
   --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/result.rs:557:5
    |
557 |     Err(#[stable(feature = "rust1", since = "1.0.0")] E),
    |     ^^^
help: use parentheses to construct this tuple variant
    |
139 |             return Err(SamplingError::NumericalInstability(/* std::string::String */));
    |                                                           +++++++++++++++++++++++++++

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/gemini/gemini_client.rs:62:33
   |
62 |         let (tx, task) = crate::runtime::channel();
   |                                 ^^^^^^^
   |                                 |
   |                                 unresolved import
   |                                 help: a similar path exists: `tokio::runtime`

error[E0599]: no variant or associated item named `EmptyLogits` found for enum `sampling::SamplingError` in the current scope
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:157:39
    |
157 |             return Err(SamplingError::EmptyLogits);
    |                                       ^^^^^^^^^^^ variant or associated item not found in `sampling::SamplingError`
    |
   ::: packages/fluent-ai-candle/src/sampling/mod.rs:40:1
    |
40  | pub enum SamplingError {
    | ---------------------- variant or associated item `EmptyLogits` not found for this enum

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/gemini_client.rs:126:17
    |
126 |     ) -> crate::runtime::AsyncTask<
    |                 ^^^^^^^
    |                 |
    |                 unresolved import
    |                 help: a similar path exists: `tokio::runtime`

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/gemini_client.rs:132:33
    |
132 |         let (tx, task) = crate::runtime::channel();
    |                                 ^^^^^^^
    |                                 |
    |                                 unresolved import
    |                                 help: a similar path exists: `tokio::runtime`

error[E0408]: variable `code` is not bound in all patterns
   --> packages/provider/src/clients/gemini/gemini_error.rs:162:13
    |
162 |             Self::HttpError { .. } |
    |             ^^^^^^^^^^^^^^^^^^^^^^ pattern doesn't bind `code`
163 |             Self::RateLimited { .. } |
    |             ^^^^^^^^^^^^^^^^^^^^^^^^ pattern doesn't bind `code`
164 |             Self::Timeout { .. } |
    |             ^^^^^^^^^^^^^^^^^^^^ pattern doesn't bind `code`
165 |             Self::InternalError { code, .. } if *code >= 500
    |                                   ---- variable not in all patterns

error[E0433]: failed to resolve: could not find `util` in the crate root
   --> packages/provider/src/clients/gemini/gemini_types.rs:114:32
    |
114 |     #[serde(deserialize_with = "crate::util::string_or_one_or_many")]
    |                                ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ could not find `util` in the crate root

error[E0061]: this method takes 3 arguments but 1 argument was supplied
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:296:39
    |
296 |         let scaled_logits = processor.process(logits)?;
    |                                       ^^^^^^^--------
    |                                              ||
    |                                              |types differ in mutability
    |                                              two arguments of type `&[u32]` and `usize` are missing
    |
    = note: expected mutable reference `&mut candle_core::Tensor`
                       found reference `&candle_core::Tensor`
note: method defined here
   --> packages/fluent-ai-candle/src/sampling/mod.rs:90:8
    |
90  |     fn process(
    |        ^^^^^^^
91  |         &self,
92  |         logits: &mut Tensor,
    |         ------
93  |         token_ids: &[u32],
    |         ---------
94  |         position: usize,
    |         --------
help: provide the arguments
    |
296 -         let scaled_logits = processor.process(logits)?;
296 +         let scaled_logits = processor.process(/* &mut candle_core::Tensor */, /* &[u32] */, /* usize */)?;
    |

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:299:34
    |
299 |         let probs = ops::softmax(&scaled_logits, D::Minus1)
    |                     ------------ ^^^^^^^^^^^^^^ expected `&Tensor`, found `&()`
    |                     |
    |                     arguments to this function are incorrect
    |
    = note: expected reference `&candle_core::Tensor`
               found reference `&()`
note: function defined here
   --> /Users/davidmaple/.cargo/git/checkouts/candle-5b4d092929d18d36/1ef1341/candle-nn/src/ops.rs:22:8
    |
22  | pub fn softmax<D: candle::shape::Dim>(xs: &Tensor, dim: D) -> Result<Tensor> {
    |        ^^^^^^^

error[E0308]: mismatched types
  --> packages/fluent-ai-candle/src/sampling/nucleus.rs:51:51
   |
51 |             return Err(SamplingError::InvalidTopP(top_p));
   |                        -------------------------- ^^^^^ expected `f64`, found `f32`
   |                        |
   |                        arguments to this enum variant are incorrect
   |
note: tuple variant defined here
  --> packages/fluent-ai-candle/src/sampling/mod.rs:45:5
   |
45 |     InvalidTopP(f64),
   |     ^^^^^^^^^^^
help: you can convert an `f32` to an `f64`
   |
51 |             return Err(SamplingError::InvalidTopP(top_p.into()));
   |                                                        +++++++

error[E0308]: mismatched types
  --> packages/fluent-ai-candle/src/sampling/nucleus.rs:55:51
   |
55 |             return Err(SamplingError::InvalidTopP(top_p));
   |                        -------------------------- ^^^^^ expected `f64`, found `f32`
   |                        |
   |                        arguments to this enum variant are incorrect
   |
note: tuple variant defined here
  --> packages/fluent-ai-candle/src/sampling/mod.rs:45:5
   |
45 |     InvalidTopP(f64),
   |     ^^^^^^^^^^^
help: you can convert an `f32` to an `f64`
   |
55 |             return Err(SamplingError::InvalidTopP(top_p.into()));
   |                                                        +++++++

error[E0407]: method `execute_completion` is not a member of trait `CompletionProvider`
   --> packages/provider/src/clients/groq/completion.rs:641:5
    |
641 | /     async fn execute_completion(
642 | |         mut builder: Self,
643 | |         prompt_text: String,
644 | |         api_key: String,
...   |
856 | |         Ok(())
857 | |     }
    | |_____^ not a member of trait `CompletionProvider`

error[E0599]: no variant or associated item named `EmptyLogits` found for enum `sampling::SamplingError` in the current scope
  --> packages/fluent-ai-candle/src/sampling/nucleus.rs:91:39
   |
91 |             return Err(SamplingError::EmptyLogits);
   |                                       ^^^^^^^^^^^ variant or associated item not found in `sampling::SamplingError`
   |
  ::: packages/fluent-ai-candle/src/sampling/mod.rs:40:1
   |
40 | pub enum SamplingError {
   | ---------------------- variant or associated item `EmptyLogits` not found for this enum

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/nucleus.rs:140:24
    |
140 |             return Err(SamplingError::NumericalInstability);
    |                    --- ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected `SamplingError`, found enum constructor
    |                    |
    |                    arguments to this enum variant are incorrect
    |
   ::: packages/fluent-ai-candle/src/sampling/mod.rs:57:5
    |
57  |     NumericalInstability(String),
    |     -------------------- `NumericalInstability` defines an enum variant constructor here, which should be called
    |
    = note:          expected enum `sampling::SamplingError`
            found enum constructor `fn(std::string::String) -> sampling::SamplingError {sampling::SamplingError::NumericalInstability}`
help: the type constructed contains `fn(std::string::String) -> sampling::SamplingError {sampling::SamplingError::NumericalInstability}` due to the type of the argument passed
   --> packages/fluent-ai-candle/src/sampling/nucleus.rs:140:20
    |
140 |             return Err(SamplingError::NumericalInstability);
    |                    ^^^^-----------------------------------^
    |                        |
    |                        this argument influences the type of `Err`
note: tuple variant defined here
   --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/result.rs:557:5
    |
557 |     Err(#[stable(feature = "rust1", since = "1.0.0")] E),
    |     ^^^
help: use parentheses to construct this tuple variant
    |
140 |             return Err(SamplingError::NumericalInstability(/* std::string::String */));
    |                                                           +++++++++++++++++++++++++++

error[E0599]: no variant or associated item named `EmptyLogits` found for enum `sampling::SamplingError` in the current scope
   --> packages/fluent-ai-candle/src/sampling/nucleus.rs:158:39
    |
158 |             return Err(SamplingError::EmptyLogits);
    |                                       ^^^^^^^^^^^ variant or associated item not found in `sampling::SamplingError`
    |
   ::: packages/fluent-ai-candle/src/sampling/mod.rs:40:1
    |
40  | pub enum SamplingError {
    | ---------------------- variant or associated item `EmptyLogits` not found for this enum

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/nucleus.rs:340:51
    |
340 |             return Err(SamplingError::InvalidTopP(target_diversity));
    |                        -------------------------- ^^^^^^^^^^^^^^^^ expected `f64`, found `f32`
    |                        |
    |                        arguments to this enum variant are incorrect
    |
note: tuple variant defined here
   --> packages/fluent-ai-candle/src/sampling/mod.rs:45:5
    |
45  |     InvalidTopP(f64),
    |     ^^^^^^^^^^^
help: you can convert an `f32` to an `f64`
    |
340 |             return Err(SamplingError::InvalidTopP(target_diversity.into()));
    |                                                                   +++++++

error[E0726]: implicit elided lifetime not allowed here
  --> packages/provider/src/clients/huggingface/streaming.rs:68:29
   |
68 |         completion_request: CompletionRequest,
   |                             ^^^^^^^^^^^^^^^^^ expected lifetime parameter
   |
help: indicate the anonymous lifetime
   |
68 |         completion_request: CompletionRequest<'_>,
   |                                              ++++

error[E0277]: `(dyn sampling::LogitsProcessor + 'static)` doesn't implement `std::fmt::Debug`
  --> packages/fluent-ai-candle/src/sampling/composite.rs:18:5
   |
15 | #[derive(Debug)]
   |          ----- in this derive macro expansion
...
18 |     processors: Vec<Box<dyn LogitsProcessor>>,
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::fmt::Debug` is not implemented for `(dyn sampling::LogitsProcessor + 'static)`
   |
   = help: the following other types implement trait `std::fmt::Debug`:
             &dyn protobuf::reflect::message::generated::MessageFactory
             dyn ammonia::AttributeFilter
             dyn std::any::Any + std::marker::Send + Sync
             dyn std::any::Any + std::marker::Send
             dyn std::any::Any
             dyn tracing::Value

error[E0277]: `(dyn sampling::LogitsProcessor + 'static)` doesn't implement `std::fmt::Debug`
   --> packages/fluent-ai-candle/src/sampling/composite.rs:198:5
    |
196 | #[derive(Debug, Default)]
    |          ----- in this derive macro expansion
197 | pub struct CompositeProcessorBuilder {
198 |     processors: Vec<Box<dyn LogitsProcessor>>,
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::fmt::Debug` is not implemented for `(dyn sampling::LogitsProcessor + 'static)`
    |
    = help: the following other types implement trait `std::fmt::Debug`:
              &dyn protobuf::reflect::message::generated::MessageFactory
              dyn ammonia::AttributeFilter
              dyn std::any::Any + std::marker::Send + Sync
              dyn std::any::Any + std::marker::Send
              dyn std::any::Any
              dyn tracing::Value

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/composite.rs:237:44
    |
237 |         let processor = TopPProcessor::new(p)?;
    |                         ------------------ ^ expected `f32`, found `f64`
    |                         |
    |                         arguments to this function are incorrect
    |
note: associated function defined here
   --> packages/fluent-ai-candle/src/sampling/nucleus.rs:48:12
    |
48  |     pub fn new(top_p: f32) -> Result<Self, SamplingError> {
    |            ^^^ ----------

error[E0277]: `(dyn sampling::LogitsProcessor + 'static)` doesn't implement `std::fmt::Debug`
   --> packages/fluent-ai-candle/src/sampling/composite.rs:278:5
    |
276 | #[derive(Debug)]
    |          ----- in this derive macro expansion
277 | pub struct ParallelCompositeProcessor {
278 |     processors: Vec<Box<dyn LogitsProcessor>>,
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ the trait `std::fmt::Debug` is not implemented for `(dyn sampling::LogitsProcessor + 'static)`
    |
    = help: the following other types implement trait `std::fmt::Debug`:
              &dyn protobuf::reflect::message::generated::MessageFactory
              dyn ammonia::AttributeFilter
              dyn std::any::Any + std::marker::Send + Sync
              dyn std::any::Any + std::marker::Send
              dyn std::any::Any
              dyn tracing::Value

warning: use of deprecated method `rand::Rng::gen_range`: Renamed to `random_range`
   --> packages/fluent-ai-candle/src/sampling/gumbel.rs:104:37
    |
104 |             let u1: f32 = rng_guard.gen_range(1e-7..1.0 - 1e-7);
    |                                     ^^^^^^^^^
    |
    = note: `#[warn(deprecated)]` on by default

warning: use of deprecated method `rand::Rng::gen_range`: Renamed to `random_range`
   --> packages/fluent-ai-candle/src/sampling/gumbel.rs:105:37
    |
105 |             let u2: f32 = rng_guard.gen_range(1e-7..1.0 - 1e-7);
    |                                     ^^^^^^^^^

error[E0277]: the trait bound `Shape: From<&Vec<usize>>` is not satisfied
   --> packages/fluent-ai-candle/src/sampling/gumbel.rs:175:41
    |
175 |         let mut one_hot = Tensor::zeros(&output_shape, DType::F32, &self.device)
    |                           ------------- ^^^^^^^^^^^^^ the trait `From<&Vec<usize>>` is not implemented for `Shape`
    |                           |
    |                           required by a bound introduced by this call
    |
    = note: required for `&Vec<usize>` to implement `Into<Shape>`
note: required by a bound in `candle_core::Tensor::zeros`
   --> /Users/davidmaple/.cargo/git/checkouts/candle-5b4d092929d18d36/1ef1341/candle-core/src/tensor.rs:255:21
    |
255 |     pub fn zeros<S: Into<Shape>>(shape: S, dtype: DType, device: &Device) -> Result<Self> {
    |                     ^^^^^^^^^^^ required by this bound in `Tensor::zeros`
help: consider dereferencing here
    |
175 |         let mut one_hot = Tensor::zeros(&*output_shape, DType::F32, &self.device)
    |                                          +

error[E0277]: the trait bound `Shape: From<&Vec<usize>>` is not satisfied
   --> packages/fluent-ai-candle/src/sampling/gumbel.rs:193:39
    |
193 |         Tensor::from_vec(one_hot_vec, &output_shape, &self.device)
    |         ----------------              ^^^^^^^^^^^^^ the trait `From<&Vec<usize>>` is not implemented for `Shape`
    |         |
    |         required by a bound introduced by this call
    |
    = note: required for `&Vec<usize>` to implement `Into<Shape>`
    = note: required for `&Vec<usize>` to implement `ShapeWithOneHole`
note: required by a bound in `candle_core::Tensor::from_vec`
   --> /Users/davidmaple/.cargo/git/checkouts/candle-5b4d092929d18d36/1ef1341/candle-core/src/tensor.rs:498:24
    |
498 |     pub fn from_vec<S: ShapeWithOneHole, D: crate::WithDType>(
    |                        ^^^^^^^^^^^^^^^^ required by this bound in `Tensor::from_vec`
help: consider dereferencing here
    |
193 |         Tensor::from_vec(one_hot_vec, &*output_shape, &self.device)
    |                                        +

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/mod.rs:313:51
    |
313 |         let processor = TemperatureProcessor::new(temperature)?;
    |                         ------------------------- ^^^^^^^^^^^ expected `f32`, found `f64`
    |                         |
    |                         arguments to this function are incorrect
    |
note: associated function defined here
   --> packages/fluent-ai-candle/src/sampling/temperature.rs:51:12
    |
51  |     pub fn new(temperature: f32) -> Result<Self, SamplingError> {
    |            ^^^ ----------------

error[E0308]: mismatched types
   --> packages/fluent-ai-candle/src/sampling/mod.rs:320:44
    |
320 |         let processor = TopPProcessor::new(top_p)?;
    |                         ------------------ ^^^^^ expected `f32`, found `f64`
    |                         |
    |                         arguments to this function are incorrect
    |
note: associated function defined here
   --> packages/fluent-ai-candle/src/sampling/nucleus.rs:48:12
    |
48  |     pub fn new(top_p: f32) -> Result<Self, SamplingError> {
    |            ^^^ ----------

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/ollama/streaming.rs:39:13
   |
39 | ) -> crate::runtime::AsyncTask<
   |             ^^^^^^^
   |             |
   |             unresolved import
   |             help: a similar path exists: `tokio::runtime`

warning: use of deprecated method `rand::Rng::gen_range`: Renamed to `random_range`
   --> packages/fluent-ai-candle/src/sampling/mod.rs:427:35
    |
427 |         let random_val: f32 = rng.gen_range(0.0..sum);
    |                                   ^^^^^^^^^

error[E0271]: expected `{async block@packages/fluent-ai-candle/src/streaming/mod.rs:790:64: 790:74}` to be a future that resolves to `Option<(_, Option<TokenOutputStream>)>`, but it resolves to `(Option<Result<String, String>>, Option<TokenOutputStream>)`
   --> packages/fluent-ai-candle/src/streaming/mod.rs:790:22
    |
790 |           let stream = unfold(Some(self), |mut token_stream_opt| async move {
    |  ______________________^
791 | |             match token_stream_opt.take() {
792 | |                 Some(mut token_stream) => {
793 | |                     match token_stream.next().await {
...   |
823 | |         });
    | |__________^ expected `Option<(_, Option<TokenOutputStream>)>`, found `(Option<Result<String, String>>, ...)`
    |
    = note: expected enum `Option<(_, Option<TokenOutputStream>)>`
              found tuple `(Option<std::result::Result<std::string::String, std::string::String>>, Option<TokenOutputStream>)`
note: required by a bound in `futures::stream::unfold`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/futures-util-0.3.31/src/stream/unfold.rs:53:17
    |
50  | pub fn unfold<T, F, Fut, Item>(init: T, f: F) -> Unfold<T, F, Fut>
    |        ------ required by a bound in this function
...
53  |     Fut: Future<Output = Option<(Item, T)>>,
    |                 ^^^^^^^^^^^^^^^^^^^^^^^^^^ required by this bound in `unfold`

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/ollama/streaming.rs:164:67
    |
164 | fn extract_usage_info(chunk: &serde_json::Value) -> Option<crate::streaming::UsageInfo> {
    |                                                                   ^^^^^^^^^
    |                                                                   |
    |                                                                   unresolved import
    |                                                                   help: a similar path exists: `candle_core::streaming`

error[E0271]: expected `{async block@packages/fluent-ai-candle/src/streaming/mod.rs:790:64: 790:74}` to be a future that resolves to `Option<(_, Option<TokenOutputStream>)>`, but it resolves to `(Option<Result<String, String>>, Option<TokenOutputStream>)`
   --> packages/fluent-ai-candle/src/streaming/mod.rs:825:32
    |
825 |         StreamingResponse::new(Box::pin(stream))
    |                                ^^^^^^^^^^^^^^^^ expected `Option<(_, Option<TokenOutputStream>)>`, found `(Option<Result<String, String>>, ...)`
    |
    = note: expected enum `Option<(_, Option<TokenOutputStream>)>`
              found tuple `(Option<std::result::Result<std::string::String, std::string::String>>, Option<TokenOutputStream>)`
    = note: required for `Unfold<Option<TokenOutputStream>, {closure@...}, ...>` to implement `Stream`
    = note: required for the cast from `Pin<Box<Unfold<Option<TokenOutputStream>, {closure@...}, ...>>>` to `Pin<Box<dyn AsyncStream<Item = Result<..., ...>> + Send>>`
    = note: the full name for the type has been written to '/Volumes/samsung_t9/fluent-ai/target/debug/deps/fluent_ai_candle-05fbdb20fa736fb1.long-type-14798518245596483679.txt'
    = note: consider using `--verbose` to print the full type name to the console

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/ollama/streaming.rs:197:21
    |
197 |         Some(crate::streaming::UsageInfo {
    |                     ^^^^^^^^^
    |                     |
    |                     unresolved import
    |                     help: a similar path exists: `candle_core::streaming`

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:154:39
    |
154 |             .map_err(|e| CandleError::tokenization(format!("Failed to load tokenizer from file: {}", e)))?;
    |                                       ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
154 -             .map_err(|e| CandleError::tokenization(format!("Failed to load tokenizer from file: {}", e)))?;
154 +             .map_err(|e| CandleError::tokenizer(format!("Failed to load tokenizer from file: {}", e)))?;
    |

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:210:39
    |
210 |             .map_err(|e| CandleError::tokenization(format!("Encoding failed: {}", e)))?;
    |                                       ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
210 -             .map_err(|e| CandleError::tokenization(format!("Encoding failed: {}", e)))?;
210 +             .map_err(|e| CandleError::tokenizer(format!("Encoding failed: {}", e)))?;
    |

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:245:43
    |
245 |                 .map_err(|_| CandleError::tokenization("Token buffer overflow"))?;
    |                                           ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
245 -                 .map_err(|_| CandleError::tokenization("Token buffer overflow"))?;
245 +                 .map_err(|_| CandleError::tokenizer("Token buffer overflow"))?;
    |

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:255:39
    |
255 |             .map_err(|e| CandleError::tokenization(format!("Decoding failed: {}", e)))
    |                                       ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
255 -             .map_err(|e| CandleError::tokenization(format!("Decoding failed: {}", e)))
255 +             .map_err(|e| CandleError::tokenizer(format!("Decoding failed: {}", e)))
    |

error[E0599]: no variant or associated item named `tokenization` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/tokenizer.rs:555:37
    |
555 |             return Err(CandleError::tokenization("Tokenizer has zero vocabulary size"));
    |                                     ^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `tokenization` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: there is an associated function `tokenizer` with a similar name
    |
555 -             return Err(CandleError::tokenization("Tokenizer has zero vocabulary size"));
555 +             return Err(CandleError::tokenizer("Tokenizer has zero vocabulary size"));
    |

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:320:37
    |
320 |             return Err(CandleError::ProcessingError("Architecture name too long"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:328:30
    |
328 |             Err(CandleError::ProcessingError("Failed to set architecture"))
    |                              ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:353:37
    |
353 |             return Err(CandleError::ProcessingError("Configuration entries full"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:360:37
    |
360 |             return Err(CandleError::ProcessingError("Configuration entry too long"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0726]: implicit elided lifetime not allowed here
    --> packages/provider/src/clients/openrouter/streaming.rs:1774:29
     |
1774 |         completion_request: CompletionRequest,
     |                             ^^^^^^^^^^^^^^^^^ expected lifetime parameter
     |
help: indicate the anonymous lifetime
     |
1774 |         completion_request: CompletionRequest<'_>,
     |                                              ++++

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:378:37
    |
378 |             return Err(CandleError::ProcessingError("Tensor entries full"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:471:37
    |
471 |             return Err(CandleError::ProcessingError("Tensor name too long"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:475:37
    |
475 |             return Err(CandleError::ProcessingError("Too many tensor dimensions"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:480:37
    |
480 |             return Err(CandleError::ProcessingError("Failed to create tensor name"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:486:41
    |
486 |                 return Err(CandleError::ProcessingError("Failed to add shape dimension"));
    |                                         ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:756:30
    |
756 |                 CandleError::ProcessingError("Invalid file path")
    |                              ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/together/completion.rs:244:18
    |
244 |         request: CompletionRequest,
    |                  ^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
244 |         request: CompletionRequest<'_>,
    |                                   ++++

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/xai/completion.rs:113:29
    |
113 |         completion_request: fluent_ai_domain::completion::CompletionRequest,
    |                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
113 |         completion_request: fluent_ai_domain::completion::CompletionRequest<'_>,
    |                                                                            ++++

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:764:37
    |
764 |             return Err(CandleError::ProcessingError("No paths provided"));
    |                                     ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0726]: implicit elided lifetime not allowed here
   --> packages/provider/src/clients/xai/completion.rs:137:18
    |
137 |         request: CompletionRequest,
    |                  ^^^^^^^^^^^^^^^^^ expected lifetime parameter
    |
help: indicate the anonymous lifetime
    |
137 |         request: CompletionRequest<'_>,
    |                                   ++++

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:769:39
    |
769 |             .map_err(|e| CandleError::ProcessingError(ERR_MODEL_LOADING))?;
    |                                       ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:840:41
    |
840 |                 return Err(CandleError::ProcessingError(ERR_TENSOR_NOT_FOUND));
    |                                         ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:856:30
    |
856 |                 CandleError::ProcessingError(ERR_TENSOR_NOT_FOUND)
    |                              ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0726]: implicit elided lifetime not allowed here
  --> packages/provider/src/clients/xai/streaming.rs:22:29
   |
22 |         completion_request: CompletionRequest,
   |                             ^^^^^^^^^^^^^^^^^ expected lifetime parameter
   |
help: indicate the anonymous lifetime
   |
22 |         completion_request: CompletionRequest<'_>,
   |                                              ++++

error[E0433]: failed to resolve: could not find `http` in the crate root
  --> packages/provider/src/client_factory.rs:46:24
   |
46 |         source: crate::http::HttpError,
   |                        ^^^^ could not find `http` in the crate root

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
   --> packages/fluent-ai-candle/src/var_builder.rs:890:30
    |
890 |                 CandleError::ProcessingError(ERR_TENSOR_NOT_FOUND)
    |                              ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
    |
   ::: packages/fluent-ai-candle/src/error.rs:13:1
    |
13  | pub enum CandleError {
    | -------------------- variant or associated item `ProcessingError` not found for this enum
    |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
   --> packages/fluent-ai-candle/src/error.rs:189:5
    |
189 |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195 |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201 |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207 |     pub fn invalid_model_format(msg: &'static str) -> Self {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0599]: no variant or associated item named `ProcessingError` found for enum `error::CandleError` in the current scope
    --> packages/fluent-ai-candle/src/var_builder.rs:1168:44
     |
1168 |             Some(arch) => Err(CandleError::ProcessingError("Architecture mismatch")),
     |                                            ^^^^^^^^^^^^^^^ variant or associated item not found in `error::CandleError`
     |
    ::: packages/fluent-ai-candle/src/error.rs:13:1
     |
13   | pub enum CandleError {
     | -------------------- variant or associated item `ProcessingError` not found for this enum
     |
note: if you're trying to build a new `error::CandleError` consider using one of the following associated functions:
      error::CandleError::model_not_found
      error::CandleError::model_load_error
      error::CandleError::model_loading
      error::CandleError::invalid_model_format
      and 15 others
    --> packages/fluent-ai-candle/src/error.rs:189:5
     |
189  |     pub fn model_not_found<S: Into<String>>(path: S) -> Self {
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
195  |     pub fn model_load_error<S: Into<String>>(msg: S) -> Self {
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
201  |     pub fn model_loading<S: Into<String>>(msg: S) -> Self {
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
...
207  |     pub fn invalid_model_format(msg: &'static str) -> Self {
     |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `tempfile`
   --> packages/provider/src/security/audit.rs:283:25
    |
283 |         let temp_file = tempfile::NamedTempFile::new().map_err(|e| SecurityError::AuditError {
    |                         ^^^^^^^^ use of unresolved module or unlinked crate `tempfile`
    |
    = help: if you wanted to use a crate named `tempfile`, use `cargo add tempfile` to add it to your `Cargo.toml`

warning: unused import: `AsyncReadExt`
  --> packages/fluent-ai-candle/src/hub.rs:23:17
   |
23 | use tokio::io::{AsyncReadExt, AsyncWriteExt};
   |                 ^^^^^^^^^^^^

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `uuid`
   --> packages/provider/src/security/audit.rs:338:17
    |
338 |             id: uuid::Uuid::new_v4().to_string(),
    |                 ^^^^ use of unresolved module or unlinked crate `uuid`
    |
    = help: if you wanted to use a crate named `uuid`, use `cargo add uuid` to add it to your `Cargo.toml`

warning: unused import: `Write`
  --> packages/fluent-ai-candle/src/hub.rs:13:43
   |
13 | use std::io::{self, Read, Seek, SeekFrom, Write};
   |                                           ^^^^^

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `uuid`
   --> packages/provider/src/security/audit.rs:585:21
    |
585 |                 id: uuid::Uuid::new_v4().to_string(),
    |                     ^^^^ use of unresolved module or unlinked crate `uuid`
    |
    = help: if you wanted to use a crate named `uuid`, use `cargo add uuid` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/client.rs:88:38
   |
88 |     ) -> AsyncTask<Result<Vec<crate::embeddings::Embedding>, crate::embeddings::EmbeddingError>>;
   |                                      ^^^^^^^^^^
   |                                      |
   |                                      unresolved import
   |                                      help: a similar path exists: `candle_transformers::models::stable_diffusion::embeddings`

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/client.rs:88:69
   |
88 |     ) -> AsyncTask<Result<Vec<crate::embeddings::Embedding>, crate::embeddings::EmbeddingError>>;
   |                                                                     ^^^^^^^^^^
   |                                                                     |
   |                                                                     unresolved import
   |                                                                     help: a similar path exists: `candle_transformers::models::stable_diffusion::embeddings`

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/anthropic/completion.rs:46:12
   |
46 |     crate::model_info::get_model_config(model_name)
   |            ^^^^^^^^^^ unresolved import
   |
note: module `crate::clients::openai::model_info` exists but is inaccessible
  --> packages/provider/src/clients/openai/mod.rs:53:1
   |
53 | mod model_info;
   | ^^^^^^^^^^^^^^^ not accessible
help: a struct with a similar name exists
   |
46 -     crate::model_info::get_model_config(model_name)
46 +     crate::ModelInfo::get_model_config(model_name)
   |
help: a similar path exists
   |
46 |     crate::clients::gemini::model_info::get_model_config(model_name)
   |            +++++++++++++++++
help: consider importing one of these modules
   |
15 + use crate::clients::gemini::model_info;
   |
15 + use crate::clients::mistral::model_info;
   |
help: if you import `model_info`, refer to it directly
   |
46 -     crate::model_info::get_model_config(model_name)
46 +     model_info::get_model_config(model_name)
   |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/messages.rs:360:41
    |
360 |     pub fn from_definition(def: &crate::completion::ToolDefinition) -> Self {
    |                                         ^^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: a similar path exists
    |
360 |     pub fn from_definition(def: &crate::fluent_ai_domain::completion::ToolDefinition) -> Self {
    |                                         ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::clients::anthropic::completion;
    |
6   + use crate::clients::deepseek::completion;
    |
6   + use crate::clients::huggingface::completion;
    |
6   + use crate::clients::mistral::completion;
    |
      and 3 other candidates
help: if you import `completion`, refer to it directly
    |
360 -     pub fn from_definition(def: &crate::completion::ToolDefinition) -> Self {
360 +     pub fn from_definition(def: &completion::ToolDefinition) -> Self {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/messages.rs:370:19
    |
370 | impl From<&crate::message::Message> for Message {
    |                   ^^^^^^^ unresolved import
    |
help: a similar path exists
    |
370 | impl From<&crate::fluent_ai_domain::message::Message> for Message {
    |                   ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::domain::message;
    |
6   + use fluent_ai_domain::message;
    |
help: if you import `message`, refer to it directly
    |
370 - impl From<&crate::message::Message> for Message {
370 + impl From<&message::Message> for Message {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/messages.rs:389:48
    |
389 |         messages: &crate::ZeroOneOrMany<crate::message::Message>,
    |                                                ^^^^^^^ unresolved import
    |
help: a similar path exists
    |
389 |         messages: &crate::ZeroOneOrMany<crate::fluent_ai_domain::message::Message>,
    |                                                ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::domain::message;
    |
6   + use fluent_ai_domain::message;
    |
help: if you import `message`, refer to it directly
    |
389 -         messages: &crate::ZeroOneOrMany<crate::message::Message>,
389 +         messages: &crate::ZeroOneOrMany<message::Message>,
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/messages.rs:401:45
    |
401 |         tools: &crate::ZeroOneOrMany<crate::completion::ToolDefinition>,
    |                                             ^^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: a similar path exists
    |
401 |         tools: &crate::ZeroOneOrMany<crate::fluent_ai_domain::completion::ToolDefinition>,
    |                                             ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::clients::anthropic::completion;
    |
6   + use crate::clients::deepseek::completion;
    |
6   + use crate::clients::huggingface::completion;
    |
6   + use crate::clients::mistral::completion;
    |
      and 3 other candidates
help: if you import `completion`, refer to it directly
    |
401 -         tools: &crate::ZeroOneOrMany<crate::completion::ToolDefinition>,
401 +         tools: &crate::ZeroOneOrMany<completion::ToolDefinition>,
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/anthropic/messages.rs:422:49
    |
422 |         documents: &crate::ZeroOneOrMany<crate::completion::Document>,
    |                                                 ^^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: a similar path exists
    |
422 |         documents: &crate::ZeroOneOrMany<crate::fluent_ai_domain::completion::Document>,
    |                                                 ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::clients::anthropic::completion;
    |
6   + use crate::clients::deepseek::completion;
    |
6   + use crate::clients::huggingface::completion;
    |
6   + use crate::clients::mistral::completion;
    |
help: if you import `completion`, refer to it directly
    |
422 -         documents: &crate::ZeroOneOrMany<crate::completion::Document>,
422 +         documents: &crate::ZeroOneOrMany<completion::Document>,
    |

error[E0422]: cannot find struct, variant or union type `AnthropicMessage` in module `crate::clients::anthropic::messages`
   --> packages/provider/src/clients/anthropic/requests.rs:189:65
    |
189 |             messages: vec![crate::clients::anthropic::messages::AnthropicMessage {
    |                                                                 ^^^^^^^^^^^^^^^^ not found in `crate::clients::anthropic::messages`
    |
help: consider importing this struct through its public re-export
    |
6   + use crate::clients::anthropic::AnthropicMessage;
    |
help: if you import `AnthropicMessage`, refer to it directly
    |
189 -             messages: vec![crate::clients::anthropic::messages::AnthropicMessage {
189 +             messages: vec![AnthropicMessage {
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:130:20
    |
130 |             crate::providers::anthropic::AnthropicError::RequestError(format!(
    |                    ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this enum through its public re-export
    |
8   + use crate::clients::AnthropicError;
    |
help: if you import `AnthropicError`, refer to it directly
    |
130 -             crate::providers::anthropic::AnthropicError::RequestError(format!(
130 +             AnthropicError::RequestError(format!(
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:150:61
    |
150 |             AsyncStream<Result<AnthropicStreamChunk, crate::providers::anthropic::AnthropicError>>,
    |                                                             ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
8   + use crate::clients::anthropic;
    |
help: if you import `anthropic`, refer to it directly
    |
150 -             AsyncStream<Result<AnthropicStreamChunk, crate::providers::anthropic::AnthropicError>>,
150 +             AsyncStream<Result<AnthropicStreamChunk, anthropic::AnthropicError>>,
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:151:20
    |
151 |             crate::providers::anthropic::AnthropicError,
    |                    ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
8   + use crate::clients::anthropic;
    |
help: if you import `anthropic`, refer to it directly
    |
151 -             crate::providers::anthropic::AnthropicError,
151 +             anthropic::AnthropicError,
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:158:53
    |
158 |                 Result<AnthropicStreamChunk, crate::providers::anthropic::AnthropicError>,
    |                                                     ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
8   + use crate::clients::anthropic;
    |
help: if you import `anthropic`, refer to it directly
    |
158 -                 Result<AnthropicStreamChunk, crate::providers::anthropic::AnthropicError>,
158 +                 Result<AnthropicStreamChunk, anthropic::AnthropicError>,
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:168:36
    |
168 | ...                   crate::providers::anthropic::AnthropicError::RequestError(
    |                              ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this enum through its public re-export
    |
8   + use crate::clients::AnthropicError;
    |
help: if you import `AnthropicError`, refer to it directly
    |
168 -                             crate::providers::anthropic::AnthropicError::RequestError(
168 +                             AnthropicError::RequestError(
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:172:48
    |
172 |                         return Ok::<(), crate::providers::anthropic::AnthropicError>(());
    |                                                ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
8   + use crate::clients::anthropic;
    |
help: if you import `anthropic`, refer to it directly
    |
172 -                         return Ok::<(), crate::providers::anthropic::AnthropicError>(());
172 +                         return Ok::<(), anthropic::AnthropicError>(());
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:195:68
    |
195 | ...                   let _ = tx.try_send(Err(crate::providers::anthropic::AnthropicError::DeserializationError(
    |                                                      ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this enum through its public re-export
    |
8   + use crate::clients::AnthropicError;
    |
help: if you import `AnthropicError`, refer to it directly
    |
195 -                                     let _ = tx.try_send(Err(crate::providers::anthropic::AnthropicError::DeserializationError(
195 +                                     let _ = tx.try_send(Err(AnthropicError::DeserializationError(
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:225:40
    |
225 | ...                   crate::providers::anthropic::AnthropicError::RequestError(
    |                              ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this enum through its public re-export
    |
8   + use crate::clients::AnthropicError;
    |
help: if you import `AnthropicError`, refer to it directly
    |
225 -                                 crate::providers::anthropic::AnthropicError::RequestError(
225 +                                 AnthropicError::RequestError(
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:234:33
    |
234 |                 Ok::<(), crate::providers::anthropic::AnthropicError>(())
    |                                 ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
8   + use crate::clients::anthropic;
    |
help: if you import `anthropic`, refer to it directly
    |
234 -                 Ok::<(), crate::providers::anthropic::AnthropicError>(())
234 +                 Ok::<(), anthropic::AnthropicError>(())
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/anthropic/streaming.rs:267:50
    |
267 | ) -> Result<Option<AnthropicStreamChunk>, crate::providers::anthropic::AnthropicError> {
    |                                                  ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
8   + use crate::clients::anthropic;
    |
help: if you import `anthropic`, refer to it directly
    |
267 - ) -> Result<Option<AnthropicStreamChunk>, crate::providers::anthropic::AnthropicError> {
267 + ) -> Result<Option<AnthropicStreamChunk>, anthropic::AnthropicError> {
    |

error[E0412]: cannot find type `Document` in module `completion`
   --> packages/provider/src/clients/azure/client.rs:366:32
    |
366 |     documents: Vec<completion::Document>,
    |                                ^^^^^^^^ not found in `completion`
    |
help: consider importing one of these structs
    |
9   + use crate::domain::Document;
    |
9   + use fluent_ai_domain::Document;
    |
9   + use yyaml::parser::Document;
    |
help: if you import `Document`, refer to it directly
    |
366 -     documents: Vec<completion::Document>,
366 +     documents: Vec<Document>,
    |

warning: unused variable: `entries`
    --> packages/fluent-ai-candle/src/kv_cache/mod.rs:1267:40
     |
1267 |     pub const fn max_entries(mut self, entries: usize) -> Self {
     |                                        ^^^^^^^ help: if this is intentional, prefix it with an underscore: `_entries`
     |
     = note: `#[warn(unused_variables)]` on by default

warning: variable does not need to be mutable
    --> packages/fluent-ai-candle/src/kv_cache/mod.rs:1267:30
     |
1267 |     pub const fn max_entries(mut self, entries: usize) -> Self {
     |                              ----^^^^
     |                              |
     |                              help: remove this `mut`

error[E0405]: cannot find trait `ToolDefinitionInto` in module `completion`
   --> packages/provider/src/clients/azure/client.rs:422:32
    |
422 |     pub fn tool<T: completion::ToolDefinitionInto>(mut self, tool: T) -> Self {
    |                                ^^^^^^^^^^^^^^^^^^ not found in `completion`

error[E0412]: cannot find type `AsyncTask` in this scope
   --> packages/provider/src/clients/azure/client.rs:489:10
    |
489 |     ) -> AsyncTask<
    |          ^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::AsyncTask;
    |
9   + use cyrup_sugars::AsyncTask;
    |
9   + use fluent_ai_domain::AsyncTask;
    |
9   + use progresshub::AsyncTask;
    |

error[E0412]: cannot find type `CompletionResponseData` in module `completion`
   --> packages/provider/src/clients/azure/client.rs:490:59
    |
490 |         Result<completion::CompletionResponse<completion::CompletionResponseData>, CompletionError>,
    |                                                           ^^^^^^^^^^^^^^^^^^^^^^ help: a struct with a similar name exists: `CompletionResponse`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/response.rs:14:1
    |
14  | pub struct CompletionResponse<'a> {
    | --------------------------------- similarly named struct `CompletionResponse` defined here

error[E0412]: cannot find type `AsyncTask` in this scope
   --> packages/provider/src/clients/azure/client.rs:499:10
    |
499 |     ) -> AsyncTask<
    |          ^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::AsyncTask;
    |
9   + use cyrup_sugars::AsyncTask;
    |
9   + use fluent_ai_domain::AsyncTask;
    |
9   + use progresshub::AsyncTask;
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/azure/client.rs:501:20
    |
501 |             crate::streaming::StreamingCompletionResponse<
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
501 |             crate::candle_core::streaming::StreamingCompletionResponse<
    |                    +++++++++++++
help: consider importing one of these modules
    |
9   + use crate::clients::azure::streaming;
    |
9   + use crate::clients::deepseek::streaming;
    |
9   + use crate::clients::gemini::streaming;
    |
9   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
501 -             crate::streaming::StreamingCompletionResponse<
501 +             streaming::StreamingCompletionResponse<
    |

error[E0412]: cannot find type `AsyncTask` in this scope
   --> packages/provider/src/clients/azure/client.rs:512:53
    |
512 |     pub fn chat(self, prompt: impl Into<String>) -> AsyncTask<Result<String, PromptError>> {
    |                                                     ^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::AsyncTask;
    |
9   + use cyrup_sugars::AsyncTask;
    |
9   + use fluent_ai_domain::AsyncTask;
    |
9   + use progresshub::AsyncTask;
    |

error[E0412]: cannot find type `PromptError` in this scope
   --> packages/provider/src/clients/azure/client.rs:512:78
    |
512 |     pub fn chat(self, prompt: impl Into<String>) -> AsyncTask<Result<String, PromptError>> {
    |                                                                              ^^^^^^^^^^^ not found in this scope
    |
help: you might be missing a type parameter
    |
466 | impl<'a, PromptError> AzureCompletionBuilder<'a, HasPrompt> {
    |        +++++++++++++

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/azure/client.rs:613:18
    |
613 |     type Model = EmbeddingModel;
    |                  ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::EmbeddingModel;
    |
9   + use crate::domain::EmbeddingModel;
    |
9   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
9   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/azure/client.rs:616:47
    |
616 |     fn embedding_model(&self, model: &str) -> EmbeddingModel {
    |                                               ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::EmbeddingModel;
    |
9   + use crate::domain::EmbeddingModel;
    |
9   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
9   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingModel`
   --> packages/provider/src/clients/azure/client.rs:624:9
    |
624 |         EmbeddingModel::new(self.clone(), model, ndims)
    |         ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingModel`
    |
help: consider importing one of these items
    |
9   + use crate::EmbeddingModel;
    |
9   + use crate::domain::EmbeddingModel;
    |
9   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
9   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/azure/client.rs:628:72
    |
628 |     fn embedding_model_with_ndims(&self, model: &str, ndims: usize) -> EmbeddingModel {
    |                                                                        ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::EmbeddingModel;
    |
9   + use crate::domain::EmbeddingModel;
    |
9   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
9   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingModel`
   --> packages/provider/src/clients/azure/client.rs:629:9
    |
629 |         EmbeddingModel::new(self.clone(), model, ndims)
    |         ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingModel`
    |
help: consider importing one of these items
    |
9   + use crate::EmbeddingModel;
    |
9   + use crate::domain::EmbeddingModel;
    |
9   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
9   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0412]: cannot find type `TranscriptionModel` in this scope
   --> packages/provider/src/clients/azure/client.rs:634:18
    |
634 |     type Model = TranscriptionModel;
    |                  ^^^^^^^^^^^^^^^^^^ help: a trait with a similar name exists: `TranscriptionClient`
    |
   ::: packages/provider/src/client.rs:43:1
    |
43  | pub trait TranscriptionClient: Send + Sync + Clone {
    | -------------------------------------------------- similarly named trait `TranscriptionClient` defined here

error[E0412]: cannot find type `TranscriptionModel` in this scope
   --> packages/provider/src/clients/azure/client.rs:637:51
    |
637 |     fn transcription_model(&self, model: &str) -> TranscriptionModel {
    |                                                   ^^^^^^^^^^^^^^^^^^ help: a trait with a similar name exists: `TranscriptionClient`
    |
   ::: packages/provider/src/client.rs:43:1
    |
43  | pub trait TranscriptionClient: Send + Sync + Clone {
    | -------------------------------------------------- similarly named trait `TranscriptionClient` defined here

error[E0573]: expected type, found function `AsyncTask`
  --> packages/provider/src/clients/azure/completion.rs:92:10
   |
92 |     ) -> AsyncTask<Result<completion::CompletionResponse<Self::Response>, CompletionError>> {
   |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a type
   |
help: consider importing one of these items instead
   |
9  + use crate::AsyncTask;
   |
9  + use cyrup_sugars::AsyncTask;
   |
9  + use fluent_ai_domain::AsyncTask;
   |
9  + use progresshub::AsyncTask;
   |

error[E0412]: cannot find type `CompletionError` in this scope
  --> packages/provider/src/clients/azure/completion.rs:92:75
   |
92 |     ) -> AsyncTask<Result<completion::CompletionResponse<Self::Response>, CompletionError>> {
   |                                                                           ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
   |
40 | pub enum CompletionCoreError {
   | ---------------------------- similarly named enum `CompletionCoreError` defined here
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0425]: cannot find function `spawn_async` in module `rt`
  --> packages/provider/src/clients/azure/completion.rs:94:13
   |
94 |         rt::spawn_async(async move { this.perform_completion(req).await })
   |             ^^^^^^^^^^^ not found in `rt`
   |
help: consider importing one of these functions
   |
9  + use crate::spawn_async;
   |
9  + use fluent_ai_domain::spawn_async;
   |
help: if you import `spawn_async`, refer to it directly
   |
94 -         rt::spawn_async(async move { this.perform_completion(req).await })
94 +         spawn_async(async move { this.perform_completion(req).await })
   |

warning: unused variable: `scaled_logits`
   --> packages/fluent-ai-candle/src/sampling/gumbel.rs:151:9
    |
151 |         scaled_logits: &Tensor
    |         ^^^^^^^^^^^^^ help: if this is intentional, prefix it with an underscore: `_scaled_logits`

error[E0573]: expected type, found function `AsyncTask`
   --> packages/provider/src/clients/azure/completion.rs:100:10
    |
100 |     ) -> AsyncTask<Result<RigStreaming<Self::StreamingResponse>, CompletionError>> {
    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a type
    |
help: consider importing one of these items instead
    |
9   + use crate::AsyncTask;
    |
9   + use cyrup_sugars::AsyncTask;
    |
9   + use fluent_ai_domain::AsyncTask;
    |
9   + use progresshub::AsyncTask;
    |

error[E0412]: cannot find type `CompletionError` in this scope
   --> packages/provider/src/clients/azure/completion.rs:100:66
    |
100 |     ) -> AsyncTask<Result<RigStreaming<Self::StreamingResponse>, CompletionError>> {
    |                                                                  ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
    |
40  | pub enum CompletionCoreError {
    | ---------------------------- similarly named enum `CompletionCoreError` defined here
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0382]: borrow of moved value: `token_analysis`
   --> packages/fluent-ai-candle/src/sampling/typical.rs:213:44
    |
169 |         let mut token_analysis: Vec<(usize, f32, f64)> = probabilities.iter()
    |             ------------------ move occurs because `token_analysis` has type `Vec<(usize, f32, f64)>`, which does not implement the `Copy` trait
...
203 |         for (token_idx, prob, _entropy_diff) in token_analysis {
    |                                                 -------------- `token_analysis` moved due to this implicit call to `.into_iter()`
...
213 |         if selected_indices.is_empty() && !token_analysis.is_empty() {
    |                                            ^^^^^^^^^^^^^^ value borrowed here after move
    |
note: `into_iter` takes ownership of the receiver `self`, which moves `token_analysis`
   --> /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/iter/traits/collect.rs:310:18
    |
310 |     fn into_iter(self) -> Self::IntoIter;
    |                  ^^^^
help: consider iterating over a slice of the `Vec<(usize, f32, f64)>`'s content to avoid moving into the `for` loop
    |
203 |         for (token_idx, prob, _entropy_diff) in &token_analysis {
    |                                                 +

error[E0425]: cannot find function `spawn_async` in module `rt`
   --> packages/provider/src/clients/azure/completion.rs:102:13
    |
102 |         rt::spawn_async(async move { this.perform_stream(req).await })
    |             ^^^^^^^^^^^ not found in `rt`
    |
help: consider importing one of these functions
    |
9   + use crate::spawn_async;
    |
9   + use fluent_ai_domain::spawn_async;
    |
help: if you import `spawn_async`, refer to it directly
    |
102 -         rt::spawn_async(async move { this.perform_stream(req).await })
102 +         spawn_async(async move { this.perform_stream(req).await })
    |

error[E0412]: cannot find type `CompletionError` in this scope
   --> packages/provider/src/clients/azure/completion.rs:113:77
    |
113 |     ) -> Result<completion::CompletionResponse<openai::CompletionResponse>, CompletionError> {
    |                                                                             ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
    |
40  | pub enum CompletionCoreError {
    | ---------------------------- similarly named enum `CompletionCoreError` defined here
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: use of undeclared type `CompletionError`
   --> packages/provider/src/clients/azure/completion.rs:135:46
    |
135 |                 ApiResponse::Err(err) => Err(CompletionError::ProviderError(err.message)),
    |                                              ^^^^^^^^^^^^^^^
    |                                              |
    |                                              use of undeclared type `CompletionError`
    |                                              help: an enum with a similar name exists: `CompletionCoreError`
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

warning: unused variable: `device`
   --> packages/fluent-ai-candle/src/sampling/mod.rs:391:9
    |
391 |         device: &Device,
    |         ^^^^^^ help: if this is intentional, prefix it with an underscore: `_device`

error[E0433]: failed to resolve: use of undeclared type `CompletionError`
   --> packages/provider/src/clients/azure/completion.rs:138:17
    |
138 |             Err(CompletionError::ProviderError(response.text().await?))
    |                 ^^^^^^^^^^^^^^^
    |                 |
    |                 use of undeclared type `CompletionError`
    |                 help: an enum with a similar name exists: `CompletionCoreError`
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0412]: cannot find type `CompletionError` in this scope
   --> packages/provider/src/clients/azure/completion.rs:146:68
    |
146 |     ) -> Result<RigStreaming<openai::StreamingCompletionResponse>, CompletionError> {
    |                                                                    ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
    |
40  | pub enum CompletionCoreError {
    | ---------------------------- similarly named enum `CompletionCoreError` defined here
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

warning: unused variable: `chunk`
   --> packages/fluent-ai-candle/src/streaming/mod.rs:664:36
    |
664 |             Err(TrySendError::Full(chunk)) => {
    |                                    ^^^^^ help: if this is intentional, prefix it with an underscore: `_chunk`

error[E0425]: cannot find function `merge` in this scope
   --> packages/provider/src/clients/azure/completion.rs:149:19
    |
149 |         request = merge(
    |                   ^^^^^ not found in this scope
    |
note: function `crate::clients::xai::streaming::merge` exists but is inaccessible
   --> packages/provider/src/clients/xai/streaming.rs:9:1
    |
9   | fn merge(mut base: serde_json::Value, other: serde_json::Value) -> serde_json::Value {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible

warning: variable does not need to be mutable
   --> packages/fluent-ai-candle/src/streaming/mod.rs:725:18
    |
725 |     fn poll_next(mut self: Pin<&mut Self>, cx: &mut Context<'_>) -> Poll<Option<Self::Item>> {
    |                  ----^^^^
    |                  |
    |                  help: remove this `mut`

error[E0412]: cannot find type `CompletionError` in this scope
   --> packages/provider/src/clients/azure/completion.rs:166:36
    |
166 |     ) -> Result<serde_json::Value, CompletionError> {
    |                                    ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
    |
40  | pub enum CompletionCoreError {
    | ---------------------------- similarly named enum `CompletionCoreError` defined here
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: could not find `ToolDefinition` in `openai`
   --> packages/provider/src/clients/azure/completion.rs:199:75
    |
199 |                 "tools": completion_request.tools.into_iter().map(openai::ToolDefinition::from).collect::<Vec<_>>(),
    |                                                                           ^^^^^^^^^^^^^^ could not find `ToolDefinition` in `openai`
    |
note: struct `crate::clients::ollama::completion::ToolDefinition` exists but is inaccessible
   --> packages/provider/src/clients/ollama/completion.rs:403:1
    |
403 | pub struct ToolDefinition {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible
help: consider importing one of these items
    |
9   + use crate::clients::azure::completion::completion::ToolDefinition;
    |
9   + use crate::clients::xai::completion::xai_api_types::ToolDefinition;
    |
9   + use crate::domain::ToolDefinition;
    |
9   + use fluent_ai_domain::ToolDefinition;
    |
      and 1 other candidate
help: if you import `ToolDefinition`, refer to it directly
    |
199 -                 "tools": completion_request.tools.into_iter().map(openai::ToolDefinition::from).collect::<Vec<_>>(),
199 +                 "tools": completion_request.tools.into_iter().map(ToolDefinition::from).collect::<Vec<_>>(),
    |

error[E0493]: destructor of `candle_core::Device` cannot be evaluated at compile-time
   --> packages/fluent-ai-candle/src/var_builder.rs:140:9
    |
140 |         self.device = device;
    |         ^^^^^^^^^^^
    |         |
    |         the destructor for this type cannot be evaluated in constant functions
    |         value is dropped here

error[E0412]: cannot find type `EmbeddingError` in this scope
  --> packages/provider/src/clients/azure/embedding.rs:75:33
   |
75 | impl From<ApiErrorResponse> for EmbeddingError {
   |                                 ^^^^^^^^^^^^^^ not found in this scope
   |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
   |
75 - impl From<ApiErrorResponse> for EmbeddingError {
75 + impl From<ApiErrorResponse> for crate::domain::ContextError {
   |
75 - impl From<ApiErrorResponse> for EmbeddingError {
75 + impl From<ApiErrorResponse> for fluent_ai_domain::ContextError {
   |

error[E0412]: cannot find type `EmbeddingError` in this scope
  --> packages/provider/src/clients/azure/embedding.rs:81:73
   |
81 | impl From<ApiResponse<EmbeddingResponse>> for Result<EmbeddingResponse, EmbeddingError> {
   |                                                                         ^^^^^^^^^^^^^^ not found in this scope
   |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
   |
81 - impl From<ApiResponse<EmbeddingResponse>> for Result<EmbeddingResponse, EmbeddingError> {
81 + impl From<ApiResponse<EmbeddingResponse>> for Result<EmbeddingResponse, crate::domain::ContextError> {
   |
81 - impl From<ApiResponse<EmbeddingResponse>> for Result<EmbeddingResponse, EmbeddingError> {
81 + impl From<ApiResponse<EmbeddingResponse>> for Result<EmbeddingResponse, fluent_ai_domain::ContextError> {
   |
help: you might be missing a type parameter
   |
81 | impl<EmbeddingError> From<ApiResponse<EmbeddingResponse>> for Result<EmbeddingResponse, EmbeddingError> {
   |     ++++++++++++++++

error[E0412]: cannot find type `EmbeddingModel` in this scope
  --> packages/provider/src/clients/azure/embedding.rs:94:6
   |
94 | impl EmbeddingModel {
   |      ^^^^^^^^^^^^^^ not found in this scope
   |
help: consider importing one of these items
   |
9  + use crate::EmbeddingModel;
   |
9  + use crate::clients::azure::embedding::embedding::EmbeddingModel;
   |
9  + use candle_transformers::models::stella_en_v5::EmbeddingModel;
   |
9  + use fluent_ai_domain::EmbeddingModel;
   |

warning: unused variable: `inner`
   --> packages/fluent-ai-candle/src/var_builder.rs:994:9
    |
994 |         inner: &VarBuilder<'a>,
    |         ^^^^^ help: if this is intentional, prefix it with an underscore: `_inner`

warning: unused variable: `name`
    --> packages/fluent-ai-candle/src/var_builder.rs:1031:57
     |
1031 |     fn optimize_tensor_placement(&self, tensor: Tensor, name: &str) -> Result<Tensor> {
     |                                                         ^^^^ help: if this is intentional, prefix it with an underscore: `_name`

error[E0433]: failed to resolve: could not find `client` in `super`
   --> packages/provider/src/clients/azure/embedding.rs:106:20
    |
106 | impl super::super::client::EmbeddingModel for EmbeddingModel {
    |                    ^^^^^^ could not find `client` in `super`
    |
note: module `crate::clients::ollama::client` exists but is inaccessible
   --> packages/provider/src/clients/ollama/mod.rs:7:1
    |
7   | mod client;
    | ^^^^^^^^^^^ not accessible
help: consider importing one of these modules
    |
9   + use crate::client;
    |
9   + use crate::clients::azure::client;
    |
9   + use crate::clients::gemini::client;
    |
9   + use crate::clients::together::client;
    |
help: if you import `client`, refer to it directly
    |
106 - impl super::super::client::EmbeddingModel for EmbeddingModel {
106 + impl client::EmbeddingModel for EmbeddingModel {
    |

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/azure/embedding.rs:106:47
    |
106 | impl super::super::client::EmbeddingModel for EmbeddingModel {
    |                                               ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::EmbeddingModel;
    |
9   + use crate::clients::azure::embedding::embedding::EmbeddingModel;
    |
9   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
9   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0573]: expected type, found function `AsyncTask`
   --> packages/provider/src/clients/azure/embedding.rs:118:10
    |
118 |     ) -> AsyncTask<Result<Vec<fluent_ai_domain::embedding::Embedding>, anyhow::Error /* was fluent_ai_domain::embedding::EmbeddingError */>>
    |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a type
    |
help: consider importing one of these items instead
    |
9   + use crate::AsyncTask;
    |
9   + use cyrup_sugars::AsyncTask;
    |
9   + use fluent_ai_domain::AsyncTask;
    |
9   + use progresshub::AsyncTask;
    |

error[E0425]: cannot find function `spawn_async` in crate `rt`
   --> packages/provider/src/clients/azure/embedding.rs:122:13
    |
122 |         rt::spawn_async(async move { this.perform_embedding_batch(documents).await })
    |             ^^^^^^^^^^^ not found in `rt`
    |
help: consider importing one of these functions
    |
9   + use crate::spawn_async;
    |
9   + use fluent_ai_domain::spawn_async;
    |
help: if you import `spawn_async`, refer to it directly
    |
122 -         rt::spawn_async(async move { this.perform_embedding_batch(documents).await })
122 +         spawn_async(async move { this.perform_embedding_batch(documents).await })
    |

error[E0573]: expected type, found function `AsyncTask`
   --> packages/provider/src/clients/azure/embedding.rs:126:36
    |
126 |     fn embed(&self, text: &str) -> AsyncTask<cyrup_sugars::ZeroOneOrMany<f32>> {
    |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a type
    |
help: consider importing one of these items instead
    |
9   + use crate::AsyncTask;
    |
9   + use cyrup_sugars::AsyncTask;
    |
9   + use fluent_ai_domain::AsyncTask;
    |
9   + use progresshub::AsyncTask;
    |

error[E0425]: cannot find function `spawn_async` in crate `rt`
   --> packages/provider/src/clients/azure/embedding.rs:129:13
    |
129 |         rt::spawn_async(async move {
    |             ^^^^^^^^^^^ not found in `rt`
    |
help: consider importing one of these functions
    |
9   + use crate::spawn_async;
    |
9   + use fluent_ai_domain::spawn_async;
    |
help: if you import `spawn_async`, refer to it directly
    |
129 -         rt::spawn_async(async move {
129 +         spawn_async(async move {
    |

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/azure/embedding.rs:176:6
    |
176 | impl EmbeddingModel {
    |      ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
9   + use crate::EmbeddingModel;
    |
9   + use crate::clients::azure::embedding::embedding::EmbeddingModel;
    |
9   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
9   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0573]: expected type, found function `AsyncTask`
  --> packages/provider/src/clients/azure/streaming.rs:43:10
   |
43 |     ) -> AsyncTask<Result<RigStreaming<StreamingCompletionResponse>, CompletionError>> {
   |          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not a type
   |
help: consider importing one of these items instead
   |
9  + use crate::AsyncTask;
   |
9  + use cyrup_sugars::AsyncTask;
   |
9  + use fluent_ai_domain::AsyncTask;
   |
9  + use progresshub::AsyncTask;
   |

Some errors have detailed explanations: E0061, E0107, E0271, E0277, E0308, E0369, E0382, E0433, E0493...
For more information about an error, try `rustc --explain E0061`.
error[E0412]: cannot find type `CompletionError` in this scope
  --> packages/provider/src/clients/azure/streaming.rs:43:70
   |
43 |     ) -> AsyncTask<Result<RigStreaming<StreamingCompletionResponse>, CompletionError>> {
   |                                                                      ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
   |
40 | pub enum CompletionCoreError {
   | ---------------------------- similarly named enum `CompletionCoreError` defined here
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0425]: cannot find function `spawn_async` in crate `rt`
  --> packages/provider/src/clients/azure/streaming.rs:44:13
   |
44 |         rt::spawn_async(self.clone().drive_stream(req))
   |             ^^^^^^^^^^^ not found in `rt`
   |
help: consider importing one of these functions
   |
9  + use crate::spawn_async;
   |
9  + use fluent_ai_domain::spawn_async;
   |
help: if you import `spawn_async`, refer to it directly
   |
44 -         rt::spawn_async(self.clone().drive_stream(req))
44 +         spawn_async(self.clone().drive_stream(req))
   |

error[E0412]: cannot find type `CompletionError` in this scope
  --> packages/provider/src/clients/azure/streaming.rs:52:60
   |
52 |     ) -> Result<RigStreaming<StreamingCompletionResponse>, CompletionError> {
   |                                                            ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
   |
40 | pub enum CompletionCoreError {
   | ---------------------------- similarly named enum `CompletionCoreError` defined here
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0425]: cannot find function `merge` in this scope
  --> packages/provider/src/clients/azure/streaming.rs:56:19
   |
56 |         request = merge(
   |                   ^^^^^ not found in this scope
   |
note: function `crate::clients::xai::streaming::merge` exists but is inaccessible
  --> packages/provider/src/clients/xai/streaming.rs:9:1
   |
9  | fn merge(mut base: serde_json::Value, other: serde_json::Value) -> serde_json::Value {
   | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0412]: cannot find type `TranscriptionModel` in this scope
  --> packages/provider/src/clients/azure/transcription.rs:38:6
   |
38 | impl TranscriptionModel {
   |      ^^^^^^^^^^^^^^^^^^ not found in this scope

warning: `fluent_ai_candle` (lib) generated 40 warnings
error: could not compile `fluent_ai_candle` (lib) due to 101 previous errors; 40 warnings emitted
warning: build failed, waiting for other jobs to finish...
error[E0433]: failed to resolve: use of unresolved module or unlinked crate `transcription`
  --> packages/provider/src/clients/azure/transcription.rs:49:6
   |
49 | impl transcription::TranscriptionModel for TranscriptionModel {
   |      ^^^^^^^^^^^^^ use of unresolved module or unlinked crate `transcription`
   |
help: to make use of source file packages/provider/src/clients/azure/transcription.rs, use `mod transcription` in this file to declare the module
  --> packages/provider/src/lib.rs:7:1
   |
7  + mod transcription;
   |
help: consider importing this module
   |
10 + use crate::clients::gemini::transcription;
   |

error[E0412]: cannot find type `TranscriptionModel` in this scope
  --> packages/provider/src/clients/azure/transcription.rs:49:44
   |
49 | impl transcription::TranscriptionModel for TranscriptionModel {
   |                                            ^^^^^^^^^^^^^^^^^^ not found in this scope

error[E0573]: expected type, found function `AsyncTask`
  --> packages/provider/src/clients/azure/transcription.rs:55:10
   |
55 |       ) -> AsyncTask<
   |  __________^
56 | |         Result<
57 | |             transcription::TranscriptionResponse<Self::Response>,
58 | |             transcription::TranscriptionError,
59 | |         >,
60 | |     > {
   | |_____^ not a type
   |
help: consider importing one of these items instead
   |
10 + use crate::AsyncTask;
   |
10 + use cyrup_sugars::AsyncTask;
   |
10 + use fluent_ai_domain::AsyncTask;
   |
10 + use progresshub::AsyncTask;
   |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `transcription`
  --> packages/provider/src/clients/azure/transcription.rs:57:13
   |
57 |             transcription::TranscriptionResponse<Self::Response>,
   |             ^^^^^^^^^^^^^ use of unresolved module or unlinked crate `transcription`
   |
help: to make use of source file packages/provider/src/clients/azure/transcription.rs, use `mod transcription` in this file to declare the module
  --> packages/provider/src/lib.rs:7:1
   |
7  + mod transcription;
   |
help: consider importing this module
   |
10 + use crate::clients::huggingface::transcription;
   |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `transcription`
  --> packages/provider/src/clients/azure/transcription.rs:58:13
   |
58 |             transcription::TranscriptionError,
   |             ^^^^^^^^^^^^^ use of unresolved module or unlinked crate `transcription`
   |
help: to make use of source file packages/provider/src/clients/azure/transcription.rs, use `mod transcription` in this file to declare the module
  --> packages/provider/src/lib.rs:7:1
   |
7  + mod transcription;
   |
help: consider importing one of these modules
   |
10 + use crate::clients::gemini::transcription;
   |
10 + use crate::clients::huggingface::transcription;
   |

error[E0425]: cannot find function `spawn_async` in crate `rt`
  --> packages/provider/src/clients/azure/transcription.rs:62:13
   |
62 |         rt::spawn_async(async move { this.perform_transcription(request).await })
   |             ^^^^^^^^^^^ not found in `rt`
   |
help: consider importing one of these functions
   |
10 + use crate::spawn_async;
   |
10 + use fluent_ai_domain::spawn_async;
   |
help: if you import `spawn_async`, refer to it directly
   |
62 -         rt::spawn_async(async move { this.perform_transcription(request).await })
62 +         spawn_async(async move { this.perform_transcription(request).await })
   |

error[E0412]: cannot find type `TranscriptionModel` in this scope
  --> packages/provider/src/clients/azure/transcription.rs:68:6
   |
68 | impl TranscriptionModel {
   |      ^^^^^^^^^^^^^^^^^^ not found in this scope

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `transcription`
  --> packages/provider/src/clients/azure/transcription.rs:73:9
   |
73 |         transcription::TranscriptionResponse<TranscriptionResponse>,
   |         ^^^^^^^^^^^^^ use of unresolved module or unlinked crate `transcription`
   |
help: to make use of source file packages/provider/src/clients/azure/transcription.rs, use `mod transcription` in this file to declare the module
  --> packages/provider/src/lib.rs:7:1
   |
7  + mod transcription;
   |
help: consider importing this module
   |
10 + use crate::clients::huggingface::transcription;
   |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `transcription`
  --> packages/provider/src/clients/azure/transcription.rs:74:9
   |
74 |         transcription::TranscriptionError,
   |         ^^^^^^^^^^^^^ use of unresolved module or unlinked crate `transcription`
   |
help: to make use of source file packages/provider/src/clients/azure/transcription.rs, use `mod transcription` in this file to declare the module
  --> packages/provider/src/lib.rs:7:1
   |
7  + mod transcription;
   |
help: consider importing one of these modules
   |
10 + use crate::clients::gemini::transcription;
   |
10 + use crate::clients::huggingface::transcription;
   |

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/completion.rs:405:39
    |
405 |                     let error_chunk = CompletionChunk {
    |                                       ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
  --> packages/provider/src/clients/bedrock/streaming.rs:74:43
   |
74 |                         let error_chunk = CompletionChunk {
   |                                           ^^^^^^^^^^^^^^^ not a struct, variant or union type
   |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
  --> packages/provider/src/clients/huggingface/streaming.rs:56:1
   |
56 | struct CompletionChunk {
   | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
  --> packages/provider/src/clients/bedrock/streaming.rs:89:35
   |
89 |                 let final_chunk = CompletionChunk {
   |                                   ^^^^^^^^^^^^^^^ not a struct, variant or union type
   |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
  --> packages/provider/src/clients/huggingface/streaming.rs:56:1
   |
56 | struct CompletionChunk {
   | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0412]: cannot find type `EventStreamEvent` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/bedrock/streaming.rs:110:33
    |
110 |         event: fluent_ai_http3::EventStreamEvent,
    |                                 ^^^^^^^^^^^^^^^^ not found in `fluent_ai_http3`

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/streaming.rs:152:25
    |
152 |             return Some(CompletionChunk {
    |                         ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/streaming.rs:173:25
    |
173 |             return Some(CompletionChunk {
    |                         ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/streaming.rs:196:25
    |
196 |             return Some(CompletionChunk {
    |                         ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/streaming.rs:219:14
    |
219 |         Some(CompletionChunk {
    |              ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/streaming.rs:254:25
    |
254 |             return Some(CompletionChunk {
    |                         ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/streaming.rs:296:37
    |
296 |                         return Some(CompletionChunk {
    |                                     ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/bedrock/streaming.rs:315:29
    |
315 |                 return Some(CompletionChunk {
    |                             ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0412]: cannot find type `ConfigMetrics` in module `super::config`
   --> packages/provider/src/clients/candle/client.rs:722:47
    |
722 |     pub global_config_metrics: super::config::ConfigMetrics,
    |                                               ^^^^^^^^^^^^^ not found in `super::config`

error[E0412]: cannot find type `RuntimeMetrics` in module `super::config`
   --> packages/provider/src/clients/candle/client.rs:724:42
    |
724 |     pub realtime_metrics: super::config::RuntimeMetrics,
    |                                          ^^^^^^^^^^^^^^ not found in `super::config`
    |
help: consider importing this struct
    |
6   + use tokio::runtime::RuntimeMetrics;
    |
help: if you import `RuntimeMetrics`, refer to it directly
    |
724 -     pub realtime_metrics: super::config::RuntimeMetrics,
724 +     pub realtime_metrics: RuntimeMetrics,
    |

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:739:39
    |
739 |                     let error_chunk = CompletionChunk {
    |                                       ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:769:35
    |
769 |                 let error_chunk = CompletionChunk {
    |                                   ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:782:39
    |
782 |                     let error_chunk = CompletionChunk {
    |                                       ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:798:35
    |
798 |                 let error_chunk = CompletionChunk {
    |                                   ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:830:39
    |
830 |                     let error_chunk = CompletionChunk {
    |                                       ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:864:43
    |
864 |                         let error_chunk = CompletionChunk {
    |                                           ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:879:43
    |
879 |                         let error_chunk = CompletionChunk {
    |                                           ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:905:39
    |
905 |                     let error_chunk = CompletionChunk {
    |                                       ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:942:40
    |
942 |                 let completion_chunk = CompletionChunk {
    |                                        ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/candle/client.rs:968:31
    |
968 |             let final_chunk = CompletionChunk {
    |                               ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0422]: cannot find struct, variant or union type `CompletionUsage` in module `fluent_ai_domain::usage`
   --> packages/provider/src/clients/candle/client.rs:976:54
    |
976 |                 usage: Some(fluent_ai_domain::usage::CompletionUsage {
    |                                                      ^^^^^^^^^^^^^^^ not found in `fluent_ai_domain::usage`

error[E0412]: cannot find type `CompletionError` in crate `fluent_ai_domain`
    --> packages/provider/src/clients/candle/client.rs:1011:52
     |
1011 | impl From<CandleClientError> for fluent_ai_domain::CompletionError {
     |                                                    ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionChunk`
     |
    ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
     |
121  | pub enum CompletionChunk {
     | ------------------------ similarly named enum `CompletionChunk` defined here
     |
     = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: could not find `CompletionError` in `fluent_ai_domain`
    --> packages/provider/src/clients/candle/client.rs:1013:27
     |
1013 |         fluent_ai_domain::CompletionError::ProviderError(err.to_string())
     |                           ^^^^^^^^^^^^^^^
     |                           |
     |                           could not find `CompletionError` in `fluent_ai_domain`
     |                           help: an enum with a similar name exists: `CompletionChunk`
     |
     = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0412]: cannot find type `AtomicU32` in this scope
    --> packages/provider/src/clients/candle/device_manager.rs:208:35
     |
208  |       avg_scan_time_us: CachePadded<AtomicU32>,
     |                                     ^^^^^^^^^
     |
    ::: /Users/davidmaple/.rustup/toolchains/nightly-aarch64-apple-darwin/lib/rustlib/src/rust/library/core/src/sync/atomic.rs:3786:1
     |
3786 | / atomic_int! {
3787 | |     cfg(target_has_atomic = "64"),
3788 | |     cfg(target_has_atomic_equal_alignment = "64"),
3789 | |     stable(feature = "integer_atomics_stable", since = "1.34.0"),
...    |
3802 | |     u64 AtomicU64
3803 | | }
     | |_- similarly named struct `AtomicU64` defined here
     |
help: a struct with a similar name exists
     |
208  -     avg_scan_time_us: CachePadded<AtomicU32>,
208  +     avg_scan_time_us: CachePadded<AtomicU64>,
     |
help: consider importing this struct
     |
6    + use std::sync::atomic::AtomicU32;
     |

error[E0433]: failed to resolve: use of undeclared type `AtomicU32`
   --> packages/provider/src/clients/candle/device_manager.rs:220:48
    |
220 |             avg_scan_time_us: CachePadded::new(AtomicU32::new(0)),
    |                                                ^^^^^^^^^ use of undeclared type `AtomicU32`
    |
help: a struct with a similar name exists
    |
220 -             avg_scan_time_us: CachePadded::new(AtomicU32::new(0)),
220 +             avg_scan_time_us: CachePadded::new(AtomicU64::new(0)),
    |
help: consider importing this struct
    |
6   + use std::sync::atomic::AtomicU32;
    |

error[E0422]: cannot find struct, variant or union type `ModelInfoData` in this scope
  --> packages/provider/src/clients/candle/models.rs:55:39
   |
55 |             CandleModel::Llama2_7B => ModelInfoData {
   |                                       ^^^^^^^^^^^^^ help: a struct with a similar name exists: `ModelInfo`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/model/info.rs:23:1
   |
23 | pub struct ModelInfo {
   | -------------------- similarly named struct `ModelInfo` defined here

error[E0422]: cannot find struct, variant or union type `ModelInfoData` in this scope
  --> packages/provider/src/clients/candle/models.rs:68:40
   |
68 |             CandleModel::Llama2_13B => ModelInfoData {
   |                                        ^^^^^^^^^^^^^ help: a struct with a similar name exists: `ModelInfo`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/model/info.rs:23:1
   |
23 | pub struct ModelInfo {
   | -------------------- similarly named struct `ModelInfo` defined here

error[E0422]: cannot find struct, variant or union type `ModelInfoData` in this scope
  --> packages/provider/src/clients/candle/models.rs:81:40
   |
81 |             CandleModel::Mistral_7B => ModelInfoData {
   |                                        ^^^^^^^^^^^^^ help: a struct with a similar name exists: `ModelInfo`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/model/info.rs:23:1
   |
23 | pub struct ModelInfo {
   | -------------------- similarly named struct `ModelInfo` defined here

error[E0422]: cannot find struct, variant or union type `ModelInfoData` in this scope
  --> packages/provider/src/clients/candle/models.rs:94:42
   |
94 |             CandleModel::CodeLlama_7B => ModelInfoData {
   |                                          ^^^^^^^^^^^^^ help: a struct with a similar name exists: `ModelInfo`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/model/info.rs:23:1
   |
23 | pub struct ModelInfo {
   | -------------------- similarly named struct `ModelInfo` defined here

error[E0422]: cannot find struct, variant or union type `ModelInfoData` in this scope
   --> packages/provider/src/clients/candle/models.rs:107:39
    |
107 |             CandleModel::Phi3_Mini => ModelInfoData {
    |                                       ^^^^^^^^^^^^^ help: a struct with a similar name exists: `ModelInfo`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/model/info.rs:23:1
    |
23  | pub struct ModelInfo {
    | -------------------- similarly named struct `ModelInfo` defined here

error[E0422]: cannot find struct, variant or union type `ModelInfoData` in this scope
   --> packages/provider/src/clients/candle/models.rs:120:38
    |
120 |             CandleModel::Gemma_2B => ModelInfoData {
    |                                      ^^^^^^^^^^^^^ help: a struct with a similar name exists: `ModelInfo`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/model/info.rs:23:1
    |
23  | pub struct ModelInfo {
    | -------------------- similarly named struct `ModelInfo` defined here

error[E0422]: cannot find struct, variant or union type `ModelInfoData` in this scope
   --> packages/provider/src/clients/candle/models.rs:133:38
    |
133 |             CandleModel::Gemma_7B => ModelInfoData {
    |                                      ^^^^^^^^^^^^^ help: a struct with a similar name exists: `ModelInfo`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/model/info.rs:23:1
    |
23  | pub struct ModelInfo {
    | -------------------- similarly named struct `ModelInfo` defined here

error[E0425]: cannot find value `data` in this scope
   --> packages/provider/src/clients/candle/models.rs:148:30
    |
148 |         ModelInfo::from_data(data)
    |                              ^^^^ not found in this scope

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/deepseek/completion.rs:42:12
   |
42 |     crate::model_info::get_model_config(model_name)
   |            ^^^^^^^^^^ unresolved import
   |
note: module `crate::clients::openai::model_info` exists but is inaccessible
  --> packages/provider/src/clients/openai/mod.rs:53:1
   |
53 | mod model_info;
   | ^^^^^^^^^^^^^^^ not accessible
help: a struct with a similar name exists
   |
42 -     crate::model_info::get_model_config(model_name)
42 +     crate::ModelInfo::get_model_config(model_name)
   |
help: a similar path exists
   |
42 |     crate::clients::gemini::model_info::get_model_config(model_name)
   |            +++++++++++++++++
help: consider importing one of these modules
   |
15 + use crate::clients::gemini::model_info;
   |
15 + use crate::clients::mistral::model_info;
   |
help: if you import `model_info`, refer to it directly
   |
42 -     crate::model_info::get_model_config(model_name)
42 +     model_info::get_model_config(model_name)
   |

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/deepseek/streaming.rs:25:12
   |
25 |     crate::runtime::spawn_async(async move {
   |            ^^^^^^^ unresolved import
   |
help: a similar path exists
   |
25 |     crate::tokio::runtime::spawn_async(async move {
   |            +++++++
help: consider importing one of these modules
   |
7  + use crate::clients::deepseek::streaming::runtime::runtime;
   |
7  + use tokio::runtime;
   |
help: if you import `runtime`, refer to it directly
   |
25 -     crate::runtime::spawn_async(async move {
25 +     runtime::spawn_async(async move {
   |

error[E0425]: cannot find function `async_stream` in crate `runtime`
  --> packages/provider/src/clients/deepseek/streaming.rs:28:22
   |
28 |             runtime::async_stream::<Result<StreamingCompletionResponse, CompletionError>>(512);
   |                      ^^^^^^^^^^^^ not found in `runtime`

error[E0412]: cannot find type `CompletionError` in this scope
  --> packages/provider/src/clients/deepseek/streaming.rs:28:73
   |
28 |             runtime::async_stream::<Result<StreamingCompletionResponse, CompletionError>>(512);
   |                                                                         ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
   |
40 | pub enum CompletionCoreError {
   | ---------------------------- similarly named enum `CompletionCoreError` defined here
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: use of undeclared type `CompletionError`
  --> packages/provider/src/clients/deepseek/streaming.rs:32:13
   |
32 |             CompletionError::RequestError(format!("Failed to create HTTP3 client: {}", e))
   |             ^^^^^^^^^^^^^^^
   |             |
   |             use of undeclared type `CompletionError`
   |             help: an enum with a similar name exists: `CompletionCoreError`
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0425]: cannot find function `spawn_async` in crate `runtime`
  --> packages/provider/src/clients/deepseek/streaming.rs:36:18
   |
36 |         runtime::spawn_async(async move {
   |                  ^^^^^^^^^^^ not found in `runtime`
   |
help: consider importing one of these functions
   |
7  + use crate::spawn_async;
   |
7  + use fluent_ai_domain::spawn_async;
   |
help: if you import `spawn_async`, refer to it directly
   |
36 -         runtime::spawn_async(async move {
36 +         spawn_async(async move {
   |

error[E0433]: failed to resolve: use of undeclared type `CompletionError`
  --> packages/provider/src/clients/deepseek/streaming.rs:41:45
   |
41 |                     let _ = tx.try_send(Err(CompletionError::RequestError(e.to_string())));
   |                                             ^^^^^^^^^^^^^^^
   |                                             |
   |                                             use of undeclared type `CompletionError`
   |                                             help: an enum with a similar name exists: `CompletionCoreError`
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0412]: cannot find type `CompletionError` in this scope
  --> packages/provider/src/clients/deepseek/streaming.rs:42:37
   |
42 |                     return Ok::<(), CompletionError>(());
   |                                     ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
   |
40 | pub enum CompletionCoreError {
   | ---------------------------- similarly named enum `CompletionCoreError` defined here
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: use of undeclared type `CompletionError`
  --> packages/provider/src/clients/deepseek/streaming.rs:71:57
   |
71 | ...                   let _ = tx.try_send(Err(CompletionError::DeserializationError(
   |                                               ^^^^^^^^^^^^^^^
   |                                               |
   |                                               use of undeclared type `CompletionError`
   |                                               help: an enum with a similar name exists: `CompletionCoreError`
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: use of undeclared type `CompletionError`
  --> packages/provider/src/clients/deepseek/streaming.rs:79:49
   |
79 |                         let _ = tx.try_send(Err(CompletionError::RequestError(e.to_string())));
   |                                                 ^^^^^^^^^^^^^^^
   |                                                 |
   |                                                 use of undeclared type `CompletionError`
   |                                                 help: an enum with a similar name exists: `CompletionCoreError`
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0412]: cannot find type `CompletionError` in this scope
  --> packages/provider/src/clients/deepseek/streaming.rs:85:22
   |
85 |             Ok::<(), CompletionError>(())
   |                      ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
   |
  ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
   |
40 | pub enum CompletionCoreError {
   | ---------------------------- similarly named enum `CompletionCoreError` defined here
   |
   = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/deepseek/streaming.rs:88:19
   |
88 |         Ok(crate::streaming::StreamingCompletionResponse::new(
   |                   ^^^^^^^^^ unresolved import
   |
help: a similar path exists
   |
88 |         Ok(crate::candle_core::streaming::StreamingCompletionResponse::new(
   |                   +++++++++++++
help: consider importing one of these items
   |
7  + use crate::clients::azure::StreamingCompletionResponse;
   |
7  + use crate::clients::gemini::streaming::StreamingCompletionResponse;
   |
7  + use crate::clients::openrouter::streaming::StreamingCompletionResponse;
   |
7  + use crate::clients::perplexity::streaming::StreamingCompletionResponse;
   |
help: if you import `StreamingCompletionResponse`, refer to it directly
   |
88 -         Ok(crate::streaming::StreamingCompletionResponse::new(
88 +         Ok(StreamingCompletionResponse::new(
   |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/gemini/client.rs:171:34
    |
171 |     ) -> Result<fluent_ai_http3::Response> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
171 -     ) -> Result<fluent_ai_http3::Response> {
171 +     ) -> Result<Response> {
    |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/gemini/client.rs:210:34
    |
210 |     ) -> Result<fluent_ai_http3::Response> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
210 -     ) -> Result<fluent_ai_http3::Response> {
210 +     ) -> Result<Response> {
    |

error[E0405]: cannot find trait `Embed` in this scope
   --> packages/provider/src/clients/gemini/client.rs:288:26
    |
288 |     pub fn embeddings<D: Embed>(&self, model: &str) -> EmbeddingBuilder<EmbeddingModel, D> {
    |                          ^^^^^ not found in this scope

error[E0412]: cannot find type `EmbeddingBuilder` in this scope
   --> packages/provider/src/clients/gemini/client.rs:288:56
    |
288 |     pub fn embeddings<D: Embed>(&self, model: &str) -> EmbeddingBuilder<EmbeddingModel, D> {
    |                                                        ^^^^^^^^^^^^^^^^ not found in this scope

error[E0412]: cannot find type `Document` in module `completion`
   --> packages/provider/src/clients/gemini/client.rs:391:32
    |
391 |     documents: Vec<completion::Document>,
    |                                ^^^^^^^^ not found in `completion`
    |
help: consider importing one of these structs
    |
7   + use crate::domain::Document;
    |
7   + use fluent_ai_domain::Document;
    |
7   + use yyaml::parser::Document;
    |
help: if you import `Document`, refer to it directly
    |
391 -     documents: Vec<completion::Document>,
391 +     documents: Vec<Document>,
    |

error[E0412]: cannot find type `Document` in module `completion`
   --> packages/provider/src/clients/gemini/client.rs:493:54
    |
493 |     pub fn documents(mut self, docs: Vec<completion::Document>) -> Self {
    |                                                      ^^^^^^^^ not found in `completion`
    |
help: consider importing one of these structs
    |
7   + use crate::domain::Document;
    |
7   + use fluent_ai_domain::Document;
    |
7   + use yyaml::parser::Document;
    |
help: if you import `Document`, refer to it directly
    |
493 -     pub fn documents(mut self, docs: Vec<completion::Document>) -> Self {
493 +     pub fn documents(mut self, docs: Vec<Document>) -> Self {
    |

error[E0412]: cannot find type `PromptError` in this scope
   --> packages/provider/src/clients/gemini/client.rs:544:58
    |
544 |     fn build_request(&self) -> Result<CompletionRequest, PromptError> {
    |                                                          ^^^^^^^^^^^ not found in this scope
    |
help: you might be missing a type parameter
    |
542 | impl<'a, PromptError> GeminiCompletionBuilder<'a, HasPrompt> {
    |        +++++++++++++

error[E0412]: cannot find type `CompletionResponse` in module `super::completion`
   --> packages/provider/src/clients/gemini/client.rs:607:63
    |
607 |             completion::CompletionResponse<super::completion::CompletionResponse>,
    |                                                               ^^^^^^^^^^^^^^^^^^
    |
   ::: packages/provider/src/clients/gemini/gemini_types.rs:398:1
    |
398 | pub struct FunctionResponse {
    | --------------------------- similarly named struct `FunctionResponse` defined here
    |
note: struct `crate::clients::ollama::completion::CompletionResponse` exists but is inaccessible
   --> packages/provider/src/clients/ollama/completion.rs:55:1
    |
55  | pub struct CompletionResponse {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible
help: a struct with a similar name exists
    |
607 -             completion::CompletionResponse<super::completion::CompletionResponse>,
607 +             completion::CompletionResponse<super::completion::FunctionResponse>,
    |
help: consider importing one of these structs
    |
7   + use crate::clients::gemini::client::completion::CompletionResponse;
    |
7   + use crate::clients::mistral::completion::CompletionResponse;
    |
7   + use crate::clients::openrouter::completion::CompletionResponse;
    |
7   + use crate::clients::perplexity::completion::CompletionResponse;
    |
      and 2 other candidates
help: if you import `CompletionResponse`, refer to it directly
    |
607 -             completion::CompletionResponse<super::completion::CompletionResponse>,
607 +             completion::CompletionResponse<CompletionResponse>,
    |

error[E0412]: cannot find type `CompletionError` in this scope
   --> packages/provider/src/clients/gemini/client.rs:608:13
    |
608 |             CompletionError,
    |             ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
    |
40  | pub enum CompletionCoreError {
    | ---------------------------- similarly named enum `CompletionCoreError` defined here
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/client.rs:634:20
    |
634 |             crate::streaming::StreamingCompletionResponse<
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
634 |             crate::candle_core::streaming::StreamingCompletionResponse<
    |                    +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
634 -             crate::streaming::StreamingCompletionResponse<
634 +             streaming::StreamingCompletionResponse<
    |

error[E0412]: cannot find type `CompletionError` in this scope
   --> packages/provider/src/clients/gemini/client.rs:637:13
    |
637 |             CompletionError,
    |             ^^^^^^^^^^^^^^^ help: an enum with a similar name exists: `CompletionCoreError`
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/candle.rs:40:1
    |
40  | pub enum CompletionCoreError {
    | ---------------------------- similarly named enum `CompletionCoreError` defined here
    |
    = note: enum `crate::completion_provider::CompletionError` exists but is inaccessible

error[E0404]: expected trait, found struct `Prompt`
   --> packages/provider/src/clients/gemini/client.rs:662:10
    |
662 | impl<'a> Prompt for GeminiCompletionBuilder<'a, NeedsPrompt> {
    |          ^^^^^^ not a trait

error[E0412]: cannot find type `PromptError` in this scope
   --> packages/provider/src/clients/gemini/client.rs:666:77
    |
666 |     fn prompt(self, prompt: impl ToString) -> Result<Self::PromptedBuilder, PromptError> {
    |                                                                             ^^^^^^^^^^^ not found in this scope
    |
help: you might be missing a type parameter
    |
662 | impl<'a, PromptError> Prompt for GeminiCompletionBuilder<'a, NeedsPrompt> {
    |        +++++++++++++

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/gemini/completion_old.rs:68:6
    |
68  | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
68  - impl CompletionModel {
68  + impl CompletionChunk {
    |
help: consider importing one of these traits
    |
30  + use crate::CompletionModel;
    |
30  + use crate::clients::xai::CompletionModel;
    |
30  + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/gemini/completion_old.rs:77:38
    |
77  | impl completion::CompletionModel for CompletionModel {
    |                                      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
77  - impl completion::CompletionModel for CompletionModel {
77  + impl completion::CompletionModel for CompletionChunk {
    |
help: consider importing one of these traits
    |
30  + use crate::CompletionModel;
    |
30  + use crate::clients::xai::CompletionModel;
    |
30  + use fluent_ai_domain::CompletionModel;
    |

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/gemini/completion_old.rs:93:24
   |
93 |                 crate::runtime::spawn_async(async move {
   |                        ^^^^^^^ unresolved import
   |
help: a similar path exists
   |
93 |                 crate::tokio::runtime::spawn_async(async move {
   |                        +++++++
help: consider importing this module
   |
30 + use tokio::runtime;
   |
help: if you import `runtime`, refer to it directly
   |
93 -                 crate::runtime::spawn_async(async move {
93 +                 runtime::spawn_async(async move {
   |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/completion_old.rs:152:20
    |
152 |             crate::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
152 |             crate::candle_core::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |                    +++++++++++++
help: consider importing one of these modules
    |
30  + use crate::clients::azure::streaming;
    |
30  + use crate::clients::deepseek::streaming;
    |
30  + use crate::clients::gemini::streaming;
    |
30  + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
152 -             crate::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
152 +             streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/completion_old.rs:160:16
    |
160 |         crate::runtime::spawn_async(async move {
    |                ^^^^^^^ unresolved import
    |
help: a similar path exists
    |
160 |         crate::tokio::runtime::spawn_async(async move {
    |                +++++++
help: consider importing this module
    |
30  + use tokio::runtime;
    |
help: if you import `runtime`, refer to it directly
    |
160 -         crate::runtime::spawn_async(async move {
160 +         runtime::spawn_async(async move {
    |

error[E0422]: cannot find struct, variant or union type `CompletionModel` in this scope
   --> packages/provider/src/clients/gemini/completion_old.rs:161:26
    |
161 |             let result = CompletionModel { client, model }
    |                          ^^^^^^^^^^^^^^^ not found in this scope

error[E0412]: cannot find type `ExecutableCode` in this scope
    --> packages/provider/src/clients/gemini/completion_old.rs:1020:24
     |
1020 |         ExecutableCode(ExecutableCode),
     |                        ^^^^^^^^^^^^^^ not found in this scope
     |
help: consider importing one of these structs
     |
847  +     use crate::clients::gemini::gemini_api_types::ExecutableCode;
     |
847  +     use crate::clients::gemini::gemini_types::ExecutableCode;
     |

error[E0412]: cannot find type `CodeExecutionResult` in this scope
    --> packages/provider/src/clients/gemini/completion_old.rs:1021:29
     |
1021 |         CodeExecutionResult(CodeExecutionResult),
     |                             ^^^^^^^^^^^^^^^^^^^
...
1608 |     pub struct CodeExecution {}
     |     ------------------------ similarly named struct `CodeExecution` defined here
     |
help: a struct with a similar name exists
     |
1021 -         CodeExecutionResult(CodeExecutionResult),
1021 +         CodeExecutionResult(CodeExecution),
     |
help: consider importing one of these structs
     |
847  +     use crate::clients::gemini::gemini_api_types::CodeExecutionResult;
     |
847  +     use crate::clients::gemini::gemini_types::CodeExecutionResult;
     |

error[E0412]: cannot find type `EmbeddingModel` in this scope
  --> packages/provider/src/clients/gemini/embedding.rs:36:37
   |
36 | impl embeddings::EmbeddingModel for EmbeddingModel {
   |                                     ^^^^^^^^^^^^^^ not found in this scope
   |
help: consider importing one of these items
   |
6  + use crate::EmbeddingModel;
   |
6  + use crate::domain::EmbeddingModel;
   |
6  + use candle_transformers::models::stella_en_v5::EmbeddingModel;
   |
6  + use fluent_ai_domain::EmbeddingModel;
   |

error[E0412]: cannot find type `ExecutableCode` in this scope
   --> packages/provider/src/clients/gemini/embedding.rs:153:33
    |
153 |         executable_code: Option<ExecutableCode>,
    |                                 ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these structs
    |
112 +     use crate::clients::gemini::gemini_api_types::ExecutableCode;
    |
112 +     use crate::clients::gemini::gemini_types::ExecutableCode;
    |

error[E0412]: cannot find type `CodeExecutionResult` in this scope
   --> packages/provider/src/clients/gemini/embedding.rs:155:39
    |
155 |         code_execution_result: Option<CodeExecutionResult>,
    |                                       ^^^^^^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these structs
    |
112 +     use crate::clients::gemini::gemini_api_types::CodeExecutionResult;
    |
112 +     use crate::clients::gemini::gemini_types::CodeExecutionResult;
    |

error[E0412]: cannot find type `TranscriptionModel` in this scope
  --> packages/provider/src/clients/gemini/transcription.rs:33:6
   |
28 | pub struct GeminiTranscriptionModel {
   | ----------------------------------- similarly named struct `GeminiTranscriptionModel` defined here
...
33 | impl TranscriptionModel {
   |      ^^^^^^^^^^^^^^^^^^ help: a struct with a similar name exists: `GeminiTranscriptionModel`

error[E0412]: cannot find type `TranscriptionModel` in this scope
  --> packages/provider/src/clients/gemini/transcription.rs:42:44
   |
28 | pub struct GeminiTranscriptionModel {
   | ----------------------------------- similarly named struct `GeminiTranscriptionModel` defined here
...
42 | impl transcription::TranscriptionModel for TranscriptionModel {
   |                                            ^^^^^^^^^^^^^^^^^^ help: a struct with a similar name exists: `GeminiTranscriptionModel`

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/gemini/gemini_client.rs:43:6
    |
43  | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
43  - impl CompletionModel {
43  + impl CompletionChunk {
    |
help: consider importing one of these traits
    |
6   + use crate::CompletionModel;
    |
6   + use crate::clients::xai::CompletionModel;
    |
6   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/gemini/gemini_client.rs:52:38
    |
52  | impl completion::CompletionModel for CompletionModel {
    |                                      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
52  - impl completion::CompletionModel for CompletionModel {
52  + impl completion::CompletionModel for CompletionChunk {
    |
help: consider importing one of these traits
    |
6   + use crate::CompletionModel;
    |
6   + use crate::clients::xai::CompletionModel;
    |
6   + use fluent_ai_domain::CompletionModel;
    |

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/gemini/gemini_client.rs:68:24
   |
68 |                 crate::runtime::spawn_async(async move {
   |                        ^^^^^^^ unresolved import
   |
help: a similar path exists
   |
68 |                 crate::tokio::runtime::spawn_async(async move {
   |                        +++++++
help: consider importing this module
   |
6  + use tokio::runtime;
   |
help: if you import `runtime`, refer to it directly
   |
68 -                 crate::runtime::spawn_async(async move {
68 +                 runtime::spawn_async(async move {
   |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/gemini_client.rs:128:20
    |
128 |             crate::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
128 |             crate::candle_core::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |                    +++++++++++++
help: consider importing one of these modules
    |
6   + use crate::clients::azure::streaming;
    |
6   + use crate::clients::deepseek::streaming;
    |
6   + use crate::clients::gemini::streaming;
    |
6   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
128 -             crate::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
128 +             streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/gemini_client.rs:136:16
    |
136 |         crate::runtime::spawn_async(async move {
    |                ^^^^^^^ unresolved import
    |
help: a similar path exists
    |
136 |         crate::tokio::runtime::spawn_async(async move {
    |                +++++++
help: consider importing this module
    |
6   + use tokio::runtime;
    |
help: if you import `runtime`, refer to it directly
    |
136 -         crate::runtime::spawn_async(async move {
136 +         runtime::spawn_async(async move {
    |

error[E0422]: cannot find struct, variant or union type `CompletionModel` in this scope
   --> packages/provider/src/clients/gemini/gemini_client.rs:137:26
    |
137 |             let result = CompletionModel { client, model }
    |                          ^^^^^^^^^^^^^^^ not found in this scope

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/gemini/gemini_client.rs:147:6
    |
147 | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
147 - impl CompletionModel {
147 + impl CompletionChunk {
    |
help: consider importing one of these traits
    |
6   + use crate::CompletionModel;
    |
6   + use crate::clients::xai::CompletionModel;
    |
6   + use fluent_ai_domain::CompletionModel;
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/gemini/gemini_client.rs:152:16
    |
152 |         crate::streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
    |                ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
152 |         crate::candle_core::streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
    |                +++++++++++++
help: consider importing one of these modules
    |
6   + use crate::clients::azure::streaming;
    |
6   + use crate::clients::deepseek::streaming;
    |
6   + use crate::clients::gemini::streaming;
    |
6   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
152 -         crate::streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
152 +         streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
    |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/groq/client.rs:136:34
    |
136 |     ) -> Result<fluent_ai_http3::Response, HttpError> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
136 -     ) -> Result<fluent_ai_http3::Response, HttpError> {
136 +     ) -> Result<Response, HttpError> {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/groq/client.rs:445:20
    |
445 |             crate::streaming::StreamingCompletionResponse<
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
445 |             crate::candle_core::streaming::StreamingCompletionResponse<
    |                    +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::groq::streaming;
    |
      and 5 other candidates
help: if you import `streaming`, refer to it directly
    |
445 -             crate::streaming::StreamingCompletionResponse<
445 +             streaming::StreamingCompletionResponse<
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/groq/completion.rs:187:6
    |
187 | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
187 - impl CompletionModel {
187 + impl CompletionChunk {
    |
help: consider importing one of these traits
    |
7   + use crate::CompletionModel;
    |
7   + use crate::clients::xai::CompletionModel;
    |
7   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/groq/completion.rs:267:38
    |
267 | impl completion::CompletionModel for CompletionModel {
    |                                      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
267 - impl completion::CompletionModel for CompletionModel {
267 + impl completion::CompletionModel for CompletionChunk {
    |
help: consider importing one of these traits
    |
7   + use crate::CompletionModel;
    |
7   + use crate::clients::xai::CompletionModel;
    |
7   + use fluent_ai_domain::CompletionModel;
    |

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/groq/completion.rs:625:35
    |
625 |                 let error_chunk = CompletionChunk {
    |                                   ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0574]: expected struct, variant or union type, found enum `CompletionChunk`
   --> packages/provider/src/clients/groq/completion.rs:798:53
    |
798 | ...                   let mut chunk = CompletionChunk {
    |                                       ^^^^^^^^^^^^^^^ not a struct, variant or union type
    |
note: struct `crate::clients::huggingface::streaming::CompletionChunk` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:56:1
    |
56  | struct CompletionChunk {
    | ^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/groq/streaming.rs:27:16
   |
27 |         crate::streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
   |                ^^^^^^^^^ unresolved import
   |
note: these modules exist but are inaccessible
  --> packages/provider/src/clients/ollama/mod.rs:9:1
   |
9  | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
   |
  ::: packages/provider/src/clients/openai/mod.rs:55:1
   |
55 | mod streaming;
   | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
   |
27 |         crate::candle_core::streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
   |                +++++++++++++
help: consider importing one of these modules
   |
7  + use crate::clients::azure::streaming;
   |
7  + use crate::clients::deepseek::streaming;
   |
7  + use crate::clients::gemini::streaming;
   |
7  + use crate::clients::huggingface::streaming;
   |
     and 4 other candidates
help: if you import `streaming`, refer to it directly
   |
27 -         crate::streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
27 +         streaming::StreamingCompletionResponse<StreamingCompletionResponse>,
   |

error[E0425]: cannot find value `tx` in this scope
  --> packages/provider/src/clients/groq/streaming.rs:68:40
   |
68 | ...                   if tx.try_send(Ok(response)).is_err() {
   |                          ^^ help: a local variable with a similar name exists: `rx`

error[E0425]: cannot find value `tx` in this scope
  --> packages/provider/src/clients/groq/streaming.rs:76:41
   |
76 | ...                   tx.try_send(Err(CompletionError::Internal(e.to_string())));
   |                       ^^ help: a local variable with a similar name exists: `rx`

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/groq/streaming.rs:93:32
   |
93 |         let result = Ok(crate::streaming::StreamingCompletionResponse::new(
   |                                ^^^^^^^^^ unresolved import
   |
help: a similar path exists
   |
93 |         let result = Ok(crate::candle_core::streaming::StreamingCompletionResponse::new(
   |                                +++++++++++++
help: consider importing one of these items
   |
7  + use crate::clients::azure::StreamingCompletionResponse;
   |
7  + use crate::clients::gemini::streaming::StreamingCompletionResponse;
   |
7  + use crate::clients::openrouter::streaming::StreamingCompletionResponse;
   |
7  + use crate::clients::perplexity::streaming::StreamingCompletionResponse;
   |
help: if you import `StreamingCompletionResponse`, refer to it directly
   |
93 -         let result = Ok(crate::streaming::StreamingCompletionResponse::new(
93 +         let result = Ok(StreamingCompletionResponse::new(
   |

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/huggingface/completion.rs:42:12
   |
42 |     crate::model_info::get_model_config(model_name)
   |            ^^^^^^^^^^ unresolved import
   |
note: module `crate::clients::openai::model_info` exists but is inaccessible
  --> packages/provider/src/clients/openai/mod.rs:53:1
   |
53 | mod model_info;
   | ^^^^^^^^^^^^^^^ not accessible
help: a struct with a similar name exists
   |
42 -     crate::model_info::get_model_config(model_name)
42 +     crate::ModelInfo::get_model_config(model_name)
   |
help: a similar path exists
   |
42 |     crate::clients::gemini::model_info::get_model_config(model_name)
   |            +++++++++++++++++
help: consider importing one of these modules
   |
15 + use crate::clients::gemini::model_info;
   |
15 + use crate::clients::mistral::model_info;
   |
help: if you import `model_info`, refer to it directly
   |
42 -     crate::model_info::get_model_config(model_name)
42 +     model_info::get_model_config(model_name)
   |

error[E0412]: cannot find type `TranscriptionModel` in this scope
  --> packages/provider/src/clients/huggingface/transcription.rs:44:6
   |
44 | impl TranscriptionModel {
   |      ^^^^^^^^^^^^^^^^^^ not found in this scope

error[E0412]: cannot find type `TranscriptionModel` in this scope
  --> packages/provider/src/clients/huggingface/transcription.rs:52:44
   |
52 | impl transcription::TranscriptionModel for TranscriptionModel {
   |                                            ^^^^^^^^^^^^^^^^^^ not found in this scope

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/mistral/completion.rs:252:6
    |
252 | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
252 - impl CompletionModel {
252 + impl CompletionChunk {
    |
help: consider importing one of these traits
    |
1   + use crate::CompletionModel;
    |
1   + use crate::clients::xai::CompletionModel;
    |
1   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/mistral/completion.rs:384:38
    |
384 | impl completion::CompletionModel for CompletionModel {
    |                                      ^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:121:1
    |
121 | pub enum CompletionChunk {
    | ------------------------ similarly named enum `CompletionChunk` defined here
    |
help: an enum with a similar name exists
    |
384 - impl completion::CompletionModel for CompletionModel {
384 + impl completion::CompletionModel for CompletionChunk {
    |
help: consider importing one of these traits
    |
1   + use crate::CompletionModel;
    |
1   + use crate::clients::xai::CompletionModel;
    |
1   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `EmbeddingModel` in this scope
  --> packages/provider/src/clients/mistral/embedding.rs:18:6
   |
18 | impl EmbeddingModel {
   |      ^^^^^^^^^^^^^^ not found in this scope
   |
help: consider importing one of these items
   |
1  + use crate::EmbeddingModel;
   |
1  + use crate::domain::EmbeddingModel;
   |
1  + use candle_transformers::models::stella_en_v5::EmbeddingModel;
   |
1  + use fluent_ai_domain::EmbeddingModel;
   |

error[E0412]: cannot find type `EmbeddingModel` in this scope
  --> packages/provider/src/clients/mistral/embedding.rs:28:37
   |
28 | impl embeddings::EmbeddingModel for EmbeddingModel {
   |                                     ^^^^^^^^^^^^^^ not found in this scope
   |
help: consider importing one of these items
   |
1  + use crate::EmbeddingModel;
   |
1  + use crate::domain::EmbeddingModel;
   |
1  + use candle_transformers::models::stella_en_v5::EmbeddingModel;
   |
1  + use fluent_ai_domain::EmbeddingModel;
   |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/mistral/model_info.rs:300:12
    |
300 |     crate::model_info::get_model_config(model_name)
    |            ^^^^^^^^^^ unresolved import
    |
note: module `crate::clients::openai::model_info` exists but is inaccessible
   --> packages/provider/src/clients/openai/mod.rs:53:1
    |
53  | mod model_info;
    | ^^^^^^^^^^^^^^^ not accessible
help: a struct with a similar name exists
    |
300 -     crate::model_info::get_model_config(model_name)
300 +     crate::ModelInfo::get_model_config(model_name)
    |
help: a similar path exists
    |
300 |     crate::clients::gemini::model_info::get_model_config(model_name)
    |            +++++++++++++++++
help: consider importing this module
    |
8   + use crate::clients::gemini::model_info;
    |
help: if you import `model_info`, refer to it directly
    |
300 -     crate::model_info::get_model_config(model_name)
300 +     model_info::get_model_config(model_name)
    |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/ollama/client.rs:141:34
    |
141 |     ) -> Result<fluent_ai_http3::Response> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
141 -     ) -> Result<fluent_ai_http3::Response> {
141 +     ) -> Result<Response> {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/ollama/client.rs:479:20
    |
479 |             crate::streaming::StreamingCompletionResponse<
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
479 |             crate::candle_core::streaming::StreamingCompletionResponse<
    |                    +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::huggingface::streaming;
    |
      and 5 other candidates
help: if you import `streaming`, refer to it directly
    |
479 -             crate::streaming::StreamingCompletionResponse<
479 +             streaming::StreamingCompletionResponse<
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/ollama/completion.rs:138:6
    |
138 | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these traits
    |
7   + use crate::CompletionModel;
    |
7   + use crate::clients::xai::CompletionModel;
    |
7   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/ollama/completion.rs:204:38
    |
204 | impl completion::CompletionModel for CompletionModel {
    |                                      ^^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these traits
    |
7   + use crate::CompletionModel;
    |
7   + use crate::clients::xai::CompletionModel;
    |
7   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/ollama/completion.rs:299:6
    |
299 | impl EmbeddingModel {
    |      ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
7   + use crate::EmbeddingModel;
    |
7   + use crate::domain::EmbeddingModel;
    |
7   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
7   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/ollama/completion.rs:336:30
    |
336 | impl EmbeddingModelTrait for EmbeddingModel {
    |                              ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
7   + use crate::EmbeddingModel;
    |
7   + use crate::domain::EmbeddingModel;
    |
7   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
7   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0433]: failed to resolve: unresolved import
  --> packages/provider/src/clients/ollama/streaming.rs:42:12
   |
42 |     crate::runtime::spawn_async(async move {
   |            ^^^^^^^ unresolved import
   |
help: a similar path exists
   |
42 |     crate::tokio::runtime::spawn_async(async move {
   |            +++++++
help: consider importing this module
   |
7  + use tokio::runtime;
   |
help: if you import `runtime`, refer to it directly
   |
42 -     crate::runtime::spawn_async(async move {
42 +     runtime::spawn_async(async move {
   |

error[E0574]: expected struct, variant or union type, found enum `ProviderMessage`
   --> packages/provider/src/clients/ollama/streaming.rs:142:16
    |
142 |         delta: ProviderMessage {
    |                ^^^^^^^^^^^^^^^ not a struct, variant or union type

error[E0425]: cannot find function `is_chat_model` in module `models`
   --> packages/provider/src/clients/openai/client.rs:420:29
    |
420 |                 if !models::is_chat_model(model) {
    |                             ^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find value `CHAT_MODELS` in module `models`
   --> packages/provider/src/clients/openai/client.rs:424:33
    |
424 |                         models::CHAT_MODELS,
    |                                 ^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `is_embedding_model` in module `models`
   --> packages/provider/src/clients/openai/client.rs:431:29
    |
431 |                 if !models::is_embedding_model(model) {
    |                             ^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `is_audio_model` in module `models`
   --> packages/provider/src/clients/openai/client.rs:442:29
    |
442 |                 if !models::is_audio_model(model) {
    |                             ^^^^^^^^^^^^^^ not found in `models`
    |
help: consider importing this function
    |
15  + use crate::clients::openai::messages::is_audio_model;
    |
help: if you import `is_audio_model`, refer to it directly
    |
442 -                 if !models::is_audio_model(model) {
442 +                 if !is_audio_model(model) {
    |

error[E0425]: cannot find value `AUDIO_MODELS` in module `models`
   --> packages/provider/src/clients/openai/client.rs:446:33
    |
446 |                           models::AUDIO_MODELS,
    |                                   ^^^^^^^^^^^^ help: a constant with a similar name exists: `ALL_MODELS`
    |
   ::: packages/provider/src/clients/openai/mod.rs:120:5
    |
120 | /     pub const ALL_MODELS: &[&str] = &[
121 | |         GPT_4_1,
122 | |         GPT_4_1_MINI,
123 | |         GPT_4_1_NANO,
...   |
138 | |         TEXT_EMBEDDING_3_SMALL,
139 | |     ];
    | |______- similarly named constant `ALL_MODELS` defined here

error[E0425]: cannot find value `WHISPER_1` in module `models`
   --> packages/provider/src/clients/openai/client.rs:447:33
    |
447 |                         models::WHISPER_1,
    |                                 ^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `is_tts_model` in module `models`
   --> packages/provider/src/clients/openai/client.rs:453:29
    |
453 |                 if !models::is_tts_model(model) {
    |                             ^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find value `TTS_MODELS` in module `models`
   --> packages/provider/src/clients/openai/client.rs:457:33
    |
457 |                           models::TTS_MODELS,
    |                                   ^^^^^^^^^^ help: a constant with a similar name exists: `ALL_MODELS`
    |
   ::: packages/provider/src/clients/openai/mod.rs:120:5
    |
120 | /     pub const ALL_MODELS: &[&str] = &[
121 | |         GPT_4_1,
122 | |         GPT_4_1_MINI,
123 | |         GPT_4_1_NANO,
...   |
138 | |         TEXT_EMBEDDING_3_SMALL,
139 | |     ];
    | |______- similarly named constant `ALL_MODELS` defined here

error[E0425]: cannot find value `TTS_1` in module `models`
   --> packages/provider/src/clients/openai/client.rs:458:33
    |
458 |                         models::TTS_1,
    |                                 ^^^^^ not found in `models`

error[E0425]: cannot find function `is_vision_model` in module `models`
   --> packages/provider/src/clients/openai/client.rs:464:29
    |
464 |                 if !models::is_vision_model(model) {
    |                             ^^^^^^^^^^^^^^^ not found in `models`
    |
help: consider importing this function
    |
15  + use crate::clients::openai::messages::is_vision_model;
    |
help: if you import `is_vision_model`, refer to it directly
    |
464 -                 if !models::is_vision_model(model) {
464 +                 if !is_vision_model(model) {
    |

error[E0425]: cannot find function `is_supported_model` in module `models`
   --> packages/provider/src/clients/openai/client.rs:475:29
    |
475 |                 if !models::is_supported_model(model) {
    |                             ^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `is_supported_model` in module `models`
   --> packages/provider/src/clients/openai/client.rs:492:21
    |
492 |         if !models::is_supported_model(model) {
    |                     ^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `model_family` in module `models`
   --> packages/provider/src/clients/openai/client.rs:504:29
    |
504 |             family: models::model_family(model).unwrap_or("unknown"),
    |                             ^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `model_generation` in module `models`
   --> packages/provider/src/clients/openai/client.rs:505:33
    |
505 |             generation: models::model_generation(model).unwrap_or("unknown"),
    |                                 ^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `context_length` in module `models`
   --> packages/provider/src/clients/openai/client.rs:506:34
    |
506 |             max_context: models::context_length(model),
    |                                  ^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `supports_streaming` in module `models`
   --> packages/provider/src/clients/openai/client.rs:507:41
    |
507 |             supports_streaming: models::supports_streaming(model),
    |                                         ^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `supports_tools` in module `models`
   --> packages/provider/src/clients/openai/client.rs:508:37
    |
508 |             supports_tools: models::supports_tools(model),
    |                                     ^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `supports_vision` in module `models`
   --> packages/provider/src/clients/openai/client.rs:509:38
    |
509 |             supports_vision: models::supports_vision(model),
    |                                      ^^^^^^^^^^^^^^^ not found in `models`
    |
help: consider importing this function
    |
15  + use crate::clients::openai::vision::supports_vision;
    |
help: if you import `supports_vision`, refer to it directly
    |
509 -             supports_vision: models::supports_vision(model),
509 +             supports_vision: supports_vision(model),
    |

error[E0425]: cannot find function `supports_audio` in module `models`
   --> packages/provider/src/clients/openai/client.rs:510:37
    |
510 |             supports_audio: models::supports_audio(model),
    |                                     ^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `temperature_range` in module `models`
   --> packages/provider/src/clients/openai/client.rs:511:40
    |
511 |             temperature_range: models::temperature_range(model),
    |                                        ^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find value `CHAT_COMPLETIONS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:549:57
    |
549 |             EndpointType::ChatCompletions => endpoints::CHAT_COMPLETIONS,
    |                                                         ^^^^^^^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `EMBEDDINGS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:550:52
    |
550 |             EndpointType::Embeddings => endpoints::EMBEDDINGS,
    |                                                    ^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `AUDIO_TRANSCRIPTIONS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:551:60
    |
551 |             EndpointType::AudioTranscription => endpoints::AUDIO_TRANSCRIPTIONS,
    |                                                            ^^^^^^^^^^^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `AUDIO_TRANSLATIONS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:552:58
    |
552 |             EndpointType::AudioTranslation => endpoints::AUDIO_TRANSLATIONS,
    |                                                          ^^^^^^^^^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `AUDIO_SPEECH` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:553:54
    |
553 |             EndpointType::TextToSpeech => endpoints::AUDIO_SPEECH,
    |                                                      ^^^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `CHAT_COMPLETIONS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:554:56
    |
554 |             EndpointType::VisionAnalysis => endpoints::CHAT_COMPLETIONS, /* Vision uses chat completions */
    |                                                        ^^^^^^^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `MODELS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:555:48
    |
555 |             EndpointType::Models => endpoints::MODELS,
    |                                                ^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `FILES` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:556:47
    |
556 |             EndpointType::Files => endpoints::FILES,
    |                                               ^^^^^ not found in `endpoints`

error[E0425]: cannot find value `FINE_TUNING` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:557:52
    |
557 |             EndpointType::FineTuning => endpoints::FINE_TUNING,
    |                                                    ^^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `MODERATIONS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:558:53
    |
558 |             EndpointType::Moderations => endpoints::MODERATIONS,
    |                                                     ^^^^^^^^^^^ not found in `endpoints`

error[E0425]: cannot find value `CHAT_COMPLETIONS` in module `endpoints`
   --> packages/provider/src/clients/openai/client.rs:695:24
    |
695 |             endpoints::CHAT_COMPLETIONS,
    |                        ^^^^^^^^^^^^^^^^ not found in `endpoints`

error[E0433]: failed to resolve: could not find `CredentialSource` in `security`
   --> packages/provider/src/clients/openai/client.rs:870:34
    |
870 |                 crate::security::CredentialSource::Runtime {
    |                                  ^^^^^^^^^^^^^^^^ could not find `CredentialSource` in `security`
    |
help: a struct with a similar name exists
    |
870 -                 crate::security::CredentialSource::Runtime {
870 +                 crate::security::CredentialConfig::Runtime {
    |
help: consider importing this enum
    |
15  + use crate::security::credentials::CredentialSource;
    |
help: if you import `CredentialSource`, refer to it directly
    |
870 -                 crate::security::CredentialSource::Runtime {
870 +                 CredentialSource::Runtime {
    |

error[E0412]: cannot find type `CredentialStatistics` in module `crate::security`
   --> packages/provider/src/clients/openai/client.rs:892:73
    |
892 |     pub async fn get_credential_statistics() -> Result<crate::security::CredentialStatistics> {
    |                                                                         ^^^^^^^^^^^^^^^^^^^^ not found in `crate::security`
    |
help: consider importing this struct
    |
15  + use crate::security::credentials::CredentialStatistics;
    |
help: if you import `CredentialStatistics`, refer to it directly
    |
892 -     pub async fn get_credential_statistics() -> Result<crate::security::CredentialStatistics> {
892 +     pub async fn get_credential_statistics() -> Result<CredentialStatistics> {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/openai/model_info.rs:115:12
    |
115 |     crate::model_info::get_model_config(model_name)
    |            ^^^^^^^^^^ unresolved import
    |
help: a struct with a similar name exists
    |
115 -     crate::model_info::get_model_config(model_name)
115 +     crate::ModelInfo::get_model_config(model_name)
    |
help: a similar path exists
    |
115 |     crate::clients::gemini::model_info::get_model_config(model_name)
    |            +++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::clients::gemini::model_info;
    |
6   + use crate::clients::mistral::model_info;
    |
help: if you import `model_info`, refer to it directly
    |
115 -     crate::model_info::get_model_config(model_name)
115 +     model_info::get_model_config(model_name)
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/openai/moderation.rs:620:12
    |
620 |     crate::async_task::spawn_async(async move {
    |            ^^^^^^^^^^ unresolved import
    |
help: a type alias with a similar name exists
    |
620 -     crate::async_task::spawn_async(async move {
620 +     crate::AsyncTask::spawn_async(async move {
    |
help: a similar path exists
    |
620 |     crate::fluent_ai_domain::async_task::spawn_async(async move {
    |            ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::domain::async_task;
    |
6   + use fluent_ai_domain::async_task;
    |
help: if you import `async_task`, refer to it directly
    |
620 -     crate::async_task::spawn_async(async move {
620 +     async_task::spawn_async(async move {
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/openai/streaming.rs:486:44
    |
486 |                 let messages_call = crate::providers::openai::messages::OpenAIToolCall {
    |                                            ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
6   + use crate::clients::openai::messages;
    |
help: if you import `messages`, refer to it directly
    |
486 -                 let messages_call = crate::providers::openai::messages::OpenAIToolCall {
486 +                 let messages_call = messages::OpenAIToolCall {
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/openai/streaming.rs:489:38
    |
489 |                     function: crate::providers::openai::messages::OpenAIFunctionCall {
    |                                      ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
6   + use crate::clients::openai::messages;
    |
help: if you import `messages`, refer to it directly
    |
489 -                     function: crate::providers::openai::messages::OpenAIFunctionCall {
489 +                     function: messages::OpenAIFunctionCall {
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/openai/streaming.rs:500:40
    |
500 |                     .map(|call| crate::providers::openai::messages::OpenAIToolCall {
    |                                        ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
6   + use crate::clients::openai::messages;
    |
help: if you import `messages`, refer to it directly
    |
500 -                     .map(|call| crate::providers::openai::messages::OpenAIToolCall {
500 +                     .map(|call| messages::OpenAIToolCall {
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/openai/streaming.rs:503:42
    |
503 |                         function: crate::providers::openai::messages::OpenAIFunctionCall {
    |                                          ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
6   + use crate::clients::openai::messages;
    |
help: if you import `messages`, refer to it directly
    |
503 -                         function: crate::providers::openai::messages::OpenAIFunctionCall {
503 +                         function: messages::OpenAIFunctionCall {
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/openai/streaming.rs:518:29
    |
518 |                 Some(crate::providers::openai::OpenAIContent::Text(
    |                             ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this enum
    |
6   + use crate::clients::openai::messages::OpenAIContent;
    |
help: if you import `OpenAIContent`, refer to it directly
    |
518 -                 Some(crate::providers::openai::OpenAIContent::Text(
518 +                 Some(OpenAIContent::Text(
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/openai/streaming.rs:526:24
    |
526 |                 crate::providers::openai::messages::OpenAIFunctionCall {
    |                        ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
6   + use crate::clients::openai::messages;
    |
help: if you import `messages`, refer to it directly
    |
526 -                 crate::providers::openai::messages::OpenAIFunctionCall {
526 +                 messages::OpenAIFunctionCall {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/openai/streaming.rs:711:12
    |
711 |     crate::async_task::spawn_async(async move {
    |            ^^^^^^^^^^ unresolved import
    |
help: a type alias with a similar name exists
    |
711 -     crate::async_task::spawn_async(async move {
711 +     crate::AsyncTask::spawn_async(async move {
    |
help: a similar path exists
    |
711 |     crate::fluent_ai_domain::async_task::spawn_async(async move {
    |            ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::domain::async_task;
    |
6   + use fluent_ai_domain::async_task;
    |
help: if you import `async_task`, refer to it directly
    |
711 -     crate::async_task::spawn_async(async move {
711 +     async_task::spawn_async(async move {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/openai/streaming.rs:754:12
    |
754 |     crate::async_task::spawn_async(async move {
    |            ^^^^^^^^^^ unresolved import
    |
help: a type alias with a similar name exists
    |
754 -     crate::async_task::spawn_async(async move {
754 +     crate::AsyncTask::spawn_async(async move {
    |
help: a similar path exists
    |
754 |     crate::fluent_ai_domain::async_task::spawn_async(async move {
    |            ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::domain::async_task;
    |
6   + use fluent_ai_domain::async_task;
    |
help: if you import `async_task`, refer to it directly
    |
754 -     crate::async_task::spawn_async(async move {
754 +     async_task::spawn_async(async move {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/openai/streaming.rs:809:12
    |
809 |     crate::async_task::spawn_async(async move {
    |            ^^^^^^^^^^ unresolved import
    |
help: a type alias with a similar name exists
    |
809 -     crate::async_task::spawn_async(async move {
809 +     crate::AsyncTask::spawn_async(async move {
    |
help: a similar path exists
    |
809 |     crate::fluent_ai_domain::async_task::spawn_async(async move {
    |            ++++++++++++++++++
help: consider importing one of these modules
    |
6   + use crate::domain::async_task;
    |
6   + use fluent_ai_domain::async_task;
    |
help: if you import `async_task`, refer to it directly
    |
809 -     crate::async_task::spawn_async(async move {
809 +     async_task::spawn_async(async move {
    |

error[E0573]: expected type, found module `models`
   --> packages/provider/src/clients/openai/mod.rs:296:6
    |
296 | impl models {
    |      ^^^^^^ not a type

error[E0425]: cannot find function `is_embedding_model` in module `models`
   --> packages/provider/src/clients/openai/mod.rs:504:20
    |
504 |         if models::is_embedding_model(model) {
    |                    ^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `cost_tier` in module `models`
   --> packages/provider/src/clients/openai/mod.rs:623:17
    |
623 |         models::cost_tier(model)
    |                 ^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `supports_vision` in module `models`
   --> packages/provider/src/clients/openai/mod.rs:647:33
    |
647 |             "vision" => models::supports_vision(model),
    |                                 ^^^^^^^^^^^^^^^ not found in `models`
    |
help: consider importing this function
    |
565 +     use crate::clients::openai::vision::supports_vision;
    |
help: if you import `supports_vision`, refer to it directly
    |
647 -             "vision" => models::supports_vision(model),
647 +             "vision" => supports_vision(model),
    |

error[E0425]: cannot find function `supports_function_calling` in module `models`
   --> packages/provider/src/clients/openai/mod.rs:648:43
    |
648 |             "function_calling" => models::supports_function_calling(model),
    |                                           ^^^^^^^^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `supports_streaming` in module `models`
   --> packages/provider/src/clients/openai/mod.rs:649:36
    |
649 |             "streaming" => models::supports_streaming(model),
    |                                    ^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0425]: cannot find function `is_embedding_model` in module `models`
   --> packages/provider/src/clients/openai/mod.rs:650:36
    |
650 |             "embedding" => models::is_embedding_model(model),
    |                                    ^^^^^^^^^^^^^^^^^^ not found in `models`

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/openrouter/client.rs:160:34
    |
160 |     ) -> Result<fluent_ai_http3::Response> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
160 -     ) -> Result<fluent_ai_http3::Response> {
160 +     ) -> Result<Response> {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/openrouter/client.rs:504:20
    |
504 |             crate::streaming::StreamingCompletionResponse<
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
504 |             crate::candle_core::streaming::StreamingCompletionResponse<
    |                    +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
504 -             crate::streaming::StreamingCompletionResponse<
504 +             streaming::StreamingCompletionResponse<
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/openrouter/completion.rs:122:6
    |
122 | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these traits
    |
1   + use crate::CompletionModel;
    |
1   + use crate::clients::xai::CompletionModel;
    |
1   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/openrouter/completion.rs:176:38
    |
176 | impl completion::CompletionModel for CompletionModel {
    |                                      ^^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these traits
    |
1   + use crate::CompletionModel;
    |
1   + use crate::clients::xai::CompletionModel;
    |
1   + use fluent_ai_domain::CompletionModel;
    |

error[E0433]: failed to resolve: use of undeclared type `CompletionModel`
   --> packages/provider/src/clients/openrouter/completion.rs:216:9
    |
216 |         CompletionModel::stream(self, completion_request).await
    |         ^^^^^^^^^^^^^^^ use of undeclared type `CompletionModel`
    |
help: consider importing one of these traits
    |
1   + use crate::CompletionModel;
    |
1   + use crate::clients::xai::CompletionModel;
    |
1   + use fluent_ai_domain::CompletionModel;
    |

error[E0412]: cannot find type `AtomicUsize` in this scope
   --> packages/provider/src/clients/openrouter/streaming.rs:761:21
    |
761 |     current_window: AtomicUsize,
    |                     ^^^^^^^^^^^ not found in this scope
    |
    = note: struct `crate::image_processing::factory::batch_processing::AtomicUsize` exists but is inaccessible
help: consider importing this struct
    |
14  + use std::sync::atomic::AtomicUsize;
    |

error[E0433]: failed to resolve: use of undeclared type `AtomicUsize`
    --> packages/provider/src/clients/openrouter/streaming.rs:1231:29
     |
1231 |             current_window: AtomicUsize::new(0),
     |                             ^^^^^^^^^^^ use of undeclared type `AtomicUsize`
     |
     = note: struct `crate::image_processing::factory::batch_processing::AtomicUsize` exists but is inaccessible
help: consider importing this struct
     |
14   + use std::sync::atomic::AtomicUsize;
     |

error[E0412]: cannot find type `AtomicUsize` in this scope
    --> packages/provider/src/clients/openrouter/streaming.rs:1395:17
     |
1395 |     cache_size: AtomicUsize,
     |                 ^^^^^^^^^^^ not found in this scope
     |
     = note: struct `crate::image_processing::factory::batch_processing::AtomicUsize` exists but is inaccessible
help: consider importing this struct
     |
14   + use std::sync::atomic::AtomicUsize;
     |

error[E0433]: failed to resolve: use of undeclared type `AtomicUsize`
    --> packages/provider/src/clients/openrouter/streaming.rs:1761:25
     |
1761 |             cache_size: AtomicUsize::new(0),
     |                         ^^^^^^^^^^^ use of undeclared type `AtomicUsize`
     |
     = note: struct `crate::image_processing::factory::batch_processing::AtomicUsize` exists but is inaccessible
help: consider importing this struct
     |
14   + use std::sync::atomic::AtomicUsize;
     |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/perplexity/client.rs:144:34
    |
144 |     ) -> Result<fluent_ai_http3::Response, HttpError> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
144 -     ) -> Result<fluent_ai_http3::Response, HttpError> {
144 +     ) -> Result<Response, HttpError> {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/perplexity/client.rs:491:20
    |
491 |             crate::streaming::StreamingCompletionResponse<
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
491 |             crate::candle_core::streaming::StreamingCompletionResponse<
    |                    +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
491 -             crate::streaming::StreamingCompletionResponse<
491 +             streaming::StreamingCompletionResponse<
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/perplexity/client.rs:492:24
    |
492 |                 crate::providers::openai::StreamingCompletionResponse,
    |                        ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
7   + use crate::clients::openai;
    |
help: if you import `openai`, refer to it directly
    |
492 -                 crate::providers::openai::StreamingCompletionResponse,
492 +                 openai::StreamingCompletionResponse,
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/perplexity/completion.rs:107:6
    |
107 | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these traits
    |
7   + use crate::CompletionModel;
    |
7   + use crate::clients::xai::CompletionModel;
    |
7   + use fluent_ai_domain::CompletionModel;
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/perplexity/completion.rs:163:25
    |
163 |     type Error = crate::completion::MessageError;
    |                         ^^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
help: a similar path exists
    |
163 |     type Error = crate::fluent_ai_domain::completion::MessageError;
    |                         ++++++++++++++++++
help: consider importing this module
    |
7   + use crate::clients::azure::completion;
    |
help: if you import `completion`, refer to it directly
    |
163 -     type Error = crate::completion::MessageError;
163 +     type Error = completion::MessageError;
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/perplexity/completion.rs:172:41
    |
172 |                         _ => Err(crate::completion::MessageError::ConversionError(
    |                                         ^^^^^^^^^^ unresolved import
    |
help: a similar path exists
    |
172 |                         _ => Err(crate::fluent_ai_domain::completion::MessageError::ConversionError(
    |                                         ++++++++++++++++++
help: consider importing one of these enums
    |
7   + use crate::domain::MessageError;
    |
7   + use fluent_ai_domain::MessageError;
    |
help: if you import `MessageError`, refer to it directly
    |
172 -                         _ => Err(crate::completion::MessageError::ConversionError(
172 +                         _ => Err(MessageError::ConversionError(
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/perplexity/completion.rs:191:52
    |
191 | ...                   _ => return Err(crate::completion::MessageError::ConversionError(
    |                                              ^^^^^^^^^^ unresolved import
    |
help: a similar path exists
    |
191 |                             _ => return Err(crate::fluent_ai_domain::completion::MessageError::ConversionError(
    |                                                    ++++++++++++++++++
help: consider importing one of these enums
    |
7   + use crate::domain::MessageError;
    |
7   + use fluent_ai_domain::MessageError;
    |
help: if you import `MessageError`, refer to it directly
    |
191 -                             _ => return Err(crate::completion::MessageError::ConversionError(
191 +                             _ => return Err(MessageError::ConversionError(
    |

error[E0412]: cannot find type `CompletionModel` in this scope
   --> packages/provider/src/clients/perplexity/completion.rs:222:38
    |
222 | impl completion::CompletionModel for CompletionModel {
    |                                      ^^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these traits
    |
7   + use crate::CompletionModel;
    |
7   + use crate::clients::xai::CompletionModel;
    |
7   + use fluent_ai_domain::CompletionModel;
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/perplexity/completion.rs:224:37
    |
224 |     type StreamingResponse = crate::providers::openai::StreamingCompletionResponse;
    |                                     ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
7   + use crate::clients::openai;
    |
help: if you import `openai`, refer to it directly
    |
224 -     type StreamingResponse = crate::providers::openai::StreamingCompletionResponse;
224 +     type StreamingResponse = openai::StreamingCompletionResponse;
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/perplexity/completion.rs:266:16
    |
266 |         crate::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |                ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
266 |         crate::candle_core::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |                +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
266 -         crate::streaming::StreamingCompletionResponse<Self::StreamingResponse>,
266 +         streaming::StreamingCompletionResponse<Self::StreamingResponse>,
    |

error[E0433]: failed to resolve: could not find `providers` in the crate root
   --> packages/provider/src/clients/perplexity/completion.rs:275:16
    |
275 |         crate::providers::openai::send_compatible_streaming_request(builder).await
    |                ^^^^^^^^^ could not find `providers` in the crate root
    |
help: consider importing this module
    |
7   + use crate::clients::openai;
    |
help: if you import `openai`, refer to it directly
    |
275 -         crate::providers::openai::send_compatible_streaming_request(builder).await
275 +         openai::send_compatible_streaming_request(builder).await
    |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/together/client.rs:156:34
    |
156 |     ) -> Result<fluent_ai_http3::Response, HttpError> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
156 -     ) -> Result<fluent_ai_http3::Response, HttpError> {
156 +     ) -> Result<Response, HttpError> {
    |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/together/client.rs:171:34
    |
171 |     ) -> Result<fluent_ai_http3::Response, HttpError> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
171 -     ) -> Result<fluent_ai_http3::Response, HttpError> {
171 +     ) -> Result<Response, HttpError> {
    |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/together/client.rs:188:34
    |
188 |     ) -> Result<fluent_ai_http3::Response, HttpError> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
188 -     ) -> Result<fluent_ai_http3::Response, HttpError> {
188 +     ) -> Result<Response, HttpError> {
    |

error[E0412]: cannot find type `CompletionResponse` in module `super::completion`
   --> packages/provider/src/clients/together/client.rs:561:63
    |
561 |             completion::CompletionResponse<super::completion::CompletionResponse>,
    |                                                               ^^^^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/request.rs:18:1
    |
18  | pub struct CompletionRequest<'a> {
    | -------------------------------- similarly named struct `CompletionRequest` defined here
    |
note: struct `crate::clients::ollama::completion::CompletionResponse` exists but is inaccessible
   --> packages/provider/src/clients/ollama/completion.rs:55:1
    |
55  | pub struct CompletionResponse {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible
help: a struct with a similar name exists
    |
561 -             completion::CompletionResponse<super::completion::CompletionResponse>,
561 +             completion::CompletionResponse<super::completion::CompletionRequest>,
    |
help: consider importing one of these structs
    |
7   + use crate::clients::mistral::completion::CompletionResponse;
    |
7   + use crate::clients::openrouter::completion::CompletionResponse;
    |
7   + use crate::clients::perplexity::completion::CompletionResponse;
    |
7   + use crate::clients::xai::completion::xai_api_types::CompletionResponse;
    |
      and 2 other candidates
help: if you import `CompletionResponse`, refer to it directly
    |
561 -             completion::CompletionResponse<super::completion::CompletionResponse>,
561 +             completion::CompletionResponse<CompletionResponse>,
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/together/client.rs:588:20
    |
588 |             crate::streaming::StreamingCompletionResponse<super::completion::CompletionResponse>,
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
588 |             crate::candle_core::streaming::StreamingCompletionResponse<super::completion::CompletionResponse>,
    |                    +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
588 -             crate::streaming::StreamingCompletionResponse<super::completion::CompletionResponse>,
588 +             streaming::StreamingCompletionResponse<super::completion::CompletionResponse>,
    |

error[E0412]: cannot find type `CompletionResponse` in module `super::completion`
   --> packages/provider/src/clients/together/client.rs:588:78
    |
588 |             crate::streaming::StreamingCompletionResponse<super::completion::CompletionResponse>,
    |                                                                              ^^^^^^^^^^^^^^^^^^
    |
   ::: /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/request.rs:18:1
    |
18  | pub struct CompletionRequest<'a> {
    | -------------------------------- similarly named struct `CompletionRequest` defined here
    |
note: struct `crate::clients::ollama::completion::CompletionResponse` exists but is inaccessible
   --> packages/provider/src/clients/ollama/completion.rs:55:1
    |
55  | pub struct CompletionResponse {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible
help: a struct with a similar name exists
    |
588 -             crate::streaming::StreamingCompletionResponse<super::completion::CompletionResponse>,
588 +             crate::streaming::StreamingCompletionResponse<super::completion::CompletionRequest>,
    |
help: consider importing one of these structs
    |
7   + use crate::clients::mistral::completion::CompletionResponse;
    |
7   + use crate::clients::openrouter::completion::CompletionResponse;
    |
7   + use crate::clients::perplexity::completion::CompletionResponse;
    |
7   + use crate::clients::xai::completion::xai_api_types::CompletionResponse;
    |
      and 2 other candidates
help: if you import `CompletionResponse`, refer to it directly
    |
588 -             crate::streaming::StreamingCompletionResponse<super::completion::CompletionResponse>,
588 +             crate::streaming::StreamingCompletionResponse<CompletionResponse>,
    |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/together/completion.rs:147:29
    |
147 |         completion_request: completion::CompletionRequest,
    |                             ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/bedrock/mod.rs:45:1
    |
45  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
    |
   ::: packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
help: to make use of source file packages/provider/src/clients/together/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
6   + use crate::clients::azure::completion;
    |
6   + use crate::clients::mistral::completion;
    |
6   + use crate::clients::openrouter::completion;
    |
6   + use crate::clients::perplexity::completion;
    |
      and 3 other candidates

error[E0433]: failed to resolve: could not find `ToolDefinition` in `openai`
   --> packages/provider/src/clients/together/completion.rs:179:75
    |
179 |                 "tools": completion_request.tools.into_iter().map(openai::ToolDefinition::from).collect::<Vec<_>>(),
    |                                                                           ^^^^^^^^^^^^^^ could not find `ToolDefinition` in `openai`
    |
note: struct `crate::clients::ollama::completion::ToolDefinition` exists but is inaccessible
   --> packages/provider/src/clients/ollama/completion.rs:403:1
    |
403 | pub struct ToolDefinition {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible
help: consider importing one of these items
    |
6   + use crate::clients::xai::completion::xai_api_types::ToolDefinition;
    |
6   + use crate::domain::ToolDefinition;
    |
6   + use crate::domain::completion::ToolDefinition;
    |
6   + use fluent_ai_domain::ToolDefinition;
    |
      and 1 other candidate
help: if you import `ToolDefinition`, refer to it directly
    |
179 -                 "tools": completion_request.tools.into_iter().map(openai::ToolDefinition::from).collect::<Vec<_>>(),
179 +                 "tools": completion_request.tools.into_iter().map(ToolDefinition::from).collect::<Vec<_>>(),
    |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/together/completion.rs:192:6
    |
192 | impl completion::CompletionModel for TogetherCompletionModel {
    |      ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
help: to make use of source file packages/provider/src/clients/together/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
6   + use crate::clients::azure::completion;
    |
6   + use crate::clients::gemini::completion;
    |
6   + use crate::clients::huggingface::completion;
    |
6   + use crate::clients::mistral::completion;
    |
      and 5 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/together/completion.rs:199:29
    |
199 |         completion_request: completion::CompletionRequest,
    |                             ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/bedrock/mod.rs:45:1
    |
45  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
    |
   ::: packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
help: to make use of source file packages/provider/src/clients/together/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
6   + use crate::clients::azure::completion;
    |
6   + use crate::clients::mistral::completion;
    |
6   + use crate::clients::openrouter::completion;
    |
6   + use crate::clients::perplexity::completion;
    |
      and 3 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/together/completion.rs:200:17
    |
200 |     ) -> Result<completion::CompletionResponse<openai::CompletionResponse>, CompletionError> {
    |                 ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/bedrock/mod.rs:45:1
    |
45  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
    |
   ::: packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: to make use of source file packages/provider/src/clients/together/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
6   + use crate::clients::azure::completion;
    |
6   + use crate::clients::gemini::completion;
    |
6   + use crate::clients::mistral::completion;
    |
6   + use crate::clients::openrouter::completion;
    |
      and 4 other candidates

error[E0412]: cannot find type `EmbeddingModel` in this scope
  --> packages/provider/src/clients/together/embedding.rs:64:37
   |
64 | impl embeddings::EmbeddingModel for EmbeddingModel {
   |                                     ^^^^^^^^^^^^^^ not found in this scope
   |
help: consider importing one of these items
   |
6  + use crate::EmbeddingModel;
   |
6  + use crate::domain::EmbeddingModel;
   |
6  + use candle_transformers::models::stella_en_v5::EmbeddingModel;
   |
6  + use fluent_ai_domain::EmbeddingModel;
   |

error[E0412]: cannot find type `EmbeddingModel` in this scope
   --> packages/provider/src/clients/together/embedding.rs:128:6
    |
128 | impl EmbeddingModel {
    |      ^^^^^^^^^^^^^^ not found in this scope
    |
help: consider importing one of these items
    |
6   + use crate::EmbeddingModel;
    |
6   + use crate::domain::EmbeddingModel;
    |
6   + use candle_transformers::models::stella_en_v5::EmbeddingModel;
    |
6   + use fluent_ai_domain::EmbeddingModel;
    |

error[E0412]: cannot find type `Response` in crate `fluent_ai_http3`
   --> packages/provider/src/clients/xai/client.rs:173:34
    |
173 |     ) -> Result<fluent_ai_http3::Response> {
    |                                  ^^^^^^^^ not found in `fluent_ai_http3`
    |
help: consider importing one of these structs
    |
7   + use http::Response;
    |
7   + use reqwest::Response;
    |
help: if you import `Response`, refer to it directly
    |
173 -     ) -> Result<fluent_ai_http3::Response> {
173 +     ) -> Result<Response> {
    |

error[E0433]: failed to resolve: unresolved import
   --> packages/provider/src/clients/xai/client.rs:519:20
    |
519 |             crate::streaming::StreamingCompletionResponse<
    |                    ^^^^^^^^^ unresolved import
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::groq::streaming`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:9:1
    |
9   | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::ollama::streaming`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:55:1
    |
55  | mod streaming;
    | ^^^^^^^^^^^^^^ `crate::clients::openai::streaming`: not accessible
help: a similar path exists
    |
519 |             crate::candle_core::streaming::StreamingCompletionResponse<
    |                    +++++++++++++
help: consider importing one of these modules
    |
7   + use crate::clients::azure::streaming;
    |
7   + use crate::clients::deepseek::streaming;
    |
7   + use crate::clients::gemini::streaming;
    |
7   + use crate::clients::huggingface::streaming;
    |
      and 4 other candidates
help: if you import `streaming`, refer to it directly
    |
519 -             crate::streaming::StreamingCompletionResponse<
519 +             streaming::StreamingCompletionResponse<
    |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:106:6
    |
106 | impl completion::CompletionModel for XaiCompletionModel {
    |      ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
6   + use crate::clients::azure::completion;
    |
6   + use crate::clients::gemini::completion;
    |
6   + use crate::clients::huggingface::completion;
    |
6   + use crate::clients::mistral::completion;
    |
      and 5 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:114:17
    |
114 |     ) -> Result<completion::CompletionResponse<CompletionResponse>, CompletionError> {
    |                 ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/bedrock/mod.rs:45:1
    |
45  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
    |
   ::: packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
6   + use crate::clients::azure::completion;
    |
6   + use crate::clients::gemini::completion;
    |
6   + use crate::clients::mistral::completion;
    |
6   + use crate::clients::openrouter::completion;
    |
      and 4 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:150:42
    |
150 |     impl TryFrom<CompletionResponse> for completion::CompletionResponse {
    |                                          ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/bedrock/mod.rs:45:1
    |
45  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
    |
   ::: packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
144 +     use crate::clients::azure::completion;
    |
144 +     use crate::clients::gemini::completion;
    |
144 +     use crate::clients::mistral::completion;
    |
144 +     use crate::clients::openrouter::completion;
    |
      and 5 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:167:33
    |
167 | ...                   completion::AssistantContent::text(text)
    |                       ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: enum `crate::clients::huggingface::streaming::AssistantContent` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:23:1
    |
23  | enum AssistantContent {
    | ^^^^^^^^^^^^^^^^^^^^^ not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these items
    |
144 +     use crate::clients::mistral::completion::AssistantContent;
    |
144 +     use crate::clients::openai::AssistantContent;
    |
144 +     use crate::domain::AssistantContent;
    |
144 +     use fluent_ai_domain::AssistantContent;
    |
help: if you import `AssistantContent`, refer to it directly
    |
167 -                                 completion::AssistantContent::text(text)
167 +                                 AssistantContent::text(text)
    |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:170:33
    |
170 | ...                   completion::AssistantContent::text(refusal)
    |                       ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: enum `crate::clients::huggingface::streaming::AssistantContent` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:23:1
    |
23  | enum AssistantContent {
    | ^^^^^^^^^^^^^^^^^^^^^ not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these items
    |
144 +     use crate::clients::mistral::completion::AssistantContent;
    |
144 +     use crate::clients::openai::AssistantContent;
    |
144 +     use crate::domain::AssistantContent;
    |
144 +     use fluent_ai_domain::AssistantContent;
    |
help: if you import `AssistantContent`, refer to it directly
    |
170 -                                 completion::AssistantContent::text(refusal)
170 +                                 AssistantContent::text(refusal)
    |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:179:33
    |
179 | ...                   completion::AssistantContent::tool_call(
    |                       ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: enum `crate::clients::huggingface::streaming::AssistantContent` exists but is inaccessible
   --> packages/provider/src/clients/huggingface/streaming.rs:23:1
    |
23  | enum AssistantContent {
    | ^^^^^^^^^^^^^^^^^^^^^ not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these items
    |
144 +     use crate::clients::mistral::completion::AssistantContent;
    |
144 +     use crate::clients::openai::AssistantContent;
    |
144 +     use crate::domain::AssistantContent;
    |
144 +     use fluent_ai_domain::AssistantContent;
    |
help: if you import `AssistantContent`, refer to it directly
    |
179 -                                 completion::AssistantContent::tool_call(
179 +                                 AssistantContent::tool_call(
    |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:200:16
    |
200 |             Ok(completion::CompletionResponse {
    |                ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/bedrock/mod.rs:45:1
    |
45  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::bedrock::completion`: not accessible
    |
   ::: packages/provider/src/clients/groq/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::groq::completion`: not accessible
    |
   ::: packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
144 +     use crate::clients::azure::completion;
    |
144 +     use crate::clients::gemini::completion;
    |
144 +     use crate::clients::mistral::completion;
    |
144 +     use crate::clients::openrouter::completion;
    |
      and 5 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:207:15
    |
207 |     impl From<completion::ToolDefinition> for ToolDefinition {
    |               ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
144 +     use crate::clients::anthropic::completion;
    |
144 +     use crate::clients::deepseek::completion;
    |
144 +     use crate::clients::huggingface::completion;
    |
144 +     use crate::clients::mistral::completion;
    |
      and 3 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:208:23
    |
208 |         fn from(tool: completion::ToolDefinition) -> Self {
    |                       ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
144 +     use crate::clients::anthropic::completion;
    |
144 +     use crate::clients::deepseek::completion;
    |
144 +     use crate::clients::huggingface::completion;
    |
144 +     use crate::clients::mistral::completion;
    |
      and 3 other candidates

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `completion`
   --> packages/provider/src/clients/xai/completion.rs:219:23
    |
219 |         pub function: completion::ToolDefinition,
    |                       ^^^^^^^^^^ use of unresolved module or unlinked crate `completion`
    |
note: these modules exist but are inaccessible
   --> packages/provider/src/clients/ollama/mod.rs:8:1
    |
8   | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::ollama::completion`: not accessible
    |
   ::: packages/provider/src/clients/openai/mod.rs:48:1
    |
48  | mod completion;
    | ^^^^^^^^^^^^^^^ `crate::clients::openai::completion`: not accessible
help: to make use of source file packages/provider/src/clients/xai/completion.rs, use `mod completion` in this file to declare the module
   --> packages/provider/src/lib.rs:7:1
    |
7   + mod completion;
    |
help: consider importing one of these modules
    |
144 +     use crate::clients::anthropic::completion;
    |
144 +     use crate::clients::deepseek::completion;
    |
144 +     use crate::clients::huggingface::completion;
    |
144 +     use crate::clients::mistral::completion;
    |
      and 3 other candidates

error[E0412]: cannot find type `OpenAIEmbeddingRequest` in module `openai`
   --> packages/provider/src/client_factory.rs:242:44
    |
242 |             let embedding_request: openai::OpenAIEmbeddingRequest =
    |                                            ^^^^^^^^^^^^^^^^^^^^^^ not found in `openai`
    |
note: struct `crate::client_factory::openai::embeddings::OpenAIEmbeddingRequest` exists but is inaccessible
   --> packages/provider/src/clients/openai/embeddings.rs:13:1
    |
13  | pub struct OpenAIEmbeddingRequest {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ not accessible

error[E0425]: cannot find function `serialize` in crate `bincode`
   --> packages/provider/src/security/encryption.rs:212:22
    |
212 |             bincode::serialize(&encrypted_data).map_err(|e| SecurityError::EncryptionError {
    |                      ^^^^^^^^^ not found in `bincode`

error[E0425]: cannot find function `deserialize` in crate `bincode`
   --> packages/provider/src/security/encryption.rs:233:22
    |
233 |             bincode::deserialize(&serialized).map_err(|e| SecurityError::EncryptionError {
    |                      ^^^^^^^^^^^ not found in `bincode`

error[E0404]: expected trait, found type alias `AsyncTask`
  --> packages/provider/src/client.rs:73:18
   |
73 |     ) -> Box<dyn AsyncTask<Result<Box<dyn AsyncStream<Self::StreamingResponse>>, Self::Error>>>;
   |                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ type aliases cannot be used as traits
   |
help: you might have meant to use `#![feature(trait_alias)]` instead of a `type` alias
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/lib.rs:541:1
   |
541- pub type AsyncTask<T> = tokio::task::JoinHandle<T>;
541+ pub trait AsyncTask<T> = tokio::task::JoinHandle<T>;
   |

error[E0404]: expected trait, found type alias `AsyncTask`
  --> packages/provider/src/client.rs:91:44
   |
91 |     fn embed(&self, text: &str) -> Box<dyn AsyncTask<ZeroOneOrMany<f32>>>;
   |                                            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ type aliases cannot be used as traits
   |
help: you might have meant to use `#![feature(trait_alias)]` instead of a `type` alias
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/lib.rs:541:1
   |
541- pub type AsyncTask<T> = tokio::task::JoinHandle<T>;
541+ pub trait AsyncTask<T> = tokio::task::JoinHandle<T>;
   |

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/anthropic/completion.rs:17:62
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |                                                              +++++++++++++++++++++++++

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/deepseek/completion.rs:17:62
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |                                                              +++++++++++++++++++++++++

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/gemini/completion_old.rs:34:62
   |
34 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
34 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |                                                              +++++++++++++++++++++++++

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/gemini/gemini_client.rs:11:62
   |
11 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
11 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |                                                              +++++++++++++++++++++++++

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/gemini/gemini_types.rs:8:62
   |
8  | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
8  | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |                                                              +++++++++++++++++++++++++

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/groq/completion.rs:9:62
   |
9  | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage as DomainUsage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
9  - use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage as DomainUsage};
9  + use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/huggingface/completion.rs:17:62
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |                                                              +++++++++++++++++++++++++

error[E0603]: struct `Usage` is private
   --> packages/provider/src/clients/mistral/completion.rs:539:62
    |
539 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage as DomainUsage};
    |                                                              ^^^^^ private struct
    |
note: the struct `Usage` is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
    |
13  | use crate::usage::Usage;
    |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
    |
539 - use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage as DomainUsage};
539 + use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
    |

error[E0603]: struct `Usage` is private
  --> packages/provider/src/clients/openai/completion.rs:17:62
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                              ^^^^^ private struct
   |
note: the struct `Usage` is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
   |
13 | use crate::usage::Usage;
   |     ^^^^^^^^^^^^^^^^^^^
help: import `Usage` directly
   |
17 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, fluent_ai_domain::usage::Usage};
   |                                                              +++++++++++++++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/anthropic/client.rs:16:34
   |
16 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                  ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
16 | use crate::completion_provider::{completion::CompletionError, CompletionProvider};
   |                                  ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/anthropic/completion.rs:30:23
   |
30 |         ChunkHandler, CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
30 |         ChunkHandler, completion::CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ++++++++++++

error[E0603]: enum import `AnthropicError` is private
  --> packages/provider/src/clients/anthropic/tools/calculator.rs:17:12
   |
17 |     core::{AnthropicError, AnthropicResult},
   |            ^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `AnthropicError` is defined here...
  --> packages/provider/src/clients/anthropic/tools/core.rs:18:20
   |
18 | use super::super::{AnthropicError, AnthropicResult, Message};
   |                    ^^^^^^^^^^^^^^
note: ...and refers to the enum import `AnthropicError` which is defined here...
  --> packages/provider/src/clients/anthropic/mod.rs:34:9
   |
34 | pub use error::*;
   |         ^^^^^^^^ you could import this re-export
note: ...and refers to the enum `AnthropicError` which is defined here
  --> packages/provider/src/clients/anthropic/error.rs:12:1
   |
12 | pub enum AnthropicError {
   | ^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicError` through the re-export
   |
17 |     core::{super::AnthropicError, AnthropicResult},
   |            +++++++

error[E0603]: type alias import `AnthropicResult` is private
   --> packages/provider/src/clients/anthropic/tools/calculator.rs:17:28
    |
17  |     core::{AnthropicError, AnthropicResult},
    |                            ^^^^^^^^^^^^^^^ private type alias import
    |
note: the type alias import `AnthropicResult` is defined here...
   --> packages/provider/src/clients/anthropic/tools/core.rs:18:36
    |
18  | use super::super::{AnthropicError, AnthropicResult, Message};
    |                                    ^^^^^^^^^^^^^^^
note: ...and refers to the type alias import `AnthropicResult` which is defined here...
   --> packages/provider/src/clients/anthropic/mod.rs:34:9
    |
34  | pub use error::*;
    |         ^^^^^^^^ you could import this re-export
note: ...and refers to the type alias `AnthropicResult` which is defined here
   --> packages/provider/src/clients/anthropic/error.rs:119:1
    |
119 | pub type AnthropicResult<T> = Result<T, AnthropicError>;
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicResult` through the re-export
    |
17  |     core::{AnthropicError, super::AnthropicResult},
    |                            +++++++

error[E0603]: enum import `AnthropicError` is private
  --> packages/provider/src/clients/anthropic/tools/file_operations.rs:16:12
   |
16 |     core::{AnthropicError, AnthropicResult},
   |            ^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `AnthropicError` is defined here...
  --> packages/provider/src/clients/anthropic/tools/core.rs:18:20
   |
18 | use super::super::{AnthropicError, AnthropicResult, Message};
   |                    ^^^^^^^^^^^^^^
note: ...and refers to the enum import `AnthropicError` which is defined here...
  --> packages/provider/src/clients/anthropic/mod.rs:34:9
   |
34 | pub use error::*;
   |         ^^^^^^^^ you could import this re-export
note: ...and refers to the enum `AnthropicError` which is defined here
  --> packages/provider/src/clients/anthropic/error.rs:12:1
   |
12 | pub enum AnthropicError {
   | ^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicError` through the re-export
   |
16 |     core::{super::AnthropicError, AnthropicResult},
   |            +++++++

error[E0603]: type alias import `AnthropicResult` is private
   --> packages/provider/src/clients/anthropic/tools/file_operations.rs:16:28
    |
16  |     core::{AnthropicError, AnthropicResult},
    |                            ^^^^^^^^^^^^^^^ private type alias import
    |
note: the type alias import `AnthropicResult` is defined here...
   --> packages/provider/src/clients/anthropic/tools/core.rs:18:36
    |
18  | use super::super::{AnthropicError, AnthropicResult, Message};
    |                                    ^^^^^^^^^^^^^^^
note: ...and refers to the type alias import `AnthropicResult` which is defined here...
   --> packages/provider/src/clients/anthropic/mod.rs:34:9
    |
34  | pub use error::*;
    |         ^^^^^^^^ you could import this re-export
note: ...and refers to the type alias `AnthropicResult` which is defined here
   --> packages/provider/src/clients/anthropic/error.rs:119:1
    |
119 | pub type AnthropicResult<T> = Result<T, AnthropicError>;
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicResult` through the re-export
    |
16  |     core::{AnthropicError, super::AnthropicResult},
    |                            +++++++

error[E0603]: enum import `AnthropicError` is private
  --> packages/provider/src/clients/anthropic/tools/function_calling.rs:13:5
   |
13 |     AnthropicError, AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
   |     ^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `AnthropicError` is defined here...
  --> packages/provider/src/clients/anthropic/tools/core.rs:18:20
   |
18 | use super::super::{AnthropicError, AnthropicResult, Message};
   |                    ^^^^^^^^^^^^^^
note: ...and refers to the enum import `AnthropicError` which is defined here...
  --> packages/provider/src/clients/anthropic/mod.rs:34:9
   |
34 | pub use error::*;
   |         ^^^^^^^^ you could import this re-export
note: ...and refers to the enum `AnthropicError` which is defined here
  --> packages/provider/src/clients/anthropic/error.rs:12:1
   |
12 | pub enum AnthropicError {
   | ^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicError` through the re-export
   |
13 |     super::AnthropicError, AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
   |     +++++++

error[E0603]: type alias import `AnthropicResult` is private
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:13:21
    |
13  |     AnthropicError, AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
    |                     ^^^^^^^^^^^^^^^ private type alias import
    |
note: the type alias import `AnthropicResult` is defined here...
   --> packages/provider/src/clients/anthropic/tools/core.rs:18:36
    |
18  | use super::super::{AnthropicError, AnthropicResult, Message};
    |                                    ^^^^^^^^^^^^^^^
note: ...and refers to the type alias import `AnthropicResult` which is defined here...
   --> packages/provider/src/clients/anthropic/mod.rs:34:9
    |
34  | pub use error::*;
    |         ^^^^^^^^ you could import this re-export
note: ...and refers to the type alias `AnthropicResult` which is defined here
   --> packages/provider/src/clients/anthropic/error.rs:119:1
    |
119 | pub type AnthropicResult<T> = Result<T, AnthropicError>;
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicResult` through the re-export
    |
13  |     AnthropicError, super::AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
    |                     +++++++

error[E0603]: struct import `Message` is private
  --> packages/provider/src/clients/anthropic/tools/function_calling.rs:14:5
   |
14 |     Message, ResultHandler, SchemaType,
   |     ^^^^^^^ private struct import
   |
note: the struct import `Message` is defined here...
  --> packages/provider/src/clients/anthropic/tools/core.rs:18:53
   |
18 | use super::super::{AnthropicError, AnthropicResult, Message};
   |                                                     ^^^^^^^
note: ...and refers to the struct import `Message` which is defined here...
  --> packages/provider/src/clients/anthropic/mod.rs:35:9
   |
35 | pub use messages::*;
   |         ^^^^^^^^^^^ you could import this re-export
note: ...and refers to the struct `Message` which is defined here
  --> packages/provider/src/clients/anthropic/messages.rs:31:1
   |
31 | pub struct Message {
   | ^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `Message` through the re-export
   |
14 |     super::Message, ResultHandler, SchemaType,
   |     +++++++

error[E0603]: enum import `AnthropicError` is private
  --> packages/provider/src/clients/anthropic/tools/mod.rs:17:5
   |
17 |     AnthropicError, AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
   |     ^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `AnthropicError` is defined here...
  --> packages/provider/src/clients/anthropic/tools/core.rs:18:20
   |
18 | use super::super::{AnthropicError, AnthropicResult, Message};
   |                    ^^^^^^^^^^^^^^
note: ...and refers to the enum import `AnthropicError` which is defined here...
  --> packages/provider/src/clients/anthropic/mod.rs:34:9
   |
34 | pub use error::*;
   |         ^^^^^^^^ you could import this re-export
note: ...and refers to the enum `AnthropicError` which is defined here
  --> packages/provider/src/clients/anthropic/error.rs:12:1
   |
12 | pub enum AnthropicError {
   | ^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicError` through the re-export
   |
17 |     super::AnthropicError, AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
   |     +++++++

error[E0603]: type alias import `AnthropicResult` is private
   --> packages/provider/src/clients/anthropic/tools/mod.rs:17:21
    |
17  |     AnthropicError, AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
    |                     ^^^^^^^^^^^^^^^ private type alias import
    |
note: the type alias import `AnthropicResult` is defined here...
   --> packages/provider/src/clients/anthropic/tools/core.rs:18:36
    |
18  | use super::super::{AnthropicError, AnthropicResult, Message};
    |                                    ^^^^^^^^^^^^^^^
note: ...and refers to the type alias import `AnthropicResult` which is defined here...
   --> packages/provider/src/clients/anthropic/mod.rs:34:9
    |
34  | pub use error::*;
    |         ^^^^^^^^ you could import this re-export
note: ...and refers to the type alias `AnthropicResult` which is defined here
   --> packages/provider/src/clients/anthropic/error.rs:119:1
    |
119 | pub type AnthropicResult<T> = Result<T, AnthropicError>;
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `AnthropicResult` through the re-export
    |
17  |     AnthropicError, super::AnthropicResult, ChainControl, Emitter, ErrorHandler, InvocationHandler,
    |                     +++++++

error[E0603]: struct import `Message` is private
  --> packages/provider/src/clients/anthropic/tools/mod.rs:18:5
   |
18 |     Message, ResultHandler, SchemaType, ToolExecutionError, ToolRegistrationError,
   |     ^^^^^^^ private struct import
   |
note: the struct import `Message` is defined here...
  --> packages/provider/src/clients/anthropic/tools/core.rs:18:53
   |
18 | use super::super::{AnthropicError, AnthropicResult, Message};
   |                                                     ^^^^^^^
note: ...and refers to the struct import `Message` which is defined here...
  --> packages/provider/src/clients/anthropic/mod.rs:35:9
   |
35 | pub use messages::*;
   |         ^^^^^^^^^^^ you could import this re-export
note: ...and refers to the struct `Message` which is defined here
  --> packages/provider/src/clients/anthropic/messages.rs:31:1
   |
31 | pub struct Message {
   | ^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `Message` through the re-export
   |
18 |     super::Message, ResultHandler, SchemaType, ToolExecutionError, ToolRegistrationError,
   |     +++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/azure/client.rs:26:34
   |
26 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                  ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
26 | use crate::completion_provider::{completion::CompletionError, CompletionProvider};
   |                                  ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/bedrock/mod.rs:41:34
   |
41 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                  ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
41 | use crate::completion_provider::{completion::CompletionError, CompletionProvider};
   |                                  ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/bedrock/client.rs:22:34
   |
22 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                  ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
22 | use crate::completion_provider::{completion::CompletionError, CompletionProvider};
   |                                  ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/bedrock/completion.rs:26:5
   |
26 |     CompletionError, CompletionProvider, CompletionResponse, StreamingResponse,
   |     ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
26 |     completion::CompletionError, CompletionProvider, CompletionResponse, StreamingResponse,
   |     ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/bedrock/error.rs:17:33
   |
17 | use crate::completion_provider::CompletionError;
   |                                 ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
17 - use crate::completion_provider::CompletionError;
17 + use completion::CompletionError;
   |

error[E0603]: struct `MemoryPool` is private
   --> packages/provider/src/clients/candle/mod.rs:28:23
    |
28  | pub use memory_pool::{MemoryPool, MemoryPoolManager, PoolConfig, PoolStatistics, PooledEntry};
    |                       ^^^^^^^^^^ private struct
    |
note: the struct `MemoryPool` is defined here
   --> packages/provider/src/clients/candle/memory_pool.rs:232:1
    |
232 | struct MemoryPool {
    | ^^^^^^^^^^^^^^^^^

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/deepseek/client.rs:17:27
   |
17 |     completion_provider::{CompletionError, CompletionProvider},
   |                           ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
17 |     completion_provider::{completion::CompletionError, CompletionProvider},
   |                           ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/deepseek/completion.rs:28:23
   |
28 |         ChunkHandler, CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
28 |         ChunkHandler, completion::CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ++++++++++++

error[E0603]: enum import `FinishReason` is private
   --> packages/provider/src/clients/gemini/completion.rs:27:32
    |
27  |     Content, ContentCandidate, FinishReason, FunctionCall, FunctionDeclaration, FunctionResponse,
    |                                ^^^^^^^^^^^^ private enum import
    |
note: the enum import `FinishReason` is defined here...
   --> packages/provider/src/clients/gemini/gemini_types.rs:8:48
    |
8   | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
    |                                                ^^^^^^^^^^^^
note: ...and refers to the enum `FinishReason` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:110:1
    |
110 | pub enum FinishReason {
    | ^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `FinishReason` through the re-export
    |
27  |     Content, ContentCandidate, chunk::FinishReason, FunctionCall, FunctionDeclaration, FunctionResponse,
    |                                +++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/gemini/gemini_error.rs:8:33
   |
8  | use crate::completion_provider::CompletionError as ProviderError;
   |                                 ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
8  - use crate::completion_provider::CompletionError as ProviderError;
8  + use completion::CompletionError;
   |

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/gemini/gemini_streaming.rs:17:33
   |
17 | use crate::completion_provider::CompletionError;
   |                                 ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
17 - use crate::completion_provider::CompletionError;
17 + use completion::CompletionError;
   |

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/groq/completion.rs:24:23
   |
24 |         ChunkHandler, CompletionError as ProviderCompletionError, CompletionProvider, ModelConfig,
   |                       ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
24 -         ChunkHandler, CompletionError as ProviderCompletionError, CompletionProvider, ModelConfig,
24 +         ChunkHandler, completion::CompletionError, CompletionProvider, ModelConfig,
   |

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/huggingface/client.rs:17:27
   |
17 |     completion_provider::{CompletionError, CompletionProvider},
   |                           ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
17 |     completion_provider::{completion::CompletionError, CompletionProvider},
   |                           ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/huggingface/completion.rs:28:23
   |
28 |         ChunkHandler, CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
28 |         ChunkHandler, completion::CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/mistral/client.rs:20:34
   |
20 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                  ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
20 | use crate::completion_provider::{completion::CompletionError, CompletionProvider};
   |                                  ++++++++++++

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/mistral/completion.rs:562:23
    |
562 |         ChunkHandler, CompletionError as ProviderError, CompletionProvider, ModelConfig, ModelInfo,
    |                       ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
562 -         ChunkHandler, CompletionError as ProviderError, CompletionProvider, ModelConfig, ModelInfo,
562 +         ChunkHandler, completion::CompletionError, CompletionProvider, ModelConfig, ModelInfo,
    |

error[E0603]: struct import `MistralCompletionBuilder` is private
   --> packages/provider/src/clients/mistral/mod.rs:6:26
    |
6   | pub use client::{Client, MistralCompletionBuilder};
    |                          ^^^^^^^^^^^^^^^^^^^^^^^^ private struct import
    |
note: the struct import `MistralCompletionBuilder` is defined here...
   --> packages/provider/src/clients/mistral/client.rs:14:5
    |
14  | use super::completion::MistralCompletionBuilder;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the struct `MistralCompletionBuilder` which is defined here
   --> packages/provider/src/clients/mistral/completion.rs:575:1
    |
575 | pub struct MistralCompletionBuilder {
    | ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `MistralCompletionBuilder` through the re-export
    |
6   | pub use client::{Client, completion::MistralCompletionBuilder};
    |                          ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/openai/mod.rs:43:34
   |
43 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                  ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
43 | use crate::completion_provider::{completion::CompletionError, CompletionProvider};
   |                                  ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/openai/client.rs:33:34
   |
33 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                  ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
33 | use crate::completion_provider::{completion::CompletionError, CompletionProvider};
   |                                  ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/openai/completion.rs:29:23
   |
29 |         ChunkHandler, CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
29 |         ChunkHandler, completion::CompletionError, CompletionProvider, ModelConfig, ModelInfo,
   |                       ++++++++++++

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/xai/completion.rs:17:60
   |
17 | use crate::{clients::openai::Message, completion_provider::CompletionError, json_util};
   |                                                            ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
17 - use crate::{clients::openai::Message, completion_provider::CompletionError, json_util};
17 + use crate::{clients::openai::Message, completion::CompletionError, json_util};
   |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/xai/completion.rs:148:37
    |
148 |     use crate::completion_provider::CompletionError;
    |                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
148 -     use crate::completion_provider::CompletionError;
148 +     use completion::CompletionError;
    |

error[E0603]: enum import `CompletionError` is private
  --> packages/provider/src/clients/xai/streaming.rs:7:33
   |
7  | use crate::completion_provider::CompletionError;
   |                                 ^^^^^^^^^^^^^^^ private enum import
   |
note: the enum import `CompletionError` is defined here...
  --> packages/provider/src/completion_provider.rs:29:9
   |
29 | pub use CompletionCoreError as CompletionError;
   |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
  --> packages/provider/src/completion_provider.rs:13:5
   |
13 | use fluent_ai_domain::completion::CompletionCoreError;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
   |
23 |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
   |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
   |
7  - use crate::completion_provider::CompletionError;
7  + use completion::CompletionError;
   |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:204:51
    |
204 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
204 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
204 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:206:54
    |
206 |             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?;
    |                                                      ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
206 -             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?;
206 +             .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:298:51
    |
298 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
298 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
298 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:304:62
    |
304 |                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
    |                                                              ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
304 -                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
304 +                     .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:309:53
    |
309 |                         crate::completion_provider::CompletionError::RequestTooLarge
    |                                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
309 -                         crate::completion_provider::CompletionError::RequestTooLarge
309 +                         completion::CompletionError
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:322:51
    |
322 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
322 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
322 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:328:62
    |
328 |                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
    |                                                              ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
328 -                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
328 +                     .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:333:53
    |
333 |                         crate::completion_provider::CompletionError::RequestTooLarge
    |                                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
333 -                         crate::completion_provider::CompletionError::RequestTooLarge
333 +                         completion::CompletionError
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:346:51
    |
346 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
346 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
346 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:352:62
    |
352 |                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
    |                                                              ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
352 -                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
352 +                     .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:357:53
    |
357 |                         crate::completion_provider::CompletionError::RequestTooLarge
    |                                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
357 -                         crate::completion_provider::CompletionError::RequestTooLarge
357 +                         completion::CompletionError
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:376:67
    |
376 |         F: Fn(Result<CompletionChunk, crate::completion_provider::CompletionError>)
    |                                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
376 -         F: Fn(Result<CompletionChunk, crate::completion_provider::CompletionError>)
376 +         F: Fn(Result<CompletionChunk, completion::CompletionError>)
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:439:73
    |
439 |         AsyncStream<Result<CompletionChunk, crate::completion_provider::CompletionError>>,
    |                                                                         ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
439 -         AsyncStream<Result<CompletionChunk, crate::completion_provider::CompletionError>>,
439 +         AsyncStream<Result<CompletionChunk, completion::CompletionError>>,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:440:37
    |
440 |         crate::completion_provider::CompletionError,
    |                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
440 -         crate::completion_provider::CompletionError,
440 +         completion::CompletionError,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:444:54
    |
444 |             .map_err(|_| crate::completion_provider::CompletionError::ParseError)?;
    |                                                      ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
444 -             .map_err(|_| crate::completion_provider::CompletionError::ParseError)?;
444 +             .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:455:54
    |
455 |             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?
    |                                                      ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
455 -             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?
455 +             .map_err(|_| completion::CompletionError)?
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:462:54
    |
462 |             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?;
    |                                                      ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
462 -             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?;
462 +             .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:466:52
    |
466 |                 401 => crate::completion_provider::CompletionError::AuthError,
    |                                                    ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
466 -                 401 => crate::completion_provider::CompletionError::AuthError,
466 +                 401 => completion::CompletionError,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:467:52
    |
467 |                 413 => crate::completion_provider::CompletionError::RequestTooLarge,
    |                                                    ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
467 -                 413 => crate::completion_provider::CompletionError::RequestTooLarge,
467 +                 413 => completion::CompletionError,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:468:52
    |
468 |                 429 => crate::completion_provider::CompletionError::RateLimited,
    |                                                    ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
468 -                 429 => crate::completion_provider::CompletionError::RateLimited,
468 +                 429 => completion::CompletionError,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:469:50
    |
469 |                 _ => crate::completion_provider::CompletionError::HttpError,
    |                                                  ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
469 -                 _ => crate::completion_provider::CompletionError::HttpError,
469 +                 _ => completion::CompletionError,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:500:57
    |
500 | ...                   crate::completion_provider::CompletionError::StreamError,
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
500 -                             crate::completion_provider::CompletionError::StreamError,
500 +                             completion::CompletionError,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:516:69
    |
516 |     ) -> Result<GenerateContentRequest, crate::completion_provider::CompletionError> {
    |                                                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
516 -     ) -> Result<GenerateContentRequest, crate::completion_provider::CompletionError> {
516 +     ) -> Result<GenerateContentRequest, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:574:54
    |
574 |     ) -> Result<Content, crate::completion_provider::CompletionError> {
    |                                                      ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
574 -     ) -> Result<Content, crate::completion_provider::CompletionError> {
574 +     ) -> Result<Content, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:580:56
    |
580 |                     .ok_or(crate::completion_provider::CompletionError::ParseError)?;
    |                                                        ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
580 -                     .ok_or(crate::completion_provider::CompletionError::ParseError)?;
580 +                     .ok_or(completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:602:66
    |
602 |                         .map_err(|_| crate::completion_provider::CompletionError::ParseError)?,
    |                                                                  ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
602 -                         .map_err(|_| crate::completion_provider::CompletionError::ParseError)?,
602 +                         .map_err(|_| completion::CompletionError)?,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:610:56
    |
610 |                     .ok_or(crate::completion_provider::CompletionError::ParseError)?;
    |                                                        ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
610 -                     .ok_or(crate::completion_provider::CompletionError::ParseError)?;
610 +                     .ok_or(completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:623:56
    |
623 |     ) -> Result<Vec<Tool>, crate::completion_provider::CompletionError> {
    |                                                        ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
623 -     ) -> Result<Vec<Tool>, crate::completion_provider::CompletionError> {
623 +     ) -> Result<Vec<Tool>, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:635:70
    |
635 | ...                   .map_err(|_| crate::completion_provider::CompletionError::ParseError)?,
    |                                                                ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
635 -                             .map_err(|_| crate::completion_provider::CompletionError::ParseError)?,
635 +                             .map_err(|_| completion::CompletionError)?,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:656:62
    |
656 |     ) -> Result<CompletionChunk, crate::completion_provider::CompletionError> {
    |                                                              ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
656 -     ) -> Result<CompletionChunk, crate::completion_provider::CompletionError> {
656 +     ) -> Result<CompletionChunk, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:659:54
    |
659 |             .map_err(|_| crate::completion_provider::CompletionError::ParseError)?;
    |                                                      ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
659 -             .map_err(|_| crate::completion_provider::CompletionError::ParseError)?;
659 +             .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:664:48
    |
664 |             .ok_or(crate::completion_provider::CompletionError::ParseError)?;
    |                                                ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
664 -             .ok_or(crate::completion_provider::CompletionError::ParseError)?;
664 +             .ok_or(completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/completion_old.rs:716:66
    |
716 | ) -> Result<GeminiCompletionBuilder, crate::completion_provider::CompletionError> {
    |                                                                  ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
716 - ) -> Result<GeminiCompletionBuilder, crate::completion_provider::CompletionError> {
716 + ) -> Result<GeminiCompletionBuilder, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:197:51
    |
197 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
197 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
197 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:199:54
    |
199 |             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?;
    |                                                      ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
199 -             .map_err(|_| crate::completion_provider::CompletionError::HttpError)?;
199 +             .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:293:51
    |
293 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
293 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
293 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:299:62
    |
299 |                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
    |                                                              ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
299 -                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
299 +                     .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:304:53
    |
304 |                         crate::completion_provider::CompletionError::RequestTooLarge
    |                                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
304 -                         crate::completion_provider::CompletionError::RequestTooLarge
304 +                         completion::CompletionError
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:317:51
    |
317 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
317 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
317 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:323:62
    |
323 |                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
    |                                                              ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
323 -                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
323 +                     .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:328:53
    |
328 |                         crate::completion_provider::CompletionError::RequestTooLarge
    |                                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
328 -                         crate::completion_provider::CompletionError::RequestTooLarge
328 +                         completion::CompletionError
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:341:51
    |
341 |     ) -> Result<Self, crate::completion_provider::CompletionError> {
    |                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
341 -     ) -> Result<Self, crate::completion_provider::CompletionError> {
341 +     ) -> Result<Self, completion::CompletionError> {
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:347:62
    |
347 |                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
    |                                                              ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
347 -                     .map_err(|_| crate::completion_provider::CompletionError::RequestTooLarge)?;
347 +                     .map_err(|_| completion::CompletionError)?;
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:352:53
    |
352 |                         crate::completion_provider::CompletionError::RequestTooLarge
    |                                                     ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
352 -                         crate::completion_provider::CompletionError::RequestTooLarge
352 +                         completion::CompletionError
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:371:67
    |
371 |         F: Fn(Result<CompletionChunk, crate::completion_provider::CompletionError>)
    |                                                                   ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
371 -         F: Fn(Result<CompletionChunk, crate::completion_provider::CompletionError>)
371 +         F: Fn(Result<CompletionChunk, completion::CompletionError>)
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:436:80
    |
436 |         crate::AsyncStream<Result<CompletionChunk, crate::completion_provider::CompletionError>>,
    |                                                                                ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
436 -         crate::AsyncStream<Result<CompletionChunk, crate::completion_provider::CompletionError>>,
436 +         crate::AsyncStream<Result<CompletionChunk, completion::CompletionError>>,
    |

error[E0603]: enum import `CompletionError` is private
   --> packages/provider/src/clients/gemini/gemini_client.rs:639:66
    |
639 | ) -> Result<GeminiCompletionBuilder, crate::completion_provider::CompletionError> {
    |                                                                  ^^^^^^^^^^^^^^^ private enum import
    |
note: the enum import `CompletionError` is defined here...
   --> packages/provider/src/completion_provider.rs:29:9
    |
29  | pub use CompletionCoreError as CompletionError;
    |         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum import `CompletionCoreError` which is defined here...
   --> packages/provider/src/completion_provider.rs:13:5
    |
13  | use fluent_ai_domain::completion::CompletionCoreError;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
note: ...and refers to the enum `CompletionCoreError` which is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/completion/mod.rs:23:52
    |
23  |     CompletionCoreClient, CompletionCoreClientExt, CompletionCoreError, CompletionCoreRequest, CompletionCoreResponse,
    |                                                    ^^^^^^^^^^^^^^^^^^^ you could import this directly
help: import `CompletionError` through the re-export
    |
639 - ) -> Result<GeminiCompletionBuilder, crate::completion_provider::CompletionError> {
639 + ) -> Result<GeminiCompletionBuilder, completion::CompletionError> {
    |

error[E0603]: unresolved item import `StreamingCompletionResponse` is private
   --> packages/provider/src/clients/ollama/client.rs:480:35
    |
480 |                 super::streaming::StreamingCompletionResponse,
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^ private unresolved item import
    |
note: the unresolved item import `StreamingCompletionResponse` is defined here
   --> packages/provider/src/clients/ollama/streaming.rs:15:37
    |
15  |     streaming::{RawStreamingChoice, StreamingCompletionResponse},
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: import `StreamingCompletionResponse` through the re-export
    |
480 -                 super::streaming::StreamingCompletionResponse,
480 +                 streaming::StreamingCompletionResponse,
    |

error[E0603]: unresolved item import `StreamingCompletionResponse` is private
   --> packages/provider/src/clients/ollama/completion.rs:206:41
    |
206 |     type StreamingResponse = streaming::StreamingCompletionResponse<CompletionResponse>;
    |                                         ^^^^^^^^^^^^^^^^^^^^^^^^^^^ private unresolved item import
    |
note: the unresolved item import `StreamingCompletionResponse` is defined here
   --> packages/provider/src/clients/ollama/streaming.rs:15:37
    |
15  |     streaming::{RawStreamingChoice, StreamingCompletionResponse},
    |                                     ^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: import `StreamingCompletionResponse` through the re-export
    |
206 -     type StreamingResponse = streaming::StreamingCompletionResponse<CompletionResponse>;
206 +     type StreamingResponse = streaming::StreamingCompletionResponse;
    |

error[E0603]: struct `Usage` is private
   --> packages/provider/src/clients/openai/streaming.rs:316:75
    |
316 |             let usage = self.usage.as_ref().map(|u| crate::domain::chunk::Usage {
    |                                                                           ^^^^^ private struct
    |
note: the struct `Usage` is defined here
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/context/chunk.rs:13:5
    |
13  | use crate::usage::Usage;
    |     ^^^^^^^^^^^^^^^^^^^
help: consider importing one of these structs instead
    |
316 -             let usage = self.usage.as_ref().map(|u| crate::domain::chunk::Usage {
316 +             let usage = self.usage.as_ref().map(|u| crate::domain::usage::Usage {
    |
316 -             let usage = self.usage.as_ref().map(|u| crate::domain::chunk::Usage {
316 +             let usage = self.usage.as_ref().map(|u| fluent_ai_domain::usage::Usage {
    |
help: import `Usage` directly
    |
316 -             let usage = self.usage.as_ref().map(|u| crate::domain::chunk::Usage {
316 +             let usage = self.usage.as_ref().map(|u| fluent_ai_domain::usage::Usage {
    |

error[E0603]: struct import `CompletionResponse` is private
   --> packages/provider/src/clients/xai/client.rs:492:63
    |
492 |             completion::CompletionResponse<super::completion::CompletionResponse>,
    |                                                               ^^^^^^^^^^^^^^^^^^ private struct import
    |
note: the struct import `CompletionResponse` is defined here...
   --> packages/provider/src/clients/xai/completion.rs:8:21
    |
8   | use xai_api_types::{CompletionResponse, ToolDefinition};
    |                     ^^^^^^^^^^^^^^^^^^
note: ...and refers to the struct `CompletionResponse` which is defined here
   --> packages/provider/src/clients/xai/completion.rs:229:5
    |
229 |     pub struct CompletionResponse {
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ you could import this directly
help: consider importing this struct instead
    |
492 -             completion::CompletionResponse<super::completion::CompletionResponse>,
492 +             completion::CompletionResponse<crate::clients::xai::completion::xai_api_types::CompletionResponse>,
    |
help: import `CompletionResponse` directly
    |
492 -             completion::CompletionResponse<super::completion::CompletionResponse>,
492 +             completion::CompletionResponse<clients::xai::completion::xai_api_types::CompletionResponse>,
    |

error[E0603]: unresolved item import `StreamingCompletionResponse` is private
   --> packages/provider/src/clients/xai/client.rs:520:35
    |
520 |                 super::streaming::StreamingCompletionResponse,
    |                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^ private unresolved item import
    |
note: the unresolved item import `StreamingCompletionResponse` is defined here
   --> packages/provider/src/clients/xai/streaming.rs:17:5
    |
17  | use crate::streaming::StreamingCompletionResponse;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
help: import `StreamingCompletionResponse` through the re-export
    |
520 -                 super::streaming::StreamingCompletionResponse,
520 +                 streaming::StreamingCompletionResponse,
    |

warning: unexpected `cfg` condition value: `candle`
  --> packages/provider/src/lib.rs:23:7
   |
23 | #[cfg(feature = "candle")]
   |       ^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `candle` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration
   = note: `#[warn(unexpected_cfgs)]` on by default

warning: unused import: `RegisteredModel`
  --> packages/provider/src/clients/anthropic/discovery.rs:14:31
   |
14 |     registry::{ModelRegistry, RegisteredModel},
   |                               ^^^^^^^^^^^^^^^
   |
   = note: `#[warn(unused_imports)]` on by default

warning: unused import: `HttpError`
  --> packages/provider/src/clients/anthropic/requests.rs:13:35
   |
13 | use fluent_ai_http3::{HttpClient, HttpError, HttpRequest, HttpResponse};
   |                                   ^^^^^^^^^

warning: unexpected `cfg` condition value: `cylo`
  --> packages/provider/src/clients/anthropic/tools/function_calling.rs:18:7
   |
18 | #[cfg(feature = "cylo")]
   |       ^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `cylo` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `cylo`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:219:11
    |
219 |     #[cfg(feature = "cylo")]
    |           ^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `cylo` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `cylo`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:303:11
    |
303 |     #[cfg(feature = "cylo")]
    |           ^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `cylo` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `cylo`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:318:15
    |
318 |     #[cfg(not(feature = "cylo"))]
    |               ^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `cylo` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `cylo`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:390:19
    |
390 |             #[cfg(feature = "cylo")]
    |                   ^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `cylo` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `cylo`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:423:15
    |
423 |         #[cfg(feature = "cylo")]
    |               ^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `cylo` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `cylo`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:453:19
    |
453 |         #[cfg(not(feature = "cylo"))]
    |                   ^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `cylo` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `cylo`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:490:11
    |
490 |     #[cfg(feature = "cylo")]
    |           ^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `cylo` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: ambiguous glob re-exports
  --> packages/provider/src/clients/anthropic/mod.rs:29:9
   |
29 | pub use completion::*;
   |         ^^^^^^^^^^^^^ the name `CacheControl` in the type namespace is first re-exported here
...
35 | pub use messages::*;
   |         ----------- but the name `CacheControl` in the type namespace is also re-exported here
   |
   = note: `#[warn(ambiguous_glob_reexports)]` on by default

warning: ambiguous glob re-exports
  --> packages/provider/src/clients/anthropic/mod.rs:29:9
   |
29 | pub use completion::*;
   |         ^^^^^^^^^^^^^ the name `AnthropicStreamChunk` in the type namespace is first re-exported here
...
38 | pub use streaming::*;
   |         ------------ but the name `AnthropicStreamChunk` in the type namespace is also re-exported here

warning: ambiguous glob re-exports
  --> packages/provider/src/clients/anthropic/mod.rs:39:9
   |
35 | pub use messages::*;
   |         ----------- but the name `Tool` in the type namespace is also re-exported here
...
39 | pub use tools::*;
   |         ^^^^^^^^ the name `Tool` in the type namespace is first re-exported here

warning: unexpected `cfg` condition value: `audio`
  --> packages/provider/src/clients/azure/mod.rs:18:7
   |
18 | #[cfg(feature = "audio")]
   |       ^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `audio` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `audio`
  --> packages/provider/src/clients/azure/mod.rs:24:7
   |
24 | #[cfg(feature = "audio")]
   |       ^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `audio` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/azure/client.rs:12:29
   |
12 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unused import: `bytes::Bytes`
  --> packages/provider/src/clients/azure/client.rs:13:5
   |
13 | use bytes::Bytes;
   |     ^^^^^^^^^^^^

warning: unexpected `cfg` condition value: `audio`
   --> packages/provider/src/clients/azure/client.rs:309:11
    |
309 |     #[cfg(feature = "audio")]
    |           ^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `audio` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused imports: `convert::Infallible` and `str::FromStr`
 --> packages/provider/src/clients/azure/completion.rs:9:11
  |
9 | use std::{convert::Infallible, str::FromStr};
  |           ^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^

warning: unused import: `Serialize`
  --> packages/provider/src/clients/azure/completion.rs:11:26
   |
11 | use serde::{Deserialize, Serialize};
   |                          ^^^^^^^^^

warning: unused imports: `OneOrMany` and `TranscriptionResponse`
  --> packages/provider/src/clients/azure/completion.rs:16:5
   |
16 |     OneOrMany,
   |     ^^^^^^^^^
17 |     clients::openai::{self, TranscriptionResponse, send_compatible_streaming_request},
   |                             ^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `CompletionCoreError`
  --> packages/provider/src/clients/azure/completion.rs:20:42
   |
20 | use fluent_ai_domain::completion::{self, CompletionCoreError, StreamingCoreResponse as RigStreaming};
   |                                          ^^^^^^^^^^^^^^^^^^^

warning: unused imports: `MessageError` and `self`
  --> packages/provider/src/clients/azure/completion.rs:21:33
   |
21 | use fluent_ai_domain::message::{self, MessageError};
   |                                 ^^^^  ^^^^^^^^^^^^

warning: unused import: `fluent_ai_domain::completion::StreamingCoreResponse`
  --> packages/provider/src/clients/azure/completion.rs:24:5
   |
24 | use fluent_ai_domain::completion::StreamingCoreResponse;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `fluent_ai_domain::model::AnyEmbeddingCapable`
 --> packages/provider/src/clients/azure/embedding.rs:9:5
  |
9 | use fluent_ai_domain::model::AnyEmbeddingCapable;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `serde_json::json`
  --> packages/provider/src/clients/azure/embedding.rs:11:5
   |
11 | use serde_json::json;
   |     ^^^^^^^^^^^^^^^^

warning: unused import: `self`
  --> packages/provider/src/clients/azure/embedding.rs:14:35
   |
14 | use fluent_ai_domain::embedding::{self}; 
   |                                   ^^^^

warning: unused import: `anyhow::Error`
   --> packages/provider/src/clients/azure/embedding.rs:183:13
    |
183 |         use anyhow::Error /* was fluent_ai_domain::embedding::EmbeddingError */;
    |             ^^^^^^^^^^^^^

warning: unused import: `HttpClient`
   --> packages/provider/src/clients/azure/embedding.rs:184:31
    |
184 |         use fluent_ai_http3::{HttpClient, HttpRequest};
    |                               ^^^^^^^^^^

warning: unused import: `anyhow::Error`
   --> packages/provider/src/clients/azure/embedding.rs:245:13
    |
245 |         use anyhow::Error /* was fluent_ai_domain::embedding::EmbeddingError */;
    |             ^^^^^^^^^^^^^

warning: unused import: `HttpClient`
   --> packages/provider/src/clients/azure/embedding.rs:246:31
    |
246 |         use fluent_ai_http3::{HttpClient, HttpRequest};
    |                               ^^^^^^^^^^

warning: unused import: `CompletionCoreError`
  --> packages/provider/src/clients/azure/streaming.rs:15:36
   |
15 | use fluent_ai_domain::completion::{CompletionCoreError, CompletionRequest};
   |                                    ^^^^^^^^^^^^^^^^^^^

warning: unused import: `transcription::*`
  --> packages/provider/src/clients/azure/mod.rs:32:9
   |
32 | pub use transcription::*;
   |         ^^^^^^^^^^^^^^^^

warning: unused imports: `CompletionClient` and `ProviderClient`
  --> packages/provider/src/clients/bedrock/mod.rs:40:21
   |
40 | use crate::client::{CompletionClient, ProviderClient};
   |                     ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^

warning: unused import: `arc_swap::ArcSwap`
  --> packages/provider/src/clients/bedrock/client.rs:14:5
   |
14 | use arc_swap::ArcSwap;
   |     ^^^^^^^^^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/bedrock/completion.rs:12:29
   |
12 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unused import: `serde_json::Value`
  --> packages/provider/src/clients/bedrock/completion.rs:19:5
   |
19 | use serde_json::Value;
   |     ^^^^^^^^^^^^^^^^^

warning: unused import: `arrayvec::ArrayString`
  --> packages/provider/src/clients/bedrock/streaming.rs:12:5
   |
12 | use arrayvec::ArrayString;
   |     ^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `super::regions`
   --> packages/provider/src/clients/bedrock/mod.rs:159:9
    |
159 |     use super::regions;
    |         ^^^^^^^^^^^^^^

warning: unused import: `DeviceInfo`
  --> packages/provider/src/clients/candle/client.rs:20:29
   |
20 | use super::device_manager::{DeviceInfo, DeviceManager};
   |                             ^^^^^^^^^^

warning: unused import: `PoolConfig`
  --> packages/provider/src/clients/candle/client.rs:24:45
   |
24 | use super::memory_pool::{MemoryPoolManager, PoolConfig};
   |                                             ^^^^^^^^^^

warning: unused import: `ModelState`
  --> packages/provider/src/clients/candle/client.rs:25:42
   |
25 | use super::model_repo::{ModelRepository, ModelState};
   |                                          ^^^^^^^^^^

warning: unused import: `TokenStreamer`
  --> packages/provider/src/clients/candle/client.rs:28:77
   |
28 | use super::streaming::{FinishReason, StreamingConfig, StreamingCoordinator, TokenStreamer};
   |                                                                             ^^^^^^^^^^^^^

warning: unused imports: `SpecialTokens` and `TokenizationResult`
  --> packages/provider/src/clients/candle/client.rs:29:41
   |
29 | use super::tokenizer::{CandleTokenizer, SpecialTokens, TextBuffer, TokenizationResult};
   |                                         ^^^^^^^^^^^^^              ^^^^^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
 --> packages/provider/src/clients/candle/config.rs:7:5
  |
7 | use std::sync::Arc;
  |     ^^^^^^^^^^^^^^

warning: unused import: `arc_swap::ArcSwap`
  --> packages/provider/src/clients/candle/config.rs:10:5
   |
10 | use arc_swap::ArcSwap;
   |     ^^^^^^^^^^^^^^^^^

warning: unused import: `AtomicU8`
 --> packages/provider/src/clients/candle/device_manager.rs:7:37
  |
7 | use std::sync::atomic::{AtomicBool, AtomicU8, AtomicU64, Ordering};
  |                                     ^^^^^^^^

warning: unused import: `Guard`
  --> packages/provider/src/clients/candle/device_manager.rs:10:25
   |
10 | use arc_swap::{ArcSwap, Guard};
   |                         ^^^^^

warning: unused import: `arrayvec::ArrayVec`
  --> packages/provider/src/clients/candle/device_manager.rs:11:5
   |
11 | use arrayvec::ArrayVec;
   |     ^^^^^^^^^^^^^^^^^^

warning: unused import: `ErrorMetrics`
  --> packages/provider/src/clients/candle/device_manager.rs:16:47
   |
16 | use super::error::{CandleError, CandleResult, ErrorMetrics, record_global_error};
   |                                               ^^^^^^^^^^^^

warning: unused import: `std::collections::HashMap`
 --> packages/provider/src/clients/candle/kv_cache.rs:6:5
  |
6 | use std::collections::HashMap;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `Guard`
  --> packages/provider/src/clients/candle/model_repo.rs:13:25
   |
13 | use arc_swap::{ArcSwap, Guard};
   |                         ^^^^^

warning: unused import: `CandleDevice`
  --> packages/provider/src/clients/candle/model_repo.rs:21:21
   |
21 | use super::models::{CandleDevice, CandleModel};
   |                     ^^^^^^^^^^^^

warning: unused import: `std::borrow::Cow`
 --> packages/provider/src/clients/candle/models.rs:3:5
  |
3 | use std::borrow::Cow;
  |     ^^^^^^^^^^^^^^^^

warning: variant `Devstral_22B` should have an upper camel case name
  --> packages/provider/src/clients/candle/models.rs:13:5
   |
13 |     Devstral_22B,
   |     ^^^^^^^^^^^^ help: convert the identifier to upper camel case: `Devstral22b`
   |
   = note: `#[warn(non_camel_case_types)]` on by default

warning: variant `Mistral_7B` should have an upper camel case name
  --> packages/provider/src/clients/candle/models.rs:19:5
   |
19 |     Mistral_7B,
   |     ^^^^^^^^^^ help: convert the identifier to upper camel case: `Mistral7b`

warning: variant `CodeLlama_7B` should have an upper camel case name
  --> packages/provider/src/clients/candle/models.rs:21:5
   |
21 |     CodeLlama_7B,
   |     ^^^^^^^^^^^^ help: convert the identifier to upper camel case: `CodeLlama7b`

warning: variant `Phi3_Mini` should have an upper camel case name
  --> packages/provider/src/clients/candle/models.rs:23:5
   |
23 |     Phi3_Mini,
   |     ^^^^^^^^^ help: convert the identifier to upper camel case: `Phi3Mini`

warning: variant `Gemma_2B` should have an upper camel case name
  --> packages/provider/src/clients/candle/models.rs:25:5
   |
25 |     Gemma_2B,
   |     ^^^^^^^^ help: convert the identifier to upper camel case: `Gemma2b`

warning: variant `Gemma_7B` should have an upper camel case name
  --> packages/provider/src/clients/candle/models.rs:27:5
   |
27 |     Gemma_7B,
   |     ^^^^^^^^ help: convert the identifier to upper camel case: `Gemma7b`

warning: unused import: `arrayvec::ArrayVec`
  --> packages/provider/src/clients/candle/streaming.rs:10:5
   |
10 | use arrayvec::ArrayVec;
   |     ^^^^^^^^^^^^^^^^^^

warning: unused import: `HttpError`
  --> packages/provider/src/clients/deepseek/completion.rs:21:47
   |
21 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpError, HttpRequest};
   |                                               ^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/gemini/client.rs:11:29
   |
11 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unused import: `bytes::Bytes`
  --> packages/provider/src/clients/gemini/client.rs:13:5
   |
13 | use bytes::Bytes;
   |     ^^^^^^^^^^^^

warning: unused import: `CompletionCoreError`
  --> packages/provider/src/clients/gemini/client.rs:26:11
   |
26 |     self, CompletionCoreError, CompletionRequest, CompletionRequestBuilder,
   |           ^^^^^^^^^^^^^^^^^^^

warning: unused import: `fluent_ai_domain::embedding::Embedding`
  --> packages/provider/src/clients/gemini/client.rs:29:5
   |
29 | use fluent_ai_domain::embedding::Embedding;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `AsyncTask`
  --> packages/provider/src/clients/gemini/completion_old.rs:36:24
   |
36 | use fluent_ai_domain::{AsyncTask, spawn_async};
   |                        ^^^^^^^^^

warning: unused import: `HttpError`
  --> packages/provider/src/clients/gemini/completion_old.rs:38:47
   |
38 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpError, HttpRequest};
   |                                               ^^^^^^^^^

warning: unused import: `fluent_ai_domain::model::AnyEmbeddingCapable`
 --> packages/provider/src/clients/gemini/embedding.rs:6:5
  |
6 | use fluent_ai_domain::model::AnyEmbeddingCapable;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
  --> packages/provider/src/clients/gemini/embedding.rs:47:16
   |
47 |     #[cfg_attr(feature = "worker", worker::send)]
   |                ^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `worker` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `fluent_ai_domain::chunk::CompletionChunk`
 --> packages/provider/src/clients/gemini/model_info.rs:6:5
  |
6 | use fluent_ai_domain::chunk::CompletionChunk;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::AsyncStream`
 --> packages/provider/src/clients/gemini/model_info.rs:8:5
  |
8 | use crate::AsyncStream;
  |     ^^^^^^^^^^^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
  --> packages/provider/src/clients/gemini/transcription.rs:45:16
   |
45 |     #[cfg_attr(feature = "worker", worker::send)]
   |                ^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `worker` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `FinishReason`
  --> packages/provider/src/clients/gemini/gemini_client.rs:11:48
   |
11 | use fluent_ai_domain::chunk::{CompletionChunk, FinishReason, Usage};
   |                                                ^^^^^^^^^^^^

warning: unused import: `AsyncTask`
  --> packages/provider/src/clients/gemini/gemini_client.rs:13:24
   |
13 | use fluent_ai_domain::{AsyncTask, Document, Message, spawn_async};
   |                        ^^^^^^^^^

warning: unused imports: `HttpError` and `HttpRequest`
  --> packages/provider/src/clients/gemini/gemini_client.rs:14:47
   |
14 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpError, HttpRequest};
   |                                               ^^^^^^^^^  ^^^^^^^^^^^

warning: unused import: `warn`
  --> packages/provider/src/clients/gemini/gemini_client.rs:16:35
   |
16 | use tracing::{debug, error, info, warn};
   |                                   ^^^^

warning: unused import: `StreamingResponse`
  --> packages/provider/src/clients/gemini/gemini_client.rs:20:54
   |
20 | use super::gemini_streaming::{GeminiStreamProcessor, StreamingResponse};
   |                                                      ^^^^^^^^^^^^^^^^^

warning: unused import: `std::fmt`
 --> packages/provider/src/clients/gemini/gemini_error.rs:6:5
  |
6 | use std::fmt;
  |     ^^^^^^^^

warning: unused import: `AsyncTask`
  --> packages/provider/src/clients/gemini/gemini_streaming.rs:10:24
   |
10 | use fluent_ai_domain::{AsyncTask, chunk::CompletionChunk, spawn_async};
   |                        ^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/groq/client.rs:10:29
   |
10 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unused import: `HttpError`
  --> packages/provider/src/clients/groq/completion.rs:12:47
   |
12 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpError, HttpRequest};
   |                                               ^^^^^^^^^

warning: unused import: `tokio::task`
  --> packages/provider/src/clients/groq/completion.rs:30:5
   |
30 | use tokio::task;
   |     ^^^^^^^^^^^

warning: unused import: `serde_json::Value`
 --> packages/provider/src/clients/groq/streaming.rs:8:5
  |
8 | use serde_json::Value;
  |     ^^^^^^^^^^^^^^^^^

warning: unused imports: `StreamingChoice` and `StreamingMessage`
  --> packages/provider/src/clients/groq/streaming.rs:13:43
   |
13 |     clients::openai::{CompletionResponse, StreamingChoice, StreamingMessage},
   |                                           ^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^

warning: unused import: `AsyncTask`
  --> packages/provider/src/clients/huggingface/completion.rs:19:24
   |
19 | use fluent_ai_domain::{AsyncTask, spawn_async};
   |                        ^^^^^^^^^

warning: unused import: `HttpError`
  --> packages/provider/src/clients/huggingface/completion.rs:21:47
   |
21 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpError, HttpRequest};
   |                                               ^^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
  --> packages/provider/src/clients/huggingface/transcription.rs:55:16
   |
55 |     #[cfg_attr(feature = "worker", worker::send)]
   |                ^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `worker` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/mistral/completion.rs:388:16
    |
388 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/mistral/completion.rs:431:16
    |
431 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `fluent_ai_domain::tool::ToolDefinition`
   --> packages/provider/src/clients/mistral/completion.rs:540:5
    |
540 | use fluent_ai_domain::tool::ToolDefinition;
    |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `AsyncTask`
   --> packages/provider/src/clients/mistral/completion.rs:554:24
    |
554 | use fluent_ai_domain::{AsyncTask, spawn_async};
    |                        ^^^^^^^^^

warning: unused import: `HttpError`
   --> packages/provider/src/clients/mistral/completion.rs:556:47
    |
556 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpError, HttpRequest};
    |                                               ^^^^^^^^^

warning: unused import: `fluent_ai_domain::model::AnyEmbeddingCapable`
 --> packages/provider/src/clients/mistral/embedding.rs:1:5
  |
1 | use fluent_ai_domain::model::AnyEmbeddingCapable;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
  --> packages/provider/src/clients/mistral/embedding.rs:34:16
   |
34 |     #[cfg_attr(feature = "worker", worker::send)]
   |                ^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `worker` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `fluent_ai_domain::chunk::CompletionChunk`
 --> packages/provider/src/clients/mistral/model_info.rs:8:5
  |
8 | use fluent_ai_domain::chunk::CompletionChunk;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `crate::AsyncStream`
  --> packages/provider/src/clients/mistral/model_info.rs:10:5
   |
10 | use crate::AsyncStream;
   |     ^^^^^^^^^^^^^^^^^^

warning: unused import: `CompletionProvider`
  --> packages/provider/src/clients/mistral/model_info.rs:12:34
   |
12 | use crate::completion_provider::{CompletionProvider, ModelConfig, ModelInfo, ModelPrompt};
   |                                  ^^^^^^^^^^^^^^^^^^

warning: unused import: `arc_swap::ArcSwap`
  --> packages/provider/src/clients/ollama/client.rs:10:5
   |
10 | use arc_swap::ArcSwap;
   |     ^^^^^^^^^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/ollama/client.rs:11:29
   |
11 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unused import: `CompletionResponse`
  --> packages/provider/src/clients/ollama/streaming.rs:11:25
   |
11 | use super::completion::{CompletionResponse, ProviderMessage};
   |                         ^^^^^^^^^^^^^^^^^^

warning: unused imports: `CompletionClient` and `ProviderClient`
  --> packages/provider/src/clients/openai/mod.rs:42:21
   |
42 | use crate::client::{CompletionClient, ProviderClient};
   |                     ^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^

warning: unused import: `CompletionProvider`
  --> packages/provider/src/clients/openai/mod.rs:43:51
   |
43 | use crate::completion_provider::{CompletionError, CompletionProvider};
   |                                                   ^^^^^^^^^^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/openai/client.rs:20:29
   |
20 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unused import: `AsyncTask`
  --> packages/provider/src/clients/openai/completion.rs:19:24
   |
19 | use fluent_ai_domain::{AsyncTask, spawn_async};
   |                        ^^^^^^^^^

warning: unused import: `HttpError`
  --> packages/provider/src/clients/openai/completion.rs:21:47
   |
21 | use fluent_ai_http3::{HttpClient, HttpConfig, HttpError, HttpRequest};
   |                                               ^^^^^^^^^

warning: unused import: `std::collections::HashMap`
 --> packages/provider/src/clients/openai/discovery.rs:3:5
  |
3 | use std::collections::HashMap;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `once_cell::sync::Lazy`
 --> packages/provider/src/clients/openai/discovery.rs:7:5
  |
7 | use once_cell::sync::Lazy;
  |     ^^^^^^^^^^^^^^^^^^^^^

warning: unused imports: `Deserialize` and `Serialize`
 --> packages/provider/src/clients/openai/discovery.rs:8:13
  |
8 | use serde::{Deserialize, Serialize};
  |             ^^^^^^^^^^^  ^^^^^^^^^

warning: unused import: `thiserror::Error`
 --> packages/provider/src/clients/openai/discovery.rs:9:5
  |
9 | use thiserror::Error;
  |     ^^^^^^^^^^^^^^^^

warning: unused import: `trace`
  --> packages/provider/src/clients/openai/discovery.rs:10:47
   |
10 | use tracing::{debug, error, info, instrument, trace, warn};
   |                                               ^^^^^

warning: unused imports: `error::OpenAIError`, `model_name_from_variant`, `model_supports_audio`, `model_supports_tools`, and `model_supports_vision`
  --> packages/provider/src/clients/openai/discovery.rs:15:5
   |
15 |     error::OpenAIError,
   |     ^^^^^^^^^^^^^^^^^^
16 |     model_info::{
17 |         get_model_config, model_name_from_variant, model_supports_audio, model_supports_tools,
   |                           ^^^^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^
18 |         model_supports_vision,
   |         ^^^^^^^^^^^^^^^^^^^^^

warning: unused imports: `Message as DomainMessage` and `ToolFunction`
 --> packages/provider/src/clients/openai/messages.rs:6:21
  |
6 | use crate::domain::{Message as DomainMessage, MessageRole, ToolCall as DomainToolCall, ToolFunction};
  |                     ^^^^^^^^^^^^^^^^^^^^^^^^                                           ^^^^^^^^^^^^

warning: unused import: `crate::AsyncStream`
 --> packages/provider/src/clients/openai/model_info.rs:8:5
  |
8 | use crate::AsyncStream;
  |     ^^^^^^^^^^^^^^^^^^

warning: unused import: `fluent_ai_domain::chunk::CompletionChunk`
 --> packages/provider/src/clients/openai/model_info.rs:9:5
  |
9 | use fluent_ai_domain::chunk::CompletionChunk;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/openrouter/client.rs:11:29
   |
11 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/openrouter/completion.rs:180:16
    |
180 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/openrouter/completion.rs:211:16
    |
211 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `std::future::Future`
  --> packages/provider/src/clients/openrouter/streaming.rs:14:5
   |
14 | use std::future::Future;
   |     ^^^^^^^^^^^^^^^^^^^

warning: unused imports: `Context` and `Poll`
  --> packages/provider/src/clients/openrouter/streaming.rs:18:17
   |
18 | use std::task::{Context, Poll};
   |                 ^^^^^^^  ^^^^

warning: unused imports: `Duration` and `Instant`
  --> packages/provider/src/clients/openrouter/streaming.rs:19:17
   |
19 | use std::time::{Duration, Instant, SystemTime};
   |                 ^^^^^^^^  ^^^^^^^

warning: unused import: `async_stream::stream`
  --> packages/provider/src/clients/openrouter/streaming.rs:23:5
   |
23 | use async_stream::stream;
   |     ^^^^^^^^^^^^^^^^^^^^

warning: unused import: `fluent_ai_domain::context::chunk::FinishReason`
  --> packages/provider/src/clients/openrouter/streaming.rs:29:5
   |
29 | use fluent_ai_domain::context::chunk::FinishReason;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `fluent_ai_http3::stream::SseEvent`
  --> packages/provider/src/clients/openrouter/streaming.rs:31:5
   |
31 | use fluent_ai_http3::stream::SseEvent;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused imports: `SmallVec` and `smallvec`
  --> packages/provider/src/clients/openrouter/streaming.rs:33:16
   |
33 | use smallvec::{SmallVec, smallvec};
   |                ^^^^^^^^  ^^^^^^^^

warning: unused imports: `AsyncStreamSender`, `AsyncStream`, and `async_stream_channel`
  --> packages/provider/src/clients/openrouter/streaming.rs:36:13
   |
36 | use crate::{AsyncStream, AsyncStreamSender, async_stream_channel};
   |             ^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^  ^^^^^^^^^^^^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/perplexity/client.rs:10:29
   |
10 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unused import: `bytes::Bytes`
  --> packages/provider/src/clients/perplexity/client.rs:12:5
   |
12 | use bytes::Bytes;
   |     ^^^^^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/perplexity/completion.rs:226:16
    |
226 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/perplexity/completion.rs:261:16
    |
261 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/together/client.rs:10:29
   |
10 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/together/completion.rs:196:16
    |
196 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/together/completion.rs:241:16
    |
241 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `worker`
  --> packages/provider/src/clients/together/embedding.rs:71:16
   |
71 |     #[cfg_attr(feature = "worker", worker::send)]
   |                ^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `worker` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `crate::clients::openai::send_compatible_streaming_request`
 --> packages/provider/src/clients/together/streaming.rs:5:5
  |
5 | use crate::clients::openai::send_compatible_streaming_request;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `ArrayVec`
  --> packages/provider/src/clients/xai/client.rs:11:29
   |
11 | use arrayvec::{ArrayString, ArrayVec};
   |                             ^^^^^^^^

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/xai/completion.rs:110:16
    |
110 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `worker`
   --> packages/provider/src/clients/xai/completion.rs:134:16
    |
134 |     #[cfg_attr(feature = "worker", worker::send)]
    |                ^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `worker` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
  --> packages/provider/src/image_processing/mod.rs:14:7
   |
14 | #[cfg(feature = "generation")]
   |       ^^^^^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `generation` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
  --> packages/provider/src/image_processing/mod.rs:18:7
   |
18 | #[cfg(feature = "generation")]
   |       ^^^^^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `generation` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/mod.rs:308:7
    |
308 | #[cfg(feature = "generation")]
    |       ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `DType`
 --> packages/provider/src/image_processing/candle_backend.rs:8:19
  |
8 | use candle_core::{DType, Device, Tensor};
  |                   ^^^^^

warning: unused import: `candle_nn::VarBuilder`
 --> packages/provider/src/image_processing/candle_backend.rs:9:5
  |
9 | use candle_nn::VarBuilder;
  |     ^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `std::sync::Arc`
  --> packages/provider/src/image_processing/candle_backend.rs:10:5
   |
10 | use std::sync::Arc;
   |     ^^^^^^^^^^^^^^

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/candle_backend.rs:621:30
    |
621 |             generation: cfg!(feature = "generation"),
    |                              ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
  --> packages/provider/src/image_processing/factory.rs:49:11
   |
49 |     #[cfg(feature = "generation")]
   |           ^^^^^^^^^^^^^^^^^^^^^^
   |
   = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
   = help: consider adding `generation` as a feature in `Cargo.toml`
   = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:111:11
    |
111 |     #[cfg(feature = "generation")]
    |           ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:141:11
    |
141 |     #[cfg(feature = "generation")]
    |           ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:237:11
    |
237 |     #[cfg(feature = "generation")]
    |           ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:261:11
    |
261 |     #[cfg(feature = "generation")]
    |           ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:276:11
    |
276 |     #[cfg(feature = "generation")]
    |           ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:287:11
    |
287 |     #[cfg(feature = "generation")]
    |           ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:246:19
    |
246 |             #[cfg(feature = "generation")]
    |                   ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unexpected `cfg` condition value: `generation`
   --> packages/provider/src/image_processing/factory.rs:303:15
    |
303 |         #[cfg(feature = "generation")]
    |               ^^^^^^^^^^^^^^^^^^^^^^
    |
    = note: expected values for `feature` are: `accelerate`, `candle-datasets`, `cpal`, `cuda`, `cudnn`, `default`, `dioxus`, `enterpolation`, `flash-attn`, `gloo-timers`, `image`, `js-sys`, `metal`, `mkl`, `nccl`, `onnx`, `palette`, `parking`, `rubato`, `safetensors`, `symphonia`, `tokenizers`, `ui`, `wasm-bindgen`, and `wide-ops`
    = help: consider adding `generation` as a feature in `Cargo.toml`
    = note: see <https://doc.rust-lang.org/nightly/rustc/check-cfg/cargo-specifics.html> for more information about checking conditional configuration

warning: unused import: `arrayvec::ArrayVec`
   --> packages/provider/src/image_processing/factory.rs:440:5
    |
440 | use arrayvec::ArrayVec;
    |     ^^^^^^^^^^^^^^^^^^

warning: unused import: `std::collections::HashMap`
 --> packages/provider/src/discovery.rs:3:5
  |
3 | use std::collections::HashMap;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `std::future::Future`
 --> packages/provider/src/discovery.rs:4:5
  |
4 | use std::future::Future;
  |     ^^^^^^^^^^^^^^^^^^^

warning: unused import: `std::pin::Pin`
 --> packages/provider/src/discovery.rs:5:5
  |
5 | use std::pin::Pin;
  |     ^^^^^^^^^^^^^

warning: unused import: `futures_util::future::BoxFuture`
  --> packages/provider/src/discovery.rs:10:5
   |
10 | use futures_util::future::BoxFuture;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused imports: `debug`, `instrument`, `trace`, and `warn`
  --> packages/provider/src/discovery.rs:13:15
   |
13 | use tracing::{debug, error, info, instrument, trace, warn};
   |               ^^^^^               ^^^^^^^^^^  ^^^^^  ^^^^

warning: unused import: `cyrup_sugars::AsyncResult`
  --> packages/provider/src/client_factory.rs:15:5
   |
15 | use cyrup_sugars::AsyncResult;
   |     ^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `sleep`
  --> packages/provider/src/security/rotation.rs:17:39
   |
17 | use tokio::time::{Interval, interval, sleep};
   |                                       ^^^^^

warning: unused import: `warn`
  --> packages/provider/src/security/rotation.rs:18:35
   |
18 | use tracing::{debug, error, info, warn};
   |                                   ^^^^

warning: unused import: `RotationConfig`
  --> packages/provider/src/security/rotation.rs:21:63
   |
21 | use super::credentials::{CredentialManager, CredentialSource, RotationConfig};
   |                                                               ^^^^^^^^^^^^^^

warning: unused import: `std::collections::HashMap`
 --> packages/provider/src/client.rs:6:5
  |
6 | use std::collections::HashMap;
  |     ^^^^^^^^^^^^^^^^^^^^^^^^^

warning: unused import: `OneOrMany`
 --> packages/provider/src/client.rs:8:20
  |
8 | use cyrup_sugars::{OneOrMany, ZeroOneOrMany};
  |                    ^^^^^^^^^

warning: unused import: `VoiceChunk`
 --> packages/provider/src/client.rs:9:64
  |
9 | use fluent_ai_domain::chunk::{CompletionChunk, EmbeddingChunk, VoiceChunk};
  |                                                                ^^^^^^^^^^

error[E0107]: missing generics for struct `fluent_ai_domain::Tool`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:706:28
    |
706 |     tools: HashMap<String, Tool>,
    |                            ^^^^ expected 1 generic argument
    |
note: struct defined here, with 1 generic parameter: `T`
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/tool/core.rs:73:12
    |
73  | pub struct Tool<T> {
    |            ^^^^ -
help: add missing generic argument
    |
706 |     tools: HashMap<String, Tool<T>>,
    |                                +++

error[E0107]: missing generics for struct `fluent_ai_domain::Tool`
  --> packages/provider/src/clients/bedrock/completion.rs:53:16
   |
53 |     tools: Vec<Tool>,
   |                ^^^^ expected 1 generic argument
   |
note: struct defined here, with 1 generic parameter: `T`
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/tool/core.rs:73:12
   |
73 | pub struct Tool<T> {
   |            ^^^^ -
help: add missing generic argument
   |
53 |     tools: Vec<Tool<T>>,
   |                    +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/device_manager.rs:146:24
    |
146 |     available_devices: SmallVec<[DeviceInfo; 8]>,
    |                        ^^^^^^^^ --------------- supplied 1 generic argument
    |                        |
    |                        expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
146 |     available_devices: SmallVec<[DeviceInfo; 8], N>,
    |                                                +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/device_manager.rs:154:23
    |
154 |     preference_order: SmallVec<[DeviceType; 4]>,
    |                       ^^^^^^^^ --------------- supplied 1 generic argument
    |                       |
    |                       expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
154 |     preference_order: SmallVec<[DeviceType; 4], N>,
    |                                               +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/error.rs:96:20
    |
96  |         available: SmallVec<[CandleDevice; 4]>,
    |                    ^^^^^^^^ ----------------- supplied 1 generic argument
    |                    |
    |                    expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
96  |         available: SmallVec<[CandleDevice; 4], N>,
    |                                              +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/memory_pool.rs:429:20
    |
429 |     pools: ArcSwap<SmallVec<[Arc<MemoryPool>; MAX_SIZE_CLASSES]>>,
    |                    ^^^^^^^^ ----------------------------------- supplied 1 generic argument
    |                    |
    |                    expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
429 |     pools: ArcSwap<SmallVec<[Arc<MemoryPool>; MAX_SIZE_CLASSES], N>>,
    |                                                                +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/memory_pool.rs:431:19
    |
431 |     size_classes: SmallVec<[usize; MAX_SIZE_CLASSES]>,
    |                   ^^^^^^^^ ------------------------- supplied 1 generic argument
    |                   |
    |                   expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
431 |     size_classes: SmallVec<[usize; MAX_SIZE_CLASSES], N>,
    |                                                     +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/streaming.rs:80:21
    |
80  |     pub text_bytes: SmallVec<[u8; MAX_TOKEN_TEXT_LEN]>,
    |                     ^^^^^^^^ ------------------------ supplied 1 generic argument
    |                     |
    |                     expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
80  |     pub text_bytes: SmallVec<[u8; MAX_TOKEN_TEXT_LEN], N>,
    |                                                      +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/tokenizer.rs:33:13
    |
33  |     buffer: SmallVec<[u8; 1024]>,
    |             ^^^^^^^^ ---------- supplied 1 generic argument
    |             |
    |             expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
33  |     buffer: SmallVec<[u8; 1024], N>,
    |                                +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/tokenizer.rs:27:21
    |
27  | pub type TokenIds = SmallVec<[u32; MAX_ENCODE_BATCH]>;
    |                     ^^^^^^^^ ----------------------- supplied 1 generic argument
    |                     |
    |                     expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
27  | pub type TokenIds = SmallVec<[u32; MAX_ENCODE_BATCH], N>;
    |                                                     +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/tokenizer.rs:216:21
    |
216 |     attention_mask: SmallVec<[u8; MAX_ENCODE_BATCH]>,
    |                     ^^^^^^^^ ---------------------- supplied 1 generic argument
    |                     |
    |                     expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
216 |     attention_mask: SmallVec<[u8; MAX_ENCODE_BATCH], N>,
    |                                                    +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/tokenizer.rs:375:19
    |
375 |     partial_utf8: SmallVec<[u8; 4]>,
    |                   ^^^^^^^^ ------- supplied 1 generic argument
    |                   |
    |                   expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
375 |     partial_utf8: SmallVec<[u8; 4], N>,
    |                                   +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/image_processing/factory.rs:569:28
    |
569 |     pub supported_formats: SmallVec<[ImageFormat; 4]>,
    |                            ^^^^^^^^ ---------------- supplied 1 generic argument
    |                            |
    |                            expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
569 |     pub supported_formats: SmallVec<[ImageFormat; 4], N>,
    |                                                     +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/image_processing/factory.rs:619:17
    |
619 |     processors: SmallVec<[Arc<dyn StreamingImageProcessor + Send + Sync>; 8]>,
    |                 ^^^^^^^^ --------------------------------------------------- supplied 1 generic argument
    |                 |
    |                 expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
619 |     processors: SmallVec<[Arc<dyn StreamingImageProcessor + Send + Sync>; 8], N>,
    |                                                                             +++

error[E0107]: struct takes 2 generic arguments but 1 generic argument was supplied
   --> packages/provider/src/clients/candle/generation.rs:26:25
    |
26  | pub type LogitsBuffer = SmallVec<[f32; SAMPLING_CACHE_SIZE]>;
    |                         ^^^^^^^^ -------------------------- supplied 1 generic argument
    |                         |
    |                         expected 2 generic arguments
    |
note: struct defined here, with 2 generic parameters: `T`, `N`
   --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/smallvec-2.0.0-alpha.11/src/lib.rs:302:12
    |
302 | pub struct SmallVec<T, const N: usize> {
    |            ^^^^^^^^ -  --------------
help: add missing generic argument
    |
26  | pub type LogitsBuffer = SmallVec<[f32; SAMPLING_CACHE_SIZE], N>;
    |                                                            +++

error[E0107]: missing generics for struct `fluent_ai_domain::Tool`
   --> packages/provider/src/clients/anthropic/tools/function_calling.rs:688:29
    |
688 |     fn definition(&self) -> Tool;
    |                             ^^^^ expected 1 generic argument
    |
note: struct defined here, with 1 generic parameter: `T`
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/tool/core.rs:73:12
    |
73  | pub struct Tool<T> {
    |            ^^^^ -
help: add missing generic argument
    |
688 |     fn definition(&self) -> Tool<T>;
    |                                 +++

error[E0107]: trait takes 0 generic arguments but 1 generic argument was supplied
  --> packages/provider/src/client.rs:61:75
   |
61 |     fn prompt(&self, prompt: fluent_ai_domain::prompt::Prompt) -> Box<dyn AsyncStream<CompletionChunk>>;
   |                                                                           ^^^^^^^^^^^ expected 0 generic arguments
   |
note: trait defined here, with 0 generic parameters
  --> /Users/davidmaple/.cargo/registry/src/index.crates.io-1949cf8c6b5b557f/futures-core-0.3.31/src/stream.rs:37:11
   |
37 | pub trait Stream {
   |           ^^^^^^
help: replace the generic bound with the associated type
   |
61 |     fn prompt(&self, prompt: fluent_ai_domain::prompt::Prompt) -> Box<dyn AsyncStream<Item = CompletionChunk>>;
   |                                                                                       ++++++

error[E0191]: the value of the associated type `Item` in `fluent_ai_domain::AsyncStream` must be specified
  --> packages/provider/src/client.rs:61:75
   |
61 |     fn prompt(&self, prompt: fluent_ai_domain::prompt::Prompt) -> Box<dyn AsyncStream<CompletionChunk>>;
   |                                                                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^ associated type `Item` must be specified

error[E0107]: missing generics for struct `fluent_ai_domain::Tool`
  --> packages/provider/src/clients/anthropic/tools/calculator.rs:66:29
   |
66 |     fn definition(&self) -> Tool {
   |                             ^^^^ expected 1 generic argument
   |
note: struct defined here, with 1 generic parameter: `T`
  --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/tool/core.rs:73:12
   |
73 | pub struct Tool<T> {
   |            ^^^^ -
help: add missing generic argument
   |
66 |     fn definition(&self) -> Tool<T> {
   |                                 +++

error[E0107]: missing generics for struct `fluent_ai_domain::Tool`
   --> packages/provider/src/clients/anthropic/tools/file_operations.rs:532:29
    |
532 |     fn definition(&self) -> Tool {
    |                             ^^^^ expected 1 generic argument
    |
note: struct defined here, with 1 generic parameter: `T`
   --> /Volumes/samsung_t9/fluent-ai/packages/domain/src/tool/core.rs:73:12
    |
73  | pub struct Tool<T> {
    |            ^^^^ -
help: add missing generic argument
    |
532 |     fn definition(&self) -> Tool<T> {
    |                                 +++

error[E0782]: expected a type, found a trait
  --> packages/provider/src/clients/azure/completion.rs:73:6
   |
73 | impl CompletionModel {
   |      ^^^^^^^^^^^^^^^
   |
help: you can add the `dyn` keyword if you want a trait object
   |
73 | impl dyn CompletionModel {
   |      +++
help: you might have intended to implement this trait for a given type
   |
73 | impl CompletionModel for /* Type */ {
   |                      ++++++++++++++

error[E0782]: expected a type, found a trait
   --> packages/provider/src/clients/azure/completion.rs:108:6
    |
108 | impl CompletionModel {
    |      ^^^^^^^^^^^^^^^
    |
help: you can add the `dyn` keyword if you want a trait object
    |
108 | impl dyn CompletionModel {
    |      +++
help: you might have intended to implement this trait for a given type
    |
108 | impl CompletionModel for /* Type */ {
    |                      ++++++++++++++

error[E0782]: expected a type, found a trait
  --> packages/provider/src/clients/azure/streaming.rs:36:6
   |
36 | impl CompletionModel {
   |      ^^^^^^^^^^^^^^^
   |
help: you can add the `dyn` keyword if you want a trait object
   |
36 | impl dyn CompletionModel {
   |      +++
help: you might have intended to implement this trait for a given type
   |
36 | impl CompletionModel for /* Type */ {
   |                      ++++++++++++++

error[E0782]: expected a type, found a trait
  --> packages/provider/src/clients/together/streaming.rs:12:6
   |
12 | impl CompletionModel {
   |      ^^^^^^^^^^^^^^^
   |
help: you can add the `dyn` keyword if you want a trait object
   |
12 | impl dyn CompletionModel {
   |      +++
help: you might have intended to implement this trait for a given type
   |
12 | impl CompletionModel for /* Type */ {
   |                      ++++++++++++++

error[E0782]: expected a type, found a trait
  --> packages/provider/src/clients/xai/streaming.rs:19:6
   |
19 | impl CompletionModel {
   |      ^^^^^^^^^^^^^^^
   |
help: you can add the `dyn` keyword if you want a trait object
   |
19 | impl dyn CompletionModel {
   |      +++
help: you might have intended to implement this trait for a given type
   |
19 | impl CompletionModel for /* Type */ {
   |                      ++++++++++++++

error[E0782]: expected a type, found a trait
   --> packages/provider/src/clients/azure/client.rs:594:18
    |
594 |     type Model = CompletionModel;
    |                  ^^^^^^^^^^^^^^^

error[E0782]: expected a type, found a trait
   --> packages/provider/src/clients/azure/client.rs:607:48
    |
607 |     fn completion_model(&self, model: &str) -> CompletionModel {
    |                                                ^^^^^^^^^^^^^^^
    |
help: use `impl CompletionModel` to return an opaque type, as long as you return a single underlying type
    |
607 |     fn completion_model(&self, model: &str) -> impl CompletionModel {
    |                                                ++++
help: alternatively, you can return an owned trait object
    |
607 |     fn completion_model(&self, model: &str) -> Box<dyn CompletionModel> {
    |                                                +++++++                +

error[E0782]: expected a type, found a trait
  --> packages/provider/src/clients/azure/completion.rs:85:38
   |
85 | impl completion::CompletionModel for CompletionModel {
   |                                      ^^^^^^^^^^^^^^^
   |
help: you can add the `dyn` keyword if you want a trait object
   |
85 | impl completion::CompletionModel for dyn CompletionModel {
   |                                      +++

error[E0107]: type alias takes 1 generic argument but 2 generic arguments were supplied
   --> packages/provider/src/clients/bedrock/client.rs:230:44
    |
230 |     fn test_connection(&self) -> AsyncTask<Result<(), Box<dyn std::error::Error + Send + Sync>>> {
    |                                            ^^^^^^   ------------------------------------------ help: remove the unnecessary generic argument
    |                                            |
    |                                            expected 1 generic argument
    |
note: type alias defined here, with 1 generic parameter: `T`
   --> packages/provider/src/clients/bedrock/error.rs:20:10
    |
20  | pub type Result<T> = std::result::Result<T, BedrockError>;
    |          ^^^^^^ -

error[E0053]: method `test_connection` has an incompatible type for trait
   --> packages/provider/src/clients/bedrock/client.rs:230:34
    |
230 |     fn test_connection(&self) -> AsyncTask<Result<(), Box<dyn std::error::Error + Send + Sync>>> {
    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ expected `Box<dyn Error + Send + Sync>`, found `BedrockError`
    |
note: type in trait
   --> packages/provider/src/client.rs:39:34
    |
39  |     fn test_connection(&self) -> AsyncTask<Result<(), Box<dyn std::error::Error + Send + Sync>>>;
    |                                  ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
    = note: expected signature `fn(&BedrockClient) -> tokio::task::JoinHandle<std::result::Result<_, Box<(dyn StdError + std::marker::Send + Sync + 'static)>>>`
               found signature `fn(&BedrockClient) -> tokio::task::JoinHandle<std::result::Result<_, BedrockError>>`
help: change the output type to match the trait
    |
230 -     fn test_connection(&self) -> AsyncTask<Result<(), Box<dyn std::error::Error + Send + Sync>>> {
230 +     fn test_connection(&self) -> tokio::task::JoinHandle<std::result::Result<(), Box<(dyn StdError + std::marker::Send + Sync + 'static)>>> {
    |

error[E0049]: method `prompt` has 0 type parameters but its trait declaration has 1 type parameter
   --> packages/provider/src/clients/bedrock/completion.rs:389:14
    |
389 |     fn prompt(&self, prompt: fluent_ai_domain::prompt::Prompt) -> AsyncStream<CompletionChunk> {
    |              ^ found 0 type parameters
    |
   ::: packages/provider/src/completion_provider.rs:133:27
    |
133 |     fn prompt(self, text: impl AsRef<str>) -> AsyncStream<CompletionChunk>;
    |                           ---------------
    |                           |
    |                           expected 1 type parameter
    |                           `impl Trait` introduces an implicit type parameter

error[E0046]: not all trait items implemented, missing: `new`, `api_key`, `system_prompt`, `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `chat_history`, `documents`, `tools`, `additional_params`, `on_chunk`
   --> packages/provider/src/clients/bedrock/completion.rs:384:1
    |
384 |   impl CompletionProvider for BedrockCompletionBuilder {
    |   ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^ missing `new`, `api_key`, `system_prompt`, `temperature`, `max_tokens`, `top_p`, `frequency_penalty`, `presence_penalty`, `chat_history`, `documents`, `tools`, `additional_params`, `on_chunk` in implementation
    |
   ::: packages/provider/src/completion_provider.rs:76:5
    |
76  |       fn new(api_key: String, model_name: &'static str) -> Result<Self, CompletionError>;
    |       ----------------------------------------------------------------------------------- `new` from trait
...
79  |       fn api_key(self, key: impl Into<String>) -> Self;
    |       ------------------------------------------------- `api_key` from trait
...
90  |       fn system_prompt(self, prompt: impl Into<String>) -> Self;
    |       ---------------------------------------------------------- `system_prompt` from trait
...
93  |       fn temperature(self, temp: f64) -> Self;
    |       ---------------------------------------- `temperature` from trait
...
96  |       fn max_tokens(self, tokens: u32) -> Self;
    |       ----------------------------------------- `max_tokens` from trait
...
99  |       fn top_p(self, p: f64) -> Self;
    |       ------------------------------- `top_p` from trait
...
102 |       fn frequency_penalty(self, penalty: f64) -> Self;
    |       ------------------------------------------------- `frequency_penalty` from trait
...
105 |       fn presence_penalty(self, penalty: f64) -> Self;
    |       ------------------------------------------------ `presence_penalty` from trait
...
108 |       fn chat_history(self, history: ZeroOneOrMany<Message>) -> Result<Self, CompletionError>;
    |       ---------------------------------------------------------------------------------------- `chat_history` from trait
...
111 |       fn documents(self, docs: ZeroOneOrMany<Document>) -> Result<Self, CompletionError>;
    |       ----------------------------------------------------------------------------------- `documents` from trait
...
114 |       fn tools(self, tools: ZeroOneOrMany<ToolDefinition>) -> Result<Self, CompletionError>;
    |       -------------------------------------------------------------------------------------- `tools` from trait
...
117 |       fn additional_params(self, params: Value) -> Self;
    |       -------------------------------------------------- `additional_params` from trait
...
127 | /     fn on_chunk<F>(self, handler: F) -> Self
128 | |     where
129 | |         F: Fn(Result<CompletionChunk, CompletionError>) + Send + Sync + 'static;
    | |________________________________________________________________________________- `on_chunk` from trait

error[E0433]: failed to resolve: use of undeclared type `TranscriptionModel`
   --> packages/provider/src/clients/azure/client.rs:638:9
    |
638 |         TranscriptionModel::new(self.clone(), model)
    |         ^^^^^^^^^^^^^^^^^^
    |         |
    |         use of undeclared type `TranscriptionModel`
    |         help: a trait with a similar name exists: `TranscriptionClient`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `json_util`
   --> packages/provider/src/clients/azure/completion.rs:205:13
    |
205 |             json_util::merge(request, params)
    |             ^^^^^^^^^ use of unresolved module or unlinked crate `json_util`
    |
    = help: if you wanted to use a crate named `json_util`, use `cargo add json_util` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
  --> packages/provider/src/clients/azure/embedding.rs:77:9
   |
77 |         EmbeddingError::ProviderError(err.message)
   |         ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
   |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
   |
77 -         EmbeddingError::ProviderError(err.message)
77 +         crate::domain::ContextError::ProviderError(err.message)
   |
77 -         EmbeddingError::ProviderError(err.message)
77 +         fluent_ai_domain::ContextError::ProviderError(err.message)
   |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
  --> packages/provider/src/clients/azure/embedding.rs:85:42
   |
85 |             ApiResponse::Err(err) => Err(EmbeddingError::ProviderError(err.message)),
   |                                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
   |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
   |
85 -             ApiResponse::Err(err) => Err(EmbeddingError::ProviderError(err.message)),
85 +             ApiResponse::Err(err) => Err(crate::domain::ContextError::ProviderError(err.message)),
   |
85 -             ApiResponse::Err(err) => Err(EmbeddingError::ProviderError(err.message)),
85 +             ApiResponse::Err(err) => Err(fluent_ai_domain::ContextError::ProviderError(err.message)),
   |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:193:26
    |
193 |             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
193 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
193 +             .map_err(|e| crate::domain::ContextError::Serialization(e.to_string()))?;
    |
193 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
193 +             .map_err(|e| fluent_ai_domain::ContextError::Serialization(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:203:26
    |
203 |             .map_err(|e| EmbeddingError::Http(e.to_string()))?
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
203 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?
203 +             .map_err(|e| crate::domain::ContextError::Http(e.to_string()))?
    |
203 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?
203 +             .map_err(|e| fluent_ai_domain::ContextError::Http(e.to_string()))?
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:212:26
    |
212 |             .map_err(|e| EmbeddingError::Http(e.to_string()))?;
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
212 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?;
212 +             .map_err(|e| crate::domain::ContextError::Http(e.to_string()))?;
    |
212 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?;
212 +             .map_err(|e| fluent_ai_domain::ContextError::Http(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:219:30
    |
219 |                 .map_err(|e| EmbeddingError::Http(e.to_string()))?;
    |                              ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
219 -                 .map_err(|e| EmbeddingError::Http(e.to_string()))?;
219 +                 .map_err(|e| crate::domain::ContextError::Http(e.to_string()))?;
    |
219 -                 .map_err(|e| EmbeddingError::Http(e.to_string()))?;
219 +                 .map_err(|e| fluent_ai_domain::ContextError::Http(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:220:24
    |
220 |             return Err(EmbeddingError::ProviderError(format!(
    |                        ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
220 -             return Err(EmbeddingError::ProviderError(format!(
220 +             return Err(crate::domain::ContextError::ProviderError(format!(
    |
220 -             return Err(EmbeddingError::ProviderError(format!(
220 +             return Err(fluent_ai_domain::ContextError::ProviderError(format!(
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:229:26
    |
229 |             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
229 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
229 +             .map_err(|e| crate::domain::ContextError::Serialization(e.to_string()))?;
    |
229 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
229 +             .map_err(|e| fluent_ai_domain::ContextError::Serialization(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:233:25
    |
233 |             None => Err(EmbeddingError::ResponseError(
    |                         ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
233 -             None => Err(EmbeddingError::ResponseError(
233 +             None => Err(crate::domain::ContextError::ResponseError(
    |
233 -             None => Err(EmbeddingError::ResponseError(
233 +             None => Err(fluent_ai_domain::ContextError::ResponseError(
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:253:24
    |
253 |             return Err(EmbeddingError::Provider(format!(
    |                        ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
253 -             return Err(EmbeddingError::Provider(format!(
253 +             return Err(crate::domain::ContextError::Provider(format!(
    |
253 -             return Err(EmbeddingError::Provider(format!(
253 +             return Err(fluent_ai_domain::ContextError::Provider(format!(
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:266:26
    |
266 |             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
266 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
266 +             .map_err(|e| crate::domain::ContextError::Serialization(e.to_string()))?;
    |
266 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
266 +             .map_err(|e| fluent_ai_domain::ContextError::Serialization(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:276:26
    |
276 |             .map_err(|e| EmbeddingError::Http(e.to_string()))?
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
276 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?
276 +             .map_err(|e| crate::domain::ContextError::Http(e.to_string()))?
    |
276 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?
276 +             .map_err(|e| fluent_ai_domain::ContextError::Http(e.to_string()))?
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:285:26
    |
285 |             .map_err(|e| EmbeddingError::Http(e.to_string()))?;
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
285 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?;
285 +             .map_err(|e| crate::domain::ContextError::Http(e.to_string()))?;
    |
285 -             .map_err(|e| EmbeddingError::Http(e.to_string()))?;
285 +             .map_err(|e| fluent_ai_domain::ContextError::Http(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:292:30
    |
292 |                 .map_err(|e| EmbeddingError::Http(e.to_string()))?;
    |                              ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
292 -                 .map_err(|e| EmbeddingError::Http(e.to_string()))?;
292 +                 .map_err(|e| crate::domain::ContextError::Http(e.to_string()))?;
    |
292 -                 .map_err(|e| EmbeddingError::Http(e.to_string()))?;
292 +                 .map_err(|e| fluent_ai_domain::ContextError::Http(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:293:24
    |
293 |             return Err(EmbeddingError::ProviderError(format!(
    |                        ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
293 -             return Err(EmbeddingError::ProviderError(format!(
293 +             return Err(crate::domain::ContextError::ProviderError(format!(
    |
293 -             return Err(EmbeddingError::ProviderError(format!(
293 +             return Err(fluent_ai_domain::ContextError::ProviderError(format!(
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:302:26
    |
302 |             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
    |                          ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
302 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
302 +             .map_err(|e| crate::domain::ContextError::Serialization(e.to_string()))?;
    |
302 -             .map_err(|e| EmbeddingError::Serialization(e.to_string()))?;
302 +             .map_err(|e| fluent_ai_domain::ContextError::Serialization(e.to_string()))?;
    |

error[E0433]: failed to resolve: use of undeclared type `EmbeddingError`
   --> packages/provider/src/clients/azure/embedding.rs:305:24
    |
305 |             return Err(EmbeddingError::ResponseError(format!(
    |                        ^^^^^^^^^^^^^^ use of undeclared type `EmbeddingError`
    |
help: there is an enum variant `crate::domain::ContextError::EmbeddingError` and 1 other; try using the variant's enum
    |
305 -             return Err(EmbeddingError::ResponseError(format!(
305 +             return Err(crate::domain::ContextError::ResponseError(format!(
    |
305 -             return Err(EmbeddingError::ResponseError(format!(
305 +             return Err(fluent_ai_domain::ContextError::ResponseError(format!(
    |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `transcription`
  --> packages/provider/src/clients/azure/transcription.rs:54:18
   |
54 |         request: transcription::TranscriptionRequest,
   |                  ^^^^^^^^^^^^^ use of unresolved module or unlinked crate `transcription`
   |
help: to make use of source file packages/provider/src/clients/azure/transcription.rs, use `mod transcription` in this file to declare the module
  --> packages/provider/src/lib.rs:7:1
   |
7  + mod transcription;
   |

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `transcription`
  --> packages/provider/src/clients/azure/transcription.rs:71:18
   |
71 |         request: transcription::TranscriptionRequest,
   |                  ^^^^^^^^^^^^^ use of unresolved module or unlinked crate `transcription`
   |
help: to make use of source file packages/provider/src/clients/azure/transcription.rs, use `mod transcription` in this file to declare the module
  --> packages/provider/src/lib.rs:7:1
   |
7  + mod transcription;
   |

error[E0433]: failed to resolve: use of undeclared type `TranscriptionError`
   --> packages/provider/src/clients/azure/transcription.rs:113:61
    |
113 |                 ApiResponse::Err(api_error_response) => Err(TranscriptionError::ProviderError(
    |                                                             ^^^^^^^^^^^^^^^^^^ use of undeclared type `TranscriptionError`

error[E0433]: failed to resolve: use of undeclared type `TranscriptionError`
   --> packages/provider/src/clients/azure/transcription.rs:118:17
    |
118 |             Err(TranscriptionError::ProviderError(response.text().await?))
    |                 ^^^^^^^^^^^^^^^^^^ use of undeclared type `TranscriptionError`

error[E0433]: failed to resolve: use of undeclared type `EmbeddingBuilder`
   --> packages/provider/src/clients/gemini/client.rs:289:9
    |
289 |         EmbeddingBuilder::new(self.embedding_model(model))
    |         ^^^^^^^^^^^^^^^^ use of undeclared type `EmbeddingBuilder`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `json_util`
   --> packages/provider/src/clients/gemini/client.rs:506:34
    |
506 |         self.additional_params = json_util::merge(self.additional_params, params);
    |                                  ^^^^^^^^^ use of unresolved module or unlinked crate `json_util`
    |
    = help: if you wanted to use a crate named `json_util`, use `cargo add json_util` to add it to your `Cargo.toml`

error[E0433]: failed to resolve: use of unresolved module or unlinked crate `json_util`
  --> packages/provider/src/clients/huggingface/streaming.rs:42:36
   |
42 |         #[serde(deserialize_with = "json_util::string_or_vec")]
   |                                    ^^^^^^^^^^^^^^^^^^^^^^^^^^ use of unresolved module or unlinked crate `json_util`
   |
   = help: if you wanted to use a crate named `json_util`, use `cargo add json_util` to add it to your `Cargo.toml`

Some errors have detailed explanations: E0046, E0049, E0053, E0106, E0107, E0191, E0364, E0365, E0404...
For more information about an error, try `rustc --explain E0046`.
warning: `fluent_ai_provider` (lib) generated 168 warnings
warning: fluent_ai_provider@0.1.0: Starting provider generation...
warning: fluent_ai_provider@0.1.0: Generated providers.rs and models.rs with 6 providers
warning: fluent_ai_provider@0.1.0: Provider generation completed successfully
error: could not compile `fluent_ai_provider` (lib) due to 572 previous errors; 168 warnings emitted
